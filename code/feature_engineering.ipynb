{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T11:07:33.629970Z",
     "start_time": "2019-10-14T11:07:27.359301Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm , skew\n",
    "from  scipy import stats\n",
    "from scipy.special import boxcox\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import fbeta_score, recall_score, precision_score, average_precision_score, precision_recall_curve\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE ,ADASYN,BorderlineSMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.metrics import make_scorer\n",
    "from time import time\n",
    "import lightgbm as light\n",
    "import catboost as cat\n",
    "import xgboost as xgb\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder,StandardScaler\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "import warnings\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split,learning_curve,cross_val_score,KFold,TimeSeriesSplit,GridSearchCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import (GradientBoostingClassifier, GradientBoostingRegressor, \n",
    "                              RandomForestClassifier, RandomForestRegressor,AdaBoostClassifier) \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgbm\n",
    "from sklearn.metrics import f1_score, confusion_matrix,roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:31:56.321176Z",
     "start_time": "2019-10-09T09:31:54.157362Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kaglle = train[train['locdt']>80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train[train['locdt']<=80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:31:57.832391Z",
     "start_time": "2019-10-09T09:31:57.826408Z"
    }
   },
   "outputs": [],
   "source": [
    "train_index = pd.DataFrame(train['txkey'])\n",
    "test_index = pd.DataFrame(test['txkey'])\n",
    "#kaggle_index = pd.DataFrame(kaggle['txkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:32:06.731964Z",
     "start_time": "2019-10-09T09:32:06.728972Z"
    }
   },
   "outputs": [],
   "source": [
    "#kaggle_ans  = kaggle['fraud_ind']\n",
    "#kaggle_ans = pd.DataFrame(kaggle_ans)\n",
    "#kaggle_ans['txkey'] = kaggle['txkey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:32:07.414723Z",
     "start_time": "2019-10-09T09:32:07.411731Z"
    }
   },
   "outputs": [],
   "source": [
    "#kaggle.drop('fraud_ind',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:32:18.704813Z",
     "start_time": "2019-10-09T09:32:18.406179Z"
    }
   },
   "outputs": [],
   "source": [
    "data_all = pd.concat([train,test],axis=0,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all = data_all.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all = data_all.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:32:23.204406Z",
     "start_time": "2019-10-09T09:32:23.110329Z"
    }
   },
   "outputs": [],
   "source": [
    "data_all['flbmk'].fillna('N', inplace=True)\n",
    "data_all['flg_3dsmk'].fillna('N', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:32:41.858890Z",
     "start_time": "2019-10-09T09:32:41.833710Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(data_all) :\n",
    "    grp = data_all.groupby(['bacno'])['conam'].min().reset_index().rename(columns={'conam':'comsum_min'})\n",
    "    \n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    \n",
    "    grp = data_all.groupby(['bacno'])['conam'].max().reset_index().rename(columns={'conam':'comsum_max'})\n",
    "    \n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    \n",
    "    grp = (data_all.groupby(['bacno'])['txkey'].count() / data_all['locdt'].max()).reset_index().rename(columns={'txkey':'acc_trad_ave'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    grp = data_all.groupby(['bacno'])['txkey'].count().reset_index().rename(columns={'txkey':'acc_trad_total'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    grp = data_all.groupby(['bacno'])['conam'].sum().reset_index().rename(columns={'conam':'comsum_total'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    grp = data_all.groupby(['bacno'])['conam'].mean().reset_index().rename(columns={'conam':'comsum_ave'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    day30 = data_all[data_all['locdt'] <= 30]\n",
    "    grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq30'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    data_all['comsum_feq30'].fillna(0,inplace=True)\n",
    "\n",
    "    day30 = data_all[(data_all['locdt'] <= 60) & (data_all['locdt'] >30 ) ]\n",
    "    grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq3060'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    data_all['comsum_feq3060'].fillna(0,inplace=True)\n",
    "\n",
    "    day30 = data_all[(data_all['locdt'] <= 90) & (data_all['locdt'] >60 ) ]\n",
    "    grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq6090'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    data_all['comsum_feq6090'].fillna(0,inplace=True)\n",
    "\n",
    "    day30 = data_all[(data_all['locdt'] <= 120) & (data_all['locdt'] >90 ) ]\n",
    "    grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq90120'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    data_all['comsum_feq90120'].fillna(0,inplace=True)\n",
    "\n",
    "    day60 = data_all[data_all['locdt'] <= 60]\n",
    "    grp = (day60.groupby(['bacno'])['txkey'].count() / 60).reset_index().rename(columns={'txkey':'comsum_feq60'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    data_all['comsum_feq60'].fillna(0,inplace=True)\n",
    "\n",
    "    day60 = data_all[(data_all['locdt'] <= 90) & (data_all['locdt'] >30 ) ]\n",
    "    grp = (day60.groupby(['bacno'])['txkey'].count() / 60).reset_index().rename(columns={'txkey':'comsum_feq3090'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    data_all['comsum_feq3090'].fillna(0,inplace=True)\n",
    "\n",
    "    day60 = data_all[(data_all['locdt'] <= 120) & (data_all['locdt'] >60 ) ]\n",
    "    grp = (day60.groupby(['bacno'])['txkey'].count() / 60).reset_index().rename(columns={'txkey':'comsum_feq60120'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    data_all['comsum_feq60120'].fillna(0,inplace=True)\n",
    "\n",
    "    grp = data_all.groupby(['locdt'])['bacno'].count().reset_index().rename(columns={'bacno':'day_trad_num'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "    grp = data_all.groupby(['locdt'])['conam'].sum().reset_index().rename(columns={'conam':'day_comsum_total'})\n",
    "    data_all = data_all.merge(grp,how='left')\n",
    "\n",
    "    data_all['ecfg_stocn'] = data_all['ecfg'] + data_all['stocn'].astype('str')\n",
    "    data_all['ecfg_scity'] = data_all['ecfg'] + data_all['scity'].astype('str')\n",
    "\n",
    "    data_all['ovrlt_stocn'] = data_all['ovrlt'] + data_all['stocn'].astype('str')\n",
    "    data_all['ovrlt_scity'] = data_all['ovrlt'] + data_all['stocn'].astype('str')\n",
    "\n",
    "    data_all['week'] = data_all['locdt']\n",
    "    data_all['week'] = data_all['week'] % 7 \n",
    "    \n",
    "\n",
    "    data_all['trad_hour'] = data_all['loctm'] // 10000\n",
    "\n",
    "    data_all['morning'] = ((data_all['trad_hour'] < 12) & (data_all['trad_hour'] >=6)).replace([True,False],[1,0])\n",
    "    data_all['afternoon'] = ((data_all['trad_hour'] < 18) & (data_all['trad_hour'] >=12)).replace([True,False],[1,0])\n",
    "    data_all['night'] = ((data_all['trad_hour'] < 24) & (data_all['trad_hour'] >=18)).replace([True,False],[1,0])\n",
    "    data_all['midnight'] = ((data_all['trad_hour'] < 6) & (data_all['trad_hour'] >=0)).replace([True,False],[1,0])\n",
    "\n",
    "    data_all['is_taiwan'] = (data_all['stocn'] == 102).replace([True,False],[1,0])\n",
    "\n",
    "    grp = data_all.groupby(['stocn'])['txkey'].count().reset_index().rename(columns={'txkey':'country_com_num'})\n",
    "    data_all = data_all.merge(grp,how='outer')\n",
    "\n",
    "    grp = data_all.groupby(['scity'])['txkey'].count().reset_index().rename(columns={'txkey':'city_com_num'})\n",
    "    data_all = data_all.merge(grp,how='outer')\n",
    "    \n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all.groupby(['bacno'])['locdt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:33:36.892388Z",
     "start_time": "2019-10-09T09:32:43.986476Z"
    }
   },
   "outputs": [],
   "source": [
    "data_all = preprocessing(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:33:39.379231Z",
     "start_time": "2019-10-09T09:33:38.611522Z"
    }
   },
   "outputs": [],
   "source": [
    "object_list = []\n",
    "int_list = []\n",
    "float_list = []\n",
    "for col in data_all.columns.tolist():\n",
    "    if data_all[col].dtype == 'object':\n",
    "        object_list.append(col)\n",
    "    if data_all[col].dtype == 'int64':\n",
    "        int_list.append(col)\n",
    "    if data_all[col].dtype == 'float64':\n",
    "        float_list.append(col)\n",
    "\n",
    "nd_ont_list = []\n",
    "nd_tar_list = []\n",
    "for col in object_list:\n",
    "\n",
    "    if len(data_all[col].unique()) < 5:\n",
    "        nd_ont_list.append(col)\n",
    "\n",
    "    else:\n",
    "        nd_tar_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:33:48.796658Z",
     "start_time": "2019-10-09T09:33:41.066676Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in nd_ont_list :\n",
    "    data_all =pd.concat([data_all] + [pd.get_dummies(data_all[col],prefix=col)] ,axis=1)\n",
    "data_all.drop(nd_ont_list,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:33:50.309246Z",
     "start_time": "2019-10-09T09:33:49.739010Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:33:53.200540Z",
     "start_time": "2019-10-09T09:33:51.249349Z"
    }
   },
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "for col in nd_tar_list :\n",
    "    data_all[col] = le.fit_transform(data_all[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = TargetEncoder(smoothing=0.9).fit(train[nd_tar_list],train['ans'])\n",
    "tar.transform(test[nd_tar_list])\n",
    "tar.transform(train[nd_tar_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:33:54.159935Z",
     "start_time": "2019-10-09T09:33:54.157940Z"
    }
   },
   "outputs": [],
   "source": [
    "#data_all[nd_tar_list] = target.transform(data_all[nd_tar_list])\n",
    "#data_all[nd_tar_list]  = target.transform(data_all[nd_tar_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:34:10.801756Z",
     "start_time": "2019-10-09T09:34:07.629599Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training = data_all.merge(train_index)\n",
    "testing = data_all.merge(test_index)\n",
    "#kaggle_ = data_all.merge(kaggle_index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:34:12.197642Z",
     "start_time": "2019-10-09T09:34:12.194650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1521787, 56) test (421665, 56)\n"
     ]
    }
   ],
   "source": [
    "print('train',training.shape , 'test', testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:34:21.295500Z",
     "start_time": "2019-10-09T09:34:21.162855Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing = testing.drop('fraud_ind',axis=1)\n",
    "#kaggle_ = kaggle_.drop('fraud_ind',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:34:22.642191Z",
     "start_time": "2019-10-09T09:34:22.638694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1521787, 56) test (421665, 55)\n"
     ]
    }
   ],
   "source": [
    "print('train',training.shape , 'test', testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:35:05.821687Z",
     "start_time": "2019-10-09T09:35:05.704007Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold , cross_val_score , train_test_split\n",
    "import lightgbm as lig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T07:35:30.438916Z",
     "start_time": "2019-10-10T07:35:30.435793Z"
    }
   },
   "outputs": [],
   "source": [
    "lig_mo = lig.LGBMClassifier(n_estimators=600,reg_alpha=0.3,num_leaves=100,learning_rate=0.1,reg_lambda=0.5,subsample=0.7,is_unbalance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T07:35:31.992482Z",
     "start_time": "2019-10-10T07:35:31.989490Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T07:35:34.382399Z",
     "start_time": "2019-10-10T07:35:33.521959Z"
    }
   },
   "outputs": [],
   "source": [
    "X , tx , Y ,ty = train_test_split(training.drop(['cano','bacno','fraud_ind','txkey','locdt'],axis=1),training['fraud_ind'],test_size=0.3,random_state =1102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ligbm adasyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T22:34:59.349201Z",
     "start_time": "2019-10-10T22:21:23.433380Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of 0's and 1's in the feature Class before oversampling the data\n",
      "0.0    1501432\n",
      "1.0      20355\n",
      "Name: fraud_ind, dtype: int64\n",
      "No. of 0's and 1's in the feature Class After oversampling the data\n",
      "Counter({0.0: 1501432, 1.0: 1495539})\n",
      "Train Time: 5.953677415847778\n",
      "Prediction Time: 5.89621114730835\n",
      "fbeta score_train: 0.7602142057596417\n",
      "recall_score_train: 0.8415827642047454\n",
      "precision_score_train: 0.5482021647404146\n",
      "========================================================\n",
      "Train Time: 5.953677415847778\n",
      "Prediction Time: 5.89621114730835\n",
      "fbeta score: 0.7584938961612002\n",
      "recall_score: 0.8382639791937582\n",
      "precision_score: 0.5493767976989453\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99    450385\n",
      "         1.0       0.55      0.84      0.66      6152\n",
      "\n",
      "    accuracy                           0.99    456537\n",
      "   macro avg       0.77      0.91      0.83    456537\n",
      "weighted avg       0.99      0.99      0.99    456537\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(training.drop(\n",
    "    ['cano', 'bacno', 'txkey', 'locdt', 'fraud_ind'], axis=1),\n",
    "                                                        training['fraud_ind'],\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=112)\n",
    "\n",
    "ad_data = training.drop(['cano', 'bacno', 'txkey', 'locdt'], axis=1)\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class before oversampling the data\")\n",
    "print(ad_data['fraud_ind'].value_counts())\n",
    "\n",
    "X_ad = ad_data.drop('fraud_ind', axis=1)\n",
    "y_ad = ad_data['fraud_ind']\n",
    "start = time()\n",
    "# Oversampling the data using SMOTE\n",
    "\n",
    "X_resampled_ad, y_resampled_ad = ADASYN(\n",
    "    sampling_strategy='minority').fit_sample(X_ad, y_ad)\n",
    "end = time()\n",
    "print(\"No. of 0's and 1's in the feature Class After oversampling the data\")\n",
    "print(Counter(y_resampled_ad))\n",
    "results = {}\n",
    "\n",
    "# Initializng the dictionary to store performance metrics\n",
    "results['ad'] = {}\n",
    "results['ad']['resample_time'] = end - start\n",
    "\n",
    "X_resampled_ad, y_resampled_ad = RandomUnderSampler(sampling_strategy={\n",
    "    1: 200000,\n",
    "    0: 200000\n",
    "}).fit_resample(X_resampled_ad, y_resampled_ad)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled_ad,\n",
    "                                                    y_resampled_ad,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=112)\n",
    "\n",
    "# Training the classifier\n",
    "start = time()\n",
    "clf_ad_BF = lig.LGBMClassifier(n_estimators=300,\n",
    "                               reg_alpha=0.3,\n",
    "                               num_leaves=100,\n",
    "                               max_depth=16,\n",
    "                               learning_rate=0.1,\n",
    "                               reg_lambda=0.5,\n",
    "                               subsample=0.7).fit(X_train, y_train)\n",
    "end = time()\n",
    "results['ad']['train_time'] = end - start\n",
    "\n",
    "# Predict on training set\n",
    "start = time()\n",
    "y_pred_score_ad = clf_ad_BF.predict(X_test1)\n",
    "y_score_ad = clf_ad_BF.predict(X_train1)\n",
    "\n",
    "end = time()\n",
    "results['ad']['pred_time'] = end - start\n",
    "\n",
    "results['ad']['fbeta_train'] = fbeta_score(y_train1, y_score_ad, beta=2)\n",
    "results['ad']['recall_train'] = recall_score(y_train1, y_score_ad)\n",
    "results['ad']['precision_train'] = precision_score(y_train1, y_score_ad)\n",
    "\n",
    "results['ad']['fbeta_test'] = fbeta_score(y_test1, y_pred_score_ad, beta=2)\n",
    "results['ad']['recall_test'] = recall_score(y_test1, y_pred_score_ad)\n",
    "results['ad']['precision_test'] = precision_score(y_test1, y_pred_score_ad)\n",
    "\n",
    "print(\"Train Time:\", results['ad']['train_time'])\n",
    "print(\"Prediction Time:\", results['ad']['pred_time'])\n",
    "print(\"fbeta score_train:\", results['ad']['fbeta_train'])\n",
    "print('recall_score_train:', results['ad']['recall_train'])\n",
    "print('precision_score_train:', results['ad']['precision_train'])\n",
    "\n",
    "print('========================================================')\n",
    "print(\"Train Time:\", results['ad']['train_time'])\n",
    "print(\"Prediction Time:\", results['ad']['pred_time'])\n",
    "print(\"fbeta score:\", results['ad']['fbeta_test'])\n",
    "print('recall_score:', results['ad']['recall_test'])\n",
    "print('precision_score:', results['ad']['precision_test'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test1, y_pred_score_ad))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test1, y_pred_score_ad)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:56:30.858953Z",
     "start_time": "2019-10-11T08:19:30.448745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of 0's and 1's in the feature Class before oversampling the data\n",
      "0.0    1501432\n",
      "1.0      20355\n",
      "Name: fraud_ind, dtype: int64\n",
      "No. of 0's and 1's in the feature Class After oversampling the data\n",
      "Counter({0.0: 1501432, 1.0: 1495539})\n",
      "[1]\ttraining's binary_logloss: 0.613243\ttraining's f1: 0.951647\tvalid_1's binary_logloss: 0.61348\tvalid_1's f1: 0.950616\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's binary_logloss: 0.547802\ttraining's f1: 0.953043\tvalid_1's binary_logloss: 0.548031\tvalid_1's f1: 0.952352\n",
      "[3]\ttraining's binary_logloss: 0.492964\ttraining's f1: 0.95432\tvalid_1's binary_logloss: 0.493371\tvalid_1's f1: 0.952818\n",
      "[4]\ttraining's binary_logloss: 0.446543\ttraining's f1: 0.954227\tvalid_1's binary_logloss: 0.447151\tvalid_1's f1: 0.953153\n",
      "[5]\ttraining's binary_logloss: 0.406572\ttraining's f1: 0.956003\tvalid_1's binary_logloss: 0.407345\tvalid_1's f1: 0.954287\n",
      "[6]\ttraining's binary_logloss: 0.372417\ttraining's f1: 0.956064\tvalid_1's binary_logloss: 0.373339\tvalid_1's f1: 0.954154\n",
      "[7]\ttraining's binary_logloss: 0.342491\ttraining's f1: 0.957266\tvalid_1's binary_logloss: 0.343648\tvalid_1's f1: 0.955355\n",
      "[8]\ttraining's binary_logloss: 0.316318\ttraining's f1: 0.957706\tvalid_1's binary_logloss: 0.317807\tvalid_1's f1: 0.955422\n",
      "[9]\ttraining's binary_logloss: 0.293279\ttraining's f1: 0.958379\tvalid_1's binary_logloss: 0.295015\tvalid_1's f1: 0.956356\n",
      "[10]\ttraining's binary_logloss: 0.273103\ttraining's f1: 0.958732\tvalid_1's binary_logloss: 0.274959\tvalid_1's f1: 0.956957\n",
      "[11]\ttraining's binary_logloss: 0.254647\ttraining's f1: 0.959348\tvalid_1's binary_logloss: 0.256805\tvalid_1's f1: 0.95689\n",
      "[12]\ttraining's binary_logloss: 0.238376\ttraining's f1: 0.959676\tvalid_1's binary_logloss: 0.240703\tvalid_1's f1: 0.957691\n",
      "[13]\ttraining's binary_logloss: 0.223878\ttraining's f1: 0.959946\tvalid_1's binary_logloss: 0.226164\tvalid_1's f1: 0.958225\n",
      "[14]\ttraining's binary_logloss: 0.211118\ttraining's f1: 0.960638\tvalid_1's binary_logloss: 0.213588\tvalid_1's f1: 0.959226\n",
      "[15]\ttraining's binary_logloss: 0.199119\ttraining's f1: 0.961127\tvalid_1's binary_logloss: 0.201705\tvalid_1's f1: 0.959492\n",
      "[16]\ttraining's binary_logloss: 0.188639\ttraining's f1: 0.961516\tvalid_1's binary_logloss: 0.191272\tvalid_1's f1: 0.959893\n",
      "[17]\ttraining's binary_logloss: 0.179153\ttraining's f1: 0.96208\tvalid_1's binary_logloss: 0.181835\tvalid_1's f1: 0.96016\n",
      "[18]\ttraining's binary_logloss: 0.170507\ttraining's f1: 0.96245\tvalid_1's binary_logloss: 0.173111\tvalid_1's f1: 0.960694\n",
      "[19]\ttraining's binary_logloss: 0.162713\ttraining's f1: 0.963369\tvalid_1's binary_logloss: 0.165462\tvalid_1's f1: 0.961561\n",
      "[20]\ttraining's binary_logloss: 0.155583\ttraining's f1: 0.963916\tvalid_1's binary_logloss: 0.158512\tvalid_1's f1: 0.961962\n",
      "[21]\ttraining's binary_logloss: 0.148566\ttraining's f1: 0.964515\tvalid_1's binary_logloss: 0.151576\tvalid_1's f1: 0.963029\n",
      "[22]\ttraining's binary_logloss: 0.142654\ttraining's f1: 0.965353\tvalid_1's binary_logloss: 0.145496\tvalid_1's f1: 0.96363\n",
      "[23]\ttraining's binary_logloss: 0.137152\ttraining's f1: 0.965627\tvalid_1's binary_logloss: 0.140018\tvalid_1's f1: 0.964497\n",
      "[24]\ttraining's binary_logloss: 0.131865\ttraining's f1: 0.966433\tvalid_1's binary_logloss: 0.134631\tvalid_1's f1: 0.965232\n",
      "[25]\ttraining's binary_logloss: 0.126983\ttraining's f1: 0.967088\tvalid_1's binary_logloss: 0.129661\tvalid_1's f1: 0.965899\n",
      "[26]\ttraining's binary_logloss: 0.122948\ttraining's f1: 0.96736\tvalid_1's binary_logloss: 0.125696\tvalid_1's f1: 0.966433\n",
      "[27]\ttraining's binary_logloss: 0.118793\ttraining's f1: 0.967994\tvalid_1's binary_logloss: 0.121606\tvalid_1's f1: 0.966967\n",
      "[28]\ttraining's binary_logloss: 0.114364\ttraining's f1: 0.968475\tvalid_1's binary_logloss: 0.116616\tvalid_1's f1: 0.967701\n",
      "[29]\ttraining's binary_logloss: 0.110802\ttraining's f1: 0.96898\tvalid_1's binary_logloss: 0.113011\tvalid_1's f1: 0.968101\n",
      "[30]\ttraining's binary_logloss: 0.106907\ttraining's f1: 0.969511\tvalid_1's binary_logloss: 0.109154\tvalid_1's f1: 0.968501\n",
      "[31]\ttraining's binary_logloss: 0.103925\ttraining's f1: 0.970046\tvalid_1's binary_logloss: 0.106289\tvalid_1's f1: 0.969236\n",
      "[32]\ttraining's binary_logloss: 0.100611\ttraining's f1: 0.970524\tvalid_1's binary_logloss: 0.102787\tvalid_1's f1: 0.969703\n",
      "[33]\ttraining's binary_logloss: 0.0977583\ttraining's f1: 0.971034\tvalid_1's binary_logloss: 0.0998871\tvalid_1's f1: 0.970103\n",
      "[34]\ttraining's binary_logloss: 0.0949404\ttraining's f1: 0.971525\tvalid_1's binary_logloss: 0.0970646\tvalid_1's f1: 0.970837\n",
      "[35]\ttraining's binary_logloss: 0.0925059\ttraining's f1: 0.971893\tvalid_1's binary_logloss: 0.0946882\tvalid_1's f1: 0.971371\n",
      "[36]\ttraining's binary_logloss: 0.0899238\ttraining's f1: 0.97243\tvalid_1's binary_logloss: 0.0920252\tvalid_1's f1: 0.971371\n",
      "[37]\ttraining's binary_logloss: 0.0877793\ttraining's f1: 0.972837\tvalid_1's binary_logloss: 0.0900032\tvalid_1's f1: 0.971505\n",
      "[38]\ttraining's binary_logloss: 0.0855745\ttraining's f1: 0.973177\tvalid_1's binary_logloss: 0.0877355\tvalid_1's f1: 0.971905\n",
      "[39]\ttraining's binary_logloss: 0.0834034\ttraining's f1: 0.973804\tvalid_1's binary_logloss: 0.0855489\tvalid_1's f1: 0.971972\n",
      "[40]\ttraining's binary_logloss: 0.0812157\ttraining's f1: 0.974464\tvalid_1's binary_logloss: 0.0833552\tvalid_1's f1: 0.972773\n",
      "[41]\ttraining's binary_logloss: 0.0793076\ttraining's f1: 0.974892\tvalid_1's binary_logloss: 0.0815212\tvalid_1's f1: 0.972839\n",
      "[42]\ttraining's binary_logloss: 0.077457\ttraining's f1: 0.975266\tvalid_1's binary_logloss: 0.0795031\tvalid_1's f1: 0.973106\n",
      "[43]\ttraining's binary_logloss: 0.0757053\ttraining's f1: 0.975591\tvalid_1's binary_logloss: 0.0775427\tvalid_1's f1: 0.973507\n",
      "[44]\ttraining's binary_logloss: 0.0740699\ttraining's f1: 0.975986\tvalid_1's binary_logloss: 0.075744\tvalid_1's f1: 0.973907\n",
      "[45]\ttraining's binary_logloss: 0.0725007\ttraining's f1: 0.976306\tvalid_1's binary_logloss: 0.0741488\tvalid_1's f1: 0.974241\n",
      "[46]\ttraining's binary_logloss: 0.0712084\ttraining's f1: 0.976645\tvalid_1's binary_logloss: 0.0729576\tvalid_1's f1: 0.974641\n",
      "[47]\ttraining's binary_logloss: 0.06984\ttraining's f1: 0.976946\tvalid_1's binary_logloss: 0.0714691\tvalid_1's f1: 0.975108\n",
      "[48]\ttraining's binary_logloss: 0.0686833\ttraining's f1: 0.977277\tvalid_1's binary_logloss: 0.0702611\tvalid_1's f1: 0.975308\n",
      "[49]\ttraining's binary_logloss: 0.0674508\ttraining's f1: 0.977651\tvalid_1's binary_logloss: 0.0690402\tvalid_1's f1: 0.976109\n",
      "[50]\ttraining's binary_logloss: 0.0655897\ttraining's f1: 0.978224\tvalid_1's binary_logloss: 0.0672247\tvalid_1's f1: 0.97651\n",
      "[51]\ttraining's binary_logloss: 0.0641437\ttraining's f1: 0.978684\tvalid_1's binary_logloss: 0.0657445\tvalid_1's f1: 0.976576\n",
      "[52]\ttraining's binary_logloss: 0.0630906\ttraining's f1: 0.978943\tvalid_1's binary_logloss: 0.0648185\tvalid_1's f1: 0.977377\n",
      "[53]\ttraining's binary_logloss: 0.0621646\ttraining's f1: 0.979299\tvalid_1's binary_logloss: 0.06385\tvalid_1's f1: 0.978045\n",
      "[54]\ttraining's binary_logloss: 0.0611871\ttraining's f1: 0.979647\tvalid_1's binary_logloss: 0.0629145\tvalid_1's f1: 0.978111\n",
      "[55]\ttraining's binary_logloss: 0.0604192\ttraining's f1: 0.97995\tvalid_1's binary_logloss: 0.0620539\tvalid_1's f1: 0.978312\n",
      "[56]\ttraining's binary_logloss: 0.0594872\ttraining's f1: 0.98025\tvalid_1's binary_logloss: 0.0610962\tvalid_1's f1: 0.978645\n",
      "[57]\ttraining's binary_logloss: 0.0583803\ttraining's f1: 0.980682\tvalid_1's binary_logloss: 0.0601249\tvalid_1's f1: 0.979046\n",
      "[58]\ttraining's binary_logloss: 0.057426\ttraining's f1: 0.980859\tvalid_1's binary_logloss: 0.0591812\tvalid_1's f1: 0.979246\n",
      "[59]\ttraining's binary_logloss: 0.0566335\ttraining's f1: 0.981122\tvalid_1's binary_logloss: 0.0582931\tvalid_1's f1: 0.979446\n",
      "[60]\ttraining's binary_logloss: 0.0557255\ttraining's f1: 0.981595\tvalid_1's binary_logloss: 0.0573324\tvalid_1's f1: 0.980113\n",
      "[61]\ttraining's binary_logloss: 0.0548778\ttraining's f1: 0.981935\tvalid_1's binary_logloss: 0.0564891\tvalid_1's f1: 0.98038\n",
      "[62]\ttraining's binary_logloss: 0.0541709\ttraining's f1: 0.982103\tvalid_1's binary_logloss: 0.0558739\tvalid_1's f1: 0.980514\n",
      "[63]\ttraining's binary_logloss: 0.0533818\ttraining's f1: 0.982458\tvalid_1's binary_logloss: 0.0551995\tvalid_1's f1: 0.981248\n",
      "[64]\ttraining's binary_logloss: 0.0527376\ttraining's f1: 0.982633\tvalid_1's binary_logloss: 0.0546212\tvalid_1's f1: 0.980981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65]\ttraining's binary_logloss: 0.0516076\ttraining's f1: 0.983061\tvalid_1's binary_logloss: 0.0534735\tvalid_1's f1: 0.981515\n",
      "[66]\ttraining's binary_logloss: 0.0506426\ttraining's f1: 0.983455\tvalid_1's binary_logloss: 0.0525752\tvalid_1's f1: 0.982316\n",
      "[67]\ttraining's binary_logloss: 0.0493412\ttraining's f1: 0.984043\tvalid_1's binary_logloss: 0.0512393\tvalid_1's f1: 0.98325\n",
      "[68]\ttraining's binary_logloss: 0.0487704\ttraining's f1: 0.984229\tvalid_1's binary_logloss: 0.0507076\tvalid_1's f1: 0.98325\n",
      "[69]\ttraining's binary_logloss: 0.0478827\ttraining's f1: 0.984522\tvalid_1's binary_logloss: 0.0498129\tvalid_1's f1: 0.983517\n",
      "[70]\ttraining's binary_logloss: 0.0473671\ttraining's f1: 0.984732\tvalid_1's binary_logloss: 0.0493082\tvalid_1's f1: 0.983584\n",
      "[71]\ttraining's binary_logloss: 0.0467746\ttraining's f1: 0.984983\tvalid_1's binary_logloss: 0.0486516\tvalid_1's f1: 0.984051\n",
      "[72]\ttraining's binary_logloss: 0.0462204\ttraining's f1: 0.985257\tvalid_1's binary_logloss: 0.0481001\tvalid_1's f1: 0.984117\n",
      "[73]\ttraining's binary_logloss: 0.0457259\ttraining's f1: 0.985483\tvalid_1's binary_logloss: 0.0475485\tvalid_1's f1: 0.984585\n",
      "[74]\ttraining's binary_logloss: 0.0452598\ttraining's f1: 0.985626\tvalid_1's binary_logloss: 0.0470695\tvalid_1's f1: 0.984651\n",
      "[75]\ttraining's binary_logloss: 0.0444545\ttraining's f1: 0.985905\tvalid_1's binary_logloss: 0.0462975\tvalid_1's f1: 0.984985\n",
      "[76]\ttraining's binary_logloss: 0.0435342\ttraining's f1: 0.986191\tvalid_1's binary_logloss: 0.0454388\tvalid_1's f1: 0.985319\n",
      "[77]\ttraining's binary_logloss: 0.0428571\ttraining's f1: 0.986412\tvalid_1's binary_logloss: 0.0447162\tvalid_1's f1: 0.985519\n",
      "[78]\ttraining's binary_logloss: 0.0424553\ttraining's f1: 0.986634\tvalid_1's binary_logloss: 0.0443647\tvalid_1's f1: 0.985586\n",
      "[79]\ttraining's binary_logloss: 0.0420119\ttraining's f1: 0.986809\tvalid_1's binary_logloss: 0.0439011\tvalid_1's f1: 0.985652\n",
      "[80]\ttraining's binary_logloss: 0.0416272\ttraining's f1: 0.986915\tvalid_1's binary_logloss: 0.0434924\tvalid_1's f1: 0.985586\n",
      "[81]\ttraining's binary_logloss: 0.0411269\ttraining's f1: 0.987146\tvalid_1's binary_logloss: 0.0430297\tvalid_1's f1: 0.985919\n",
      "[82]\ttraining's binary_logloss: 0.0406881\ttraining's f1: 0.987277\tvalid_1's binary_logloss: 0.0425769\tvalid_1's f1: 0.985919\n",
      "[83]\ttraining's binary_logloss: 0.0402322\ttraining's f1: 0.987498\tvalid_1's binary_logloss: 0.0420435\tvalid_1's f1: 0.986053\n",
      "[84]\ttraining's binary_logloss: 0.0396372\ttraining's f1: 0.987711\tvalid_1's binary_logloss: 0.0414525\tvalid_1's f1: 0.986119\n",
      "[85]\ttraining's binary_logloss: 0.039193\ttraining's f1: 0.98789\tvalid_1's binary_logloss: 0.0410222\tvalid_1's f1: 0.986253\n",
      "[86]\ttraining's binary_logloss: 0.0388146\ttraining's f1: 0.988036\tvalid_1's binary_logloss: 0.0405961\tvalid_1's f1: 0.98652\n",
      "[87]\ttraining's binary_logloss: 0.0385068\ttraining's f1: 0.988216\tvalid_1's binary_logloss: 0.040279\tvalid_1's f1: 0.986854\n",
      "[88]\ttraining's binary_logloss: 0.038219\ttraining's f1: 0.988321\tvalid_1's binary_logloss: 0.0400178\tvalid_1's f1: 0.986787\n",
      "[89]\ttraining's binary_logloss: 0.0379643\ttraining's f1: 0.988418\tvalid_1's binary_logloss: 0.0397918\tvalid_1's f1: 0.986854\n",
      "[90]\ttraining's binary_logloss: 0.0376158\ttraining's f1: 0.98854\tvalid_1's binary_logloss: 0.0394892\tvalid_1's f1: 0.98692\n",
      "[91]\ttraining's binary_logloss: 0.0372575\ttraining's f1: 0.988639\tvalid_1's binary_logloss: 0.0391115\tvalid_1's f1: 0.987054\n",
      "[92]\ttraining's binary_logloss: 0.0367233\ttraining's f1: 0.988836\tvalid_1's binary_logloss: 0.038588\tvalid_1's f1: 0.987054\n",
      "[93]\ttraining's binary_logloss: 0.0364479\ttraining's f1: 0.988904\tvalid_1's binary_logloss: 0.0383228\tvalid_1's f1: 0.986987\n",
      "[94]\ttraining's binary_logloss: 0.0360029\ttraining's f1: 0.989069\tvalid_1's binary_logloss: 0.0378772\tvalid_1's f1: 0.98712\n",
      "[95]\ttraining's binary_logloss: 0.0356192\ttraining's f1: 0.98924\tvalid_1's binary_logloss: 0.0375311\tvalid_1's f1: 0.987321\n",
      "[96]\ttraining's binary_logloss: 0.0353162\ttraining's f1: 0.989363\tvalid_1's binary_logloss: 0.0372375\tvalid_1's f1: 0.987321\n",
      "[97]\ttraining's binary_logloss: 0.0350271\ttraining's f1: 0.989515\tvalid_1's binary_logloss: 0.0369138\tvalid_1's f1: 0.987588\n",
      "[98]\ttraining's binary_logloss: 0.0346653\ttraining's f1: 0.989688\tvalid_1's binary_logloss: 0.0365723\tvalid_1's f1: 0.987788\n",
      "[99]\ttraining's binary_logloss: 0.0343994\ttraining's f1: 0.9898\tvalid_1's binary_logloss: 0.0362491\tvalid_1's f1: 0.988121\n",
      "[100]\ttraining's binary_logloss: 0.034158\ttraining's f1: 0.989896\tvalid_1's binary_logloss: 0.0359401\tvalid_1's f1: 0.988255\n",
      "[101]\ttraining's binary_logloss: 0.0338718\ttraining's f1: 0.990037\tvalid_1's binary_logloss: 0.0356687\tvalid_1's f1: 0.988322\n",
      "[102]\ttraining's binary_logloss: 0.0336105\ttraining's f1: 0.99014\tvalid_1's binary_logloss: 0.0354496\tvalid_1's f1: 0.988188\n",
      "[103]\ttraining's binary_logloss: 0.0332888\ttraining's f1: 0.990277\tvalid_1's binary_logloss: 0.0351466\tvalid_1's f1: 0.988255\n",
      "[104]\ttraining's binary_logloss: 0.033008\ttraining's f1: 0.990387\tvalid_1's binary_logloss: 0.0348664\tvalid_1's f1: 0.988522\n",
      "[105]\ttraining's binary_logloss: 0.0327646\ttraining's f1: 0.990476\tvalid_1's binary_logloss: 0.0346714\tvalid_1's f1: 0.988789\n",
      "[106]\ttraining's binary_logloss: 0.0323124\ttraining's f1: 0.990683\tvalid_1's binary_logloss: 0.0342434\tvalid_1's f1: 0.988856\n",
      "[107]\ttraining's binary_logloss: 0.0319833\ttraining's f1: 0.990826\tvalid_1's binary_logloss: 0.0338383\tvalid_1's f1: 0.989256\n",
      "[108]\ttraining's binary_logloss: 0.0317143\ttraining's f1: 0.99092\tvalid_1's binary_logloss: 0.0335468\tvalid_1's f1: 0.989189\n",
      "[109]\ttraining's binary_logloss: 0.0314228\ttraining's f1: 0.991037\tvalid_1's binary_logloss: 0.0332664\tvalid_1's f1: 0.989456\n",
      "[110]\ttraining's binary_logloss: 0.0310775\ttraining's f1: 0.991165\tvalid_1's binary_logloss: 0.0329418\tvalid_1's f1: 0.989389\n",
      "[111]\ttraining's binary_logloss: 0.0308557\ttraining's f1: 0.991239\tvalid_1's binary_logloss: 0.0327389\tvalid_1's f1: 0.98959\n",
      "[112]\ttraining's binary_logloss: 0.0306135\ttraining's f1: 0.991287\tvalid_1's binary_logloss: 0.0325041\tvalid_1's f1: 0.989723\n",
      "[113]\ttraining's binary_logloss: 0.0303773\ttraining's f1: 0.991425\tvalid_1's binary_logloss: 0.032275\tvalid_1's f1: 0.990057\n",
      "[114]\ttraining's binary_logloss: 0.0301805\ttraining's f1: 0.991519\tvalid_1's binary_logloss: 0.0320862\tvalid_1's f1: 0.990257\n",
      "[115]\ttraining's binary_logloss: 0.0299652\ttraining's f1: 0.991591\tvalid_1's binary_logloss: 0.0318192\tvalid_1's f1: 0.99019\n",
      "[116]\ttraining's binary_logloss: 0.0296953\ttraining's f1: 0.991709\tvalid_1's binary_logloss: 0.0315803\tvalid_1's f1: 0.99019\n",
      "[117]\ttraining's binary_logloss: 0.029514\ttraining's f1: 0.991798\tvalid_1's binary_logloss: 0.0313789\tvalid_1's f1: 0.99019\n",
      "[118]\ttraining's binary_logloss: 0.029304\ttraining's f1: 0.991877\tvalid_1's binary_logloss: 0.0311839\tvalid_1's f1: 0.990524\n",
      "[119]\ttraining's binary_logloss: 0.0291408\ttraining's f1: 0.991959\tvalid_1's binary_logloss: 0.0309961\tvalid_1's f1: 0.990657\n",
      "[120]\ttraining's binary_logloss: 0.0289357\ttraining's f1: 0.992033\tvalid_1's binary_logloss: 0.0307696\tvalid_1's f1: 0.990724\n",
      "[121]\ttraining's binary_logloss: 0.0287161\ttraining's f1: 0.992117\tvalid_1's binary_logloss: 0.0305802\tvalid_1's f1: 0.990724\n",
      "[122]\ttraining's binary_logloss: 0.028558\ttraining's f1: 0.992175\tvalid_1's binary_logloss: 0.0304226\tvalid_1's f1: 0.991058\n",
      "[123]\ttraining's binary_logloss: 0.0284067\ttraining's f1: 0.992246\tvalid_1's binary_logloss: 0.0302933\tvalid_1's f1: 0.991191\n",
      "[124]\ttraining's binary_logloss: 0.0281829\ttraining's f1: 0.992325\tvalid_1's binary_logloss: 0.0300272\tvalid_1's f1: 0.991191\n",
      "[125]\ttraining's binary_logloss: 0.0279426\ttraining's f1: 0.992454\tvalid_1's binary_logloss: 0.0297812\tvalid_1's f1: 0.991325\n",
      "[126]\ttraining's binary_logloss: 0.0276944\ttraining's f1: 0.992545\tvalid_1's binary_logloss: 0.0295668\tvalid_1's f1: 0.991325\n",
      "[127]\ttraining's binary_logloss: 0.0274787\ttraining's f1: 0.992615\tvalid_1's binary_logloss: 0.0293325\tvalid_1's f1: 0.991525\n",
      "[128]\ttraining's binary_logloss: 0.0272962\ttraining's f1: 0.992681\tvalid_1's binary_logloss: 0.0291349\tvalid_1's f1: 0.991725\n",
      "[129]\ttraining's binary_logloss: 0.0271246\ttraining's f1: 0.992732\tvalid_1's binary_logloss: 0.0289705\tvalid_1's f1: 0.991859\n",
      "[130]\ttraining's binary_logloss: 0.0269168\ttraining's f1: 0.992819\tvalid_1's binary_logloss: 0.0287632\tvalid_1's f1: 0.991925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131]\ttraining's binary_logloss: 0.026759\ttraining's f1: 0.992902\tvalid_1's binary_logloss: 0.0285806\tvalid_1's f1: 0.991992\n",
      "[132]\ttraining's binary_logloss: 0.0266101\ttraining's f1: 0.992969\tvalid_1's binary_logloss: 0.028487\tvalid_1's f1: 0.991925\n",
      "[133]\ttraining's binary_logloss: 0.0264139\ttraining's f1: 0.993051\tvalid_1's binary_logloss: 0.0282749\tvalid_1's f1: 0.991859\n",
      "[134]\ttraining's binary_logloss: 0.0262274\ttraining's f1: 0.993125\tvalid_1's binary_logloss: 0.0281131\tvalid_1's f1: 0.991925\n",
      "[135]\ttraining's binary_logloss: 0.0260301\ttraining's f1: 0.993236\tvalid_1's binary_logloss: 0.0279234\tvalid_1's f1: 0.992125\n",
      "[136]\ttraining's binary_logloss: 0.0259126\ttraining's f1: 0.993279\tvalid_1's binary_logloss: 0.0277867\tvalid_1's f1: 0.992259\n",
      "[137]\ttraining's binary_logloss: 0.025729\ttraining's f1: 0.993344\tvalid_1's binary_logloss: 0.0275965\tvalid_1's f1: 0.992259\n",
      "[138]\ttraining's binary_logloss: 0.0256031\ttraining's f1: 0.993407\tvalid_1's binary_logloss: 0.0274441\tvalid_1's f1: 0.992326\n",
      "[139]\ttraining's binary_logloss: 0.0254497\ttraining's f1: 0.993476\tvalid_1's binary_logloss: 0.0273123\tvalid_1's f1: 0.992392\n",
      "[140]\ttraining's binary_logloss: 0.0253127\ttraining's f1: 0.993535\tvalid_1's binary_logloss: 0.0271855\tvalid_1's f1: 0.992326\n",
      "[141]\ttraining's binary_logloss: 0.0251779\ttraining's f1: 0.993594\tvalid_1's binary_logloss: 0.0270672\tvalid_1's f1: 0.992459\n",
      "[142]\ttraining's binary_logloss: 0.0249716\ttraining's f1: 0.993662\tvalid_1's binary_logloss: 0.0268959\tvalid_1's f1: 0.992593\n",
      "[143]\ttraining's binary_logloss: 0.0248424\ttraining's f1: 0.993716\tvalid_1's binary_logloss: 0.0267589\tvalid_1's f1: 0.992659\n",
      "[144]\ttraining's binary_logloss: 0.0247283\ttraining's f1: 0.993755\tvalid_1's binary_logloss: 0.0266442\tvalid_1's f1: 0.992659\n",
      "[145]\ttraining's binary_logloss: 0.0246162\ttraining's f1: 0.993795\tvalid_1's binary_logloss: 0.0265272\tvalid_1's f1: 0.99286\n",
      "[146]\ttraining's binary_logloss: 0.0244503\ttraining's f1: 0.99388\tvalid_1's binary_logloss: 0.0263136\tvalid_1's f1: 0.992793\n",
      "[147]\ttraining's binary_logloss: 0.0242033\ttraining's f1: 0.993968\tvalid_1's binary_logloss: 0.0260689\tvalid_1's f1: 0.992793\n",
      "[148]\ttraining's binary_logloss: 0.0240763\ttraining's f1: 0.99401\tvalid_1's binary_logloss: 0.0259678\tvalid_1's f1: 0.99286\n",
      "[149]\ttraining's binary_logloss: 0.0239792\ttraining's f1: 0.994049\tvalid_1's binary_logloss: 0.0258651\tvalid_1's f1: 0.992926\n",
      "[150]\ttraining's binary_logloss: 0.0238174\ttraining's f1: 0.994121\tvalid_1's binary_logloss: 0.0256814\tvalid_1's f1: 0.992926\n",
      "[151]\ttraining's binary_logloss: 0.0235909\ttraining's f1: 0.994201\tvalid_1's binary_logloss: 0.0254676\tvalid_1's f1: 0.992993\n",
      "[152]\ttraining's binary_logloss: 0.0233741\ttraining's f1: 0.994304\tvalid_1's binary_logloss: 0.025268\tvalid_1's f1: 0.993193\n",
      "[153]\ttraining's binary_logloss: 0.023234\ttraining's f1: 0.994329\tvalid_1's binary_logloss: 0.025128\tvalid_1's f1: 0.993193\n",
      "[154]\ttraining's binary_logloss: 0.0231132\ttraining's f1: 0.994384\tvalid_1's binary_logloss: 0.0249987\tvalid_1's f1: 0.99326\n",
      "[155]\ttraining's binary_logloss: 0.022993\ttraining's f1: 0.994429\tvalid_1's binary_logloss: 0.0248625\tvalid_1's f1: 0.99326\n",
      "[156]\ttraining's binary_logloss: 0.0228827\ttraining's f1: 0.994479\tvalid_1's binary_logloss: 0.0247459\tvalid_1's f1: 0.993393\n",
      "[157]\ttraining's binary_logloss: 0.0227532\ttraining's f1: 0.994523\tvalid_1's binary_logloss: 0.0246241\tvalid_1's f1: 0.993527\n",
      "[158]\ttraining's binary_logloss: 0.0226377\ttraining's f1: 0.994544\tvalid_1's binary_logloss: 0.0244844\tvalid_1's f1: 0.993527\n",
      "[159]\ttraining's binary_logloss: 0.022526\ttraining's f1: 0.994586\tvalid_1's binary_logloss: 0.0243815\tvalid_1's f1: 0.993594\n",
      "[160]\ttraining's binary_logloss: 0.0224277\ttraining's f1: 0.994616\tvalid_1's binary_logloss: 0.0242962\tvalid_1's f1: 0.993594\n",
      "[161]\ttraining's binary_logloss: 0.0222281\ttraining's f1: 0.994681\tvalid_1's binary_logloss: 0.0241227\tvalid_1's f1: 0.993794\n",
      "[162]\ttraining's binary_logloss: 0.022132\ttraining's f1: 0.994705\tvalid_1's binary_logloss: 0.0240121\tvalid_1's f1: 0.993927\n",
      "[163]\ttraining's binary_logloss: 0.0220199\ttraining's f1: 0.994737\tvalid_1's binary_logloss: 0.0239171\tvalid_1's f1: 0.993994\n",
      "[164]\ttraining's binary_logloss: 0.0218862\ttraining's f1: 0.994767\tvalid_1's binary_logloss: 0.0237811\tvalid_1's f1: 0.993994\n",
      "[165]\ttraining's binary_logloss: 0.0217604\ttraining's f1: 0.994817\tvalid_1's binary_logloss: 0.0236382\tvalid_1's f1: 0.993927\n",
      "[166]\ttraining's binary_logloss: 0.0216263\ttraining's f1: 0.994859\tvalid_1's binary_logloss: 0.0234734\tvalid_1's f1: 0.994061\n",
      "[167]\ttraining's binary_logloss: 0.0215213\ttraining's f1: 0.994883\tvalid_1's binary_logloss: 0.0233504\tvalid_1's f1: 0.994127\n",
      "[168]\ttraining's binary_logloss: 0.0214166\ttraining's f1: 0.994908\tvalid_1's binary_logloss: 0.0232406\tvalid_1's f1: 0.994194\n",
      "[169]\ttraining's binary_logloss: 0.0212914\ttraining's f1: 0.994955\tvalid_1's binary_logloss: 0.0230963\tvalid_1's f1: 0.994394\n",
      "[170]\ttraining's binary_logloss: 0.0212018\ttraining's f1: 0.994985\tvalid_1's binary_logloss: 0.0229955\tvalid_1's f1: 0.994461\n",
      "[171]\ttraining's binary_logloss: 0.0210746\ttraining's f1: 0.995033\tvalid_1's binary_logloss: 0.0229313\tvalid_1's f1: 0.994461\n",
      "[172]\ttraining's binary_logloss: 0.0209471\ttraining's f1: 0.995101\tvalid_1's binary_logloss: 0.0227976\tvalid_1's f1: 0.994461\n",
      "[173]\ttraining's binary_logloss: 0.0208571\ttraining's f1: 0.995134\tvalid_1's binary_logloss: 0.0227338\tvalid_1's f1: 0.994461\n",
      "[174]\ttraining's binary_logloss: 0.0207695\ttraining's f1: 0.995147\tvalid_1's binary_logloss: 0.0226783\tvalid_1's f1: 0.994394\n",
      "[175]\ttraining's binary_logloss: 0.0206679\ttraining's f1: 0.995185\tvalid_1's binary_logloss: 0.0225805\tvalid_1's f1: 0.994595\n",
      "[176]\ttraining's binary_logloss: 0.0205749\ttraining's f1: 0.99521\tvalid_1's binary_logloss: 0.0225063\tvalid_1's f1: 0.994595\n",
      "[177]\ttraining's binary_logloss: 0.0204935\ttraining's f1: 0.995234\tvalid_1's binary_logloss: 0.0224123\tvalid_1's f1: 0.994528\n",
      "[178]\ttraining's binary_logloss: 0.0203834\ttraining's f1: 0.995279\tvalid_1's binary_logloss: 0.0223343\tvalid_1's f1: 0.994528\n",
      "[179]\ttraining's binary_logloss: 0.0202852\ttraining's f1: 0.995303\tvalid_1's binary_logloss: 0.0222246\tvalid_1's f1: 0.994528\n",
      "[180]\ttraining's binary_logloss: 0.0201809\ttraining's f1: 0.995331\tvalid_1's binary_logloss: 0.0220858\tvalid_1's f1: 0.994528\n",
      "[181]\ttraining's binary_logloss: 0.0200962\ttraining's f1: 0.995366\tvalid_1's binary_logloss: 0.0220248\tvalid_1's f1: 0.994595\n",
      "[182]\ttraining's binary_logloss: 0.0200198\ttraining's f1: 0.995387\tvalid_1's binary_logloss: 0.0219527\tvalid_1's f1: 0.994461\n",
      "[183]\ttraining's binary_logloss: 0.0199424\ttraining's f1: 0.995409\tvalid_1's binary_logloss: 0.0218882\tvalid_1's f1: 0.994461\n",
      "[184]\ttraining's binary_logloss: 0.0198228\ttraining's f1: 0.995442\tvalid_1's binary_logloss: 0.0217858\tvalid_1's f1: 0.994461\n",
      "[185]\ttraining's binary_logloss: 0.0197034\ttraining's f1: 0.995474\tvalid_1's binary_logloss: 0.021661\tvalid_1's f1: 0.994528\n",
      "[186]\ttraining's binary_logloss: 0.0196076\ttraining's f1: 0.995499\tvalid_1's binary_logloss: 0.0215783\tvalid_1's f1: 0.994461\n",
      "[187]\ttraining's binary_logloss: 0.0195421\ttraining's f1: 0.995534\tvalid_1's binary_logloss: 0.021504\tvalid_1's f1: 0.994528\n",
      "[188]\ttraining's binary_logloss: 0.0194639\ttraining's f1: 0.995557\tvalid_1's binary_logloss: 0.0214254\tvalid_1's f1: 0.994595\n",
      "[189]\ttraining's binary_logloss: 0.0193794\ttraining's f1: 0.995589\tvalid_1's binary_logloss: 0.0213312\tvalid_1's f1: 0.994661\n",
      "[190]\ttraining's binary_logloss: 0.0192993\ttraining's f1: 0.995613\tvalid_1's binary_logloss: 0.0212389\tvalid_1's f1: 0.994661\n",
      "[191]\ttraining's binary_logloss: 0.0192199\ttraining's f1: 0.995618\tvalid_1's binary_logloss: 0.0211504\tvalid_1's f1: 0.994661\n",
      "[192]\ttraining's binary_logloss: 0.0191047\ttraining's f1: 0.99565\tvalid_1's binary_logloss: 0.0209833\tvalid_1's f1: 0.994661\n",
      "[193]\ttraining's binary_logloss: 0.0190289\ttraining's f1: 0.995669\tvalid_1's binary_logloss: 0.0209088\tvalid_1's f1: 0.994595\n",
      "[194]\ttraining's binary_logloss: 0.0189589\ttraining's f1: 0.995695\tvalid_1's binary_logloss: 0.0208514\tvalid_1's f1: 0.994661\n",
      "[195]\ttraining's binary_logloss: 0.0188689\ttraining's f1: 0.99572\tvalid_1's binary_logloss: 0.0207592\tvalid_1's f1: 0.994595\n",
      "[196]\ttraining's binary_logloss: 0.0187985\ttraining's f1: 0.995741\tvalid_1's binary_logloss: 0.0207006\tvalid_1's f1: 0.994595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197]\ttraining's binary_logloss: 0.0187199\ttraining's f1: 0.995766\tvalid_1's binary_logloss: 0.0206303\tvalid_1's f1: 0.994661\n",
      "[198]\ttraining's binary_logloss: 0.0186429\ttraining's f1: 0.995787\tvalid_1's binary_logloss: 0.0205584\tvalid_1's f1: 0.994728\n",
      "[199]\ttraining's binary_logloss: 0.0185676\ttraining's f1: 0.995803\tvalid_1's binary_logloss: 0.0204834\tvalid_1's f1: 0.994728\n",
      "[200]\ttraining's binary_logloss: 0.0185089\ttraining's f1: 0.995823\tvalid_1's binary_logloss: 0.0204266\tvalid_1's f1: 0.994728\n",
      "[201]\ttraining's binary_logloss: 0.0184225\ttraining's f1: 0.995857\tvalid_1's binary_logloss: 0.0203371\tvalid_1's f1: 0.994861\n",
      "[202]\ttraining's binary_logloss: 0.0183477\ttraining's f1: 0.995877\tvalid_1's binary_logloss: 0.0202737\tvalid_1's f1: 0.994861\n",
      "[203]\ttraining's binary_logloss: 0.0182506\ttraining's f1: 0.995909\tvalid_1's binary_logloss: 0.0201858\tvalid_1's f1: 0.994928\n",
      "[204]\ttraining's binary_logloss: 0.0181833\ttraining's f1: 0.995916\tvalid_1's binary_logloss: 0.020117\tvalid_1's f1: 0.994928\n",
      "[205]\ttraining's binary_logloss: 0.0181313\ttraining's f1: 0.995931\tvalid_1's binary_logloss: 0.0200654\tvalid_1's f1: 0.994928\n",
      "[206]\ttraining's binary_logloss: 0.0180572\ttraining's f1: 0.995955\tvalid_1's binary_logloss: 0.0199702\tvalid_1's f1: 0.994928\n",
      "[207]\ttraining's binary_logloss: 0.0179933\ttraining's f1: 0.995973\tvalid_1's binary_logloss: 0.0199292\tvalid_1's f1: 0.994995\n",
      "[208]\ttraining's binary_logloss: 0.0179379\ttraining's f1: 0.995991\tvalid_1's binary_logloss: 0.0199021\tvalid_1's f1: 0.994995\n",
      "[209]\ttraining's binary_logloss: 0.0178655\ttraining's f1: 0.996036\tvalid_1's binary_logloss: 0.0198265\tvalid_1's f1: 0.995128\n",
      "[210]\ttraining's binary_logloss: 0.0177927\ttraining's f1: 0.996049\tvalid_1's binary_logloss: 0.019764\tvalid_1's f1: 0.995128\n",
      "[211]\ttraining's binary_logloss: 0.017719\ttraining's f1: 0.996067\tvalid_1's binary_logloss: 0.0196735\tvalid_1's f1: 0.995128\n",
      "[212]\ttraining's binary_logloss: 0.017666\ttraining's f1: 0.996083\tvalid_1's binary_logloss: 0.0196299\tvalid_1's f1: 0.995128\n",
      "[213]\ttraining's binary_logloss: 0.0175657\ttraining's f1: 0.996102\tvalid_1's binary_logloss: 0.0195428\tvalid_1's f1: 0.995128\n",
      "[214]\ttraining's binary_logloss: 0.0175182\ttraining's f1: 0.996111\tvalid_1's binary_logloss: 0.0194946\tvalid_1's f1: 0.995195\n",
      "[215]\ttraining's binary_logloss: 0.0174603\ttraining's f1: 0.996118\tvalid_1's binary_logloss: 0.0194325\tvalid_1's f1: 0.995195\n",
      "[216]\ttraining's binary_logloss: 0.0174174\ttraining's f1: 0.996124\tvalid_1's binary_logloss: 0.0193924\tvalid_1's f1: 0.995195\n",
      "[217]\ttraining's binary_logloss: 0.0173092\ttraining's f1: 0.996159\tvalid_1's binary_logloss: 0.0193179\tvalid_1's f1: 0.995262\n",
      "[218]\ttraining's binary_logloss: 0.0172532\ttraining's f1: 0.996173\tvalid_1's binary_logloss: 0.0192819\tvalid_1's f1: 0.995262\n",
      "[219]\ttraining's binary_logloss: 0.0172067\ttraining's f1: 0.996187\tvalid_1's binary_logloss: 0.0192348\tvalid_1's f1: 0.995262\n",
      "[220]\ttraining's binary_logloss: 0.0171442\ttraining's f1: 0.996205\tvalid_1's binary_logloss: 0.0191837\tvalid_1's f1: 0.995329\n",
      "[221]\ttraining's binary_logloss: 0.0170997\ttraining's f1: 0.996213\tvalid_1's binary_logloss: 0.0191382\tvalid_1's f1: 0.995529\n",
      "[222]\ttraining's binary_logloss: 0.0170334\ttraining's f1: 0.996228\tvalid_1's binary_logloss: 0.0190733\tvalid_1's f1: 0.995462\n",
      "[223]\ttraining's binary_logloss: 0.0169809\ttraining's f1: 0.996245\tvalid_1's binary_logloss: 0.0190226\tvalid_1's f1: 0.995462\n",
      "[224]\ttraining's binary_logloss: 0.0169278\ttraining's f1: 0.996256\tvalid_1's binary_logloss: 0.0189897\tvalid_1's f1: 0.995529\n",
      "[225]\ttraining's binary_logloss: 0.0168596\ttraining's f1: 0.996263\tvalid_1's binary_logloss: 0.0189359\tvalid_1's f1: 0.995462\n",
      "[226]\ttraining's binary_logloss: 0.0167895\ttraining's f1: 0.996283\tvalid_1's binary_logloss: 0.0188785\tvalid_1's f1: 0.995462\n",
      "[227]\ttraining's binary_logloss: 0.0167073\ttraining's f1: 0.996309\tvalid_1's binary_logloss: 0.0188138\tvalid_1's f1: 0.995462\n",
      "[228]\ttraining's binary_logloss: 0.016646\ttraining's f1: 0.996322\tvalid_1's binary_logloss: 0.0187757\tvalid_1's f1: 0.995395\n",
      "[229]\ttraining's binary_logloss: 0.0165835\ttraining's f1: 0.996346\tvalid_1's binary_logloss: 0.0187\tvalid_1's f1: 0.995395\n",
      "[230]\ttraining's binary_logloss: 0.0165246\ttraining's f1: 0.996358\tvalid_1's binary_logloss: 0.01865\tvalid_1's f1: 0.995329\n",
      "[231]\ttraining's binary_logloss: 0.0164351\ttraining's f1: 0.996381\tvalid_1's binary_logloss: 0.0185223\tvalid_1's f1: 0.995462\n",
      "[232]\ttraining's binary_logloss: 0.0163943\ttraining's f1: 0.996393\tvalid_1's binary_logloss: 0.0184933\tvalid_1's f1: 0.995462\n",
      "[233]\ttraining's binary_logloss: 0.0162644\ttraining's f1: 0.996428\tvalid_1's binary_logloss: 0.0183856\tvalid_1's f1: 0.995462\n",
      "[234]\ttraining's binary_logloss: 0.0161995\ttraining's f1: 0.996449\tvalid_1's binary_logloss: 0.0183328\tvalid_1's f1: 0.995462\n",
      "[235]\ttraining's binary_logloss: 0.0161271\ttraining's f1: 0.996461\tvalid_1's binary_logloss: 0.0182936\tvalid_1's f1: 0.995462\n",
      "[236]\ttraining's binary_logloss: 0.0160749\ttraining's f1: 0.996488\tvalid_1's binary_logloss: 0.0182608\tvalid_1's f1: 0.995462\n",
      "[237]\ttraining's binary_logloss: 0.0160252\ttraining's f1: 0.996504\tvalid_1's binary_logloss: 0.0181932\tvalid_1's f1: 0.995462\n",
      "[238]\ttraining's binary_logloss: 0.0159737\ttraining's f1: 0.996512\tvalid_1's binary_logloss: 0.0181356\tvalid_1's f1: 0.995462\n",
      "[239]\ttraining's binary_logloss: 0.0159194\ttraining's f1: 0.996538\tvalid_1's binary_logloss: 0.0180801\tvalid_1's f1: 0.995529\n",
      "[240]\ttraining's binary_logloss: 0.0158678\ttraining's f1: 0.996548\tvalid_1's binary_logloss: 0.0180313\tvalid_1's f1: 0.995529\n",
      "[241]\ttraining's binary_logloss: 0.0158329\ttraining's f1: 0.99656\tvalid_1's binary_logloss: 0.0180162\tvalid_1's f1: 0.995529\n",
      "[242]\ttraining's binary_logloss: 0.0157935\ttraining's f1: 0.996573\tvalid_1's binary_logloss: 0.018006\tvalid_1's f1: 0.995462\n",
      "[243]\ttraining's binary_logloss: 0.0157366\ttraining's f1: 0.996591\tvalid_1's binary_logloss: 0.0179338\tvalid_1's f1: 0.995462\n",
      "[244]\ttraining's binary_logloss: 0.0156605\ttraining's f1: 0.996609\tvalid_1's binary_logloss: 0.0178732\tvalid_1's f1: 0.995462\n",
      "[245]\ttraining's binary_logloss: 0.0155942\ttraining's f1: 0.996629\tvalid_1's binary_logloss: 0.0177952\tvalid_1's f1: 0.995529\n",
      "[246]\ttraining's binary_logloss: 0.0155569\ttraining's f1: 0.996639\tvalid_1's binary_logloss: 0.0177649\tvalid_1's f1: 0.995529\n",
      "[247]\ttraining's binary_logloss: 0.015504\ttraining's f1: 0.996659\tvalid_1's binary_logloss: 0.0177062\tvalid_1's f1: 0.995596\n",
      "[248]\ttraining's binary_logloss: 0.0154563\ttraining's f1: 0.99666\tvalid_1's binary_logloss: 0.017653\tvalid_1's f1: 0.995596\n",
      "[249]\ttraining's binary_logloss: 0.0154248\ttraining's f1: 0.996668\tvalid_1's binary_logloss: 0.0176147\tvalid_1's f1: 0.995596\n",
      "[250]\ttraining's binary_logloss: 0.0153574\ttraining's f1: 0.996686\tvalid_1's binary_logloss: 0.0175605\tvalid_1's f1: 0.995596\n",
      "[251]\ttraining's binary_logloss: 0.0153185\ttraining's f1: 0.996697\tvalid_1's binary_logloss: 0.0175164\tvalid_1's f1: 0.995596\n",
      "[252]\ttraining's binary_logloss: 0.0152689\ttraining's f1: 0.996709\tvalid_1's binary_logloss: 0.0174858\tvalid_1's f1: 0.995662\n",
      "[253]\ttraining's binary_logloss: 0.0152248\ttraining's f1: 0.996714\tvalid_1's binary_logloss: 0.0174568\tvalid_1's f1: 0.995662\n",
      "[254]\ttraining's binary_logloss: 0.0151682\ttraining's f1: 0.996731\tvalid_1's binary_logloss: 0.01741\tvalid_1's f1: 0.995662\n",
      "[255]\ttraining's binary_logloss: 0.0151272\ttraining's f1: 0.99674\tvalid_1's binary_logloss: 0.017382\tvalid_1's f1: 0.995662\n",
      "[256]\ttraining's binary_logloss: 0.0150871\ttraining's f1: 0.99676\tvalid_1's binary_logloss: 0.0173315\tvalid_1's f1: 0.995662\n",
      "[257]\ttraining's binary_logloss: 0.015047\ttraining's f1: 0.996766\tvalid_1's binary_logloss: 0.0172855\tvalid_1's f1: 0.995662\n",
      "[258]\ttraining's binary_logloss: 0.0150015\ttraining's f1: 0.996775\tvalid_1's binary_logloss: 0.0172233\tvalid_1's f1: 0.995729\n",
      "[259]\ttraining's binary_logloss: 0.0149543\ttraining's f1: 0.996788\tvalid_1's binary_logloss: 0.0171994\tvalid_1's f1: 0.995729\n",
      "[260]\ttraining's binary_logloss: 0.0149027\ttraining's f1: 0.996802\tvalid_1's binary_logloss: 0.0171437\tvalid_1's f1: 0.995729\n",
      "[261]\ttraining's binary_logloss: 0.0148588\ttraining's f1: 0.996815\tvalid_1's binary_logloss: 0.017087\tvalid_1's f1: 0.995729\n",
      "[262]\ttraining's binary_logloss: 0.0147992\ttraining's f1: 0.996824\tvalid_1's binary_logloss: 0.0170461\tvalid_1's f1: 0.995662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[263]\ttraining's binary_logloss: 0.0147662\ttraining's f1: 0.996831\tvalid_1's binary_logloss: 0.0170233\tvalid_1's f1: 0.995662\n",
      "[264]\ttraining's binary_logloss: 0.0147182\ttraining's f1: 0.996845\tvalid_1's binary_logloss: 0.016962\tvalid_1's f1: 0.995729\n",
      "[265]\ttraining's binary_logloss: 0.01466\ttraining's f1: 0.996857\tvalid_1's binary_logloss: 0.0169283\tvalid_1's f1: 0.995796\n",
      "[266]\ttraining's binary_logloss: 0.0146211\ttraining's f1: 0.996857\tvalid_1's binary_logloss: 0.0168838\tvalid_1's f1: 0.995796\n",
      "[267]\ttraining's binary_logloss: 0.0145734\ttraining's f1: 0.996866\tvalid_1's binary_logloss: 0.0168391\tvalid_1's f1: 0.995796\n",
      "[268]\ttraining's binary_logloss: 0.0145239\ttraining's f1: 0.996879\tvalid_1's binary_logloss: 0.0167997\tvalid_1's f1: 0.995796\n",
      "[269]\ttraining's binary_logloss: 0.0144868\ttraining's f1: 0.99689\tvalid_1's binary_logloss: 0.0167636\tvalid_1's f1: 0.995729\n",
      "[270]\ttraining's binary_logloss: 0.0144178\ttraining's f1: 0.996908\tvalid_1's binary_logloss: 0.01669\tvalid_1's f1: 0.995729\n",
      "[271]\ttraining's binary_logloss: 0.0143718\ttraining's f1: 0.996919\tvalid_1's binary_logloss: 0.0166499\tvalid_1's f1: 0.995662\n",
      "[272]\ttraining's binary_logloss: 0.01432\ttraining's f1: 0.996928\tvalid_1's binary_logloss: 0.0166186\tvalid_1's f1: 0.995662\n",
      "[273]\ttraining's binary_logloss: 0.0142704\ttraining's f1: 0.996938\tvalid_1's binary_logloss: 0.0165905\tvalid_1's f1: 0.995662\n",
      "[274]\ttraining's binary_logloss: 0.0142218\ttraining's f1: 0.996954\tvalid_1's binary_logloss: 0.0165339\tvalid_1's f1: 0.995662\n",
      "[275]\ttraining's binary_logloss: 0.0141876\ttraining's f1: 0.996963\tvalid_1's binary_logloss: 0.0165183\tvalid_1's f1: 0.995662\n",
      "[276]\ttraining's binary_logloss: 0.014089\ttraining's f1: 0.996999\tvalid_1's binary_logloss: 0.0164149\tvalid_1's f1: 0.995596\n",
      "[277]\ttraining's binary_logloss: 0.0140473\ttraining's f1: 0.997018\tvalid_1's binary_logloss: 0.0163756\tvalid_1's f1: 0.995796\n",
      "[278]\ttraining's binary_logloss: 0.0139991\ttraining's f1: 0.997028\tvalid_1's binary_logloss: 0.0163319\tvalid_1's f1: 0.995796\n",
      "[279]\ttraining's binary_logloss: 0.013955\ttraining's f1: 0.997037\tvalid_1's binary_logloss: 0.0163236\tvalid_1's f1: 0.995862\n",
      "[280]\ttraining's binary_logloss: 0.0139121\ttraining's f1: 0.997047\tvalid_1's binary_logloss: 0.0162946\tvalid_1's f1: 0.995929\n",
      "[281]\ttraining's binary_logloss: 0.013882\ttraining's f1: 0.997054\tvalid_1's binary_logloss: 0.0162695\tvalid_1's f1: 0.995929\n",
      "[282]\ttraining's binary_logloss: 0.0138363\ttraining's f1: 0.997064\tvalid_1's binary_logloss: 0.0162376\tvalid_1's f1: 0.995929\n",
      "[283]\ttraining's binary_logloss: 0.0137938\ttraining's f1: 0.997073\tvalid_1's binary_logloss: 0.0162096\tvalid_1's f1: 0.995862\n",
      "[284]\ttraining's binary_logloss: 0.013757\ttraining's f1: 0.997077\tvalid_1's binary_logloss: 0.0161732\tvalid_1's f1: 0.995929\n",
      "[285]\ttraining's binary_logloss: 0.0137212\ttraining's f1: 0.997091\tvalid_1's binary_logloss: 0.0161578\tvalid_1's f1: 0.996063\n",
      "[286]\ttraining's binary_logloss: 0.0136775\ttraining's f1: 0.997104\tvalid_1's binary_logloss: 0.016122\tvalid_1's f1: 0.996063\n",
      "[287]\ttraining's binary_logloss: 0.0136206\ttraining's f1: 0.997117\tvalid_1's binary_logloss: 0.0160632\tvalid_1's f1: 0.996129\n",
      "[288]\ttraining's binary_logloss: 0.0135662\ttraining's f1: 0.997126\tvalid_1's binary_logloss: 0.0160033\tvalid_1's f1: 0.995996\n",
      "[289]\ttraining's binary_logloss: 0.0135237\ttraining's f1: 0.997141\tvalid_1's binary_logloss: 0.0159735\tvalid_1's f1: 0.995996\n",
      "[290]\ttraining's binary_logloss: 0.013501\ttraining's f1: 0.997146\tvalid_1's binary_logloss: 0.0159577\tvalid_1's f1: 0.995996\n",
      "[291]\ttraining's binary_logloss: 0.0134781\ttraining's f1: 0.997152\tvalid_1's binary_logloss: 0.0159416\tvalid_1's f1: 0.995929\n",
      "[292]\ttraining's binary_logloss: 0.0134393\ttraining's f1: 0.997165\tvalid_1's binary_logloss: 0.0159391\tvalid_1's f1: 0.995929\n",
      "[293]\ttraining's binary_logloss: 0.013356\ttraining's f1: 0.99719\tvalid_1's binary_logloss: 0.0158464\tvalid_1's f1: 0.995929\n",
      "[294]\ttraining's binary_logloss: 0.0133183\ttraining's f1: 0.997193\tvalid_1's binary_logloss: 0.0158228\tvalid_1's f1: 0.995929\n",
      "[295]\ttraining's binary_logloss: 0.0132825\ttraining's f1: 0.997203\tvalid_1's binary_logloss: 0.0157881\tvalid_1's f1: 0.996063\n",
      "[296]\ttraining's binary_logloss: 0.0132109\ttraining's f1: 0.997218\tvalid_1's binary_logloss: 0.015708\tvalid_1's f1: 0.996129\n",
      "[297]\ttraining's binary_logloss: 0.0131674\ttraining's f1: 0.997223\tvalid_1's binary_logloss: 0.0156544\tvalid_1's f1: 0.996129\n",
      "[298]\ttraining's binary_logloss: 0.0131337\ttraining's f1: 0.997234\tvalid_1's binary_logloss: 0.0156145\tvalid_1's f1: 0.996129\n",
      "[299]\ttraining's binary_logloss: 0.0131074\ttraining's f1: 0.99724\tvalid_1's binary_logloss: 0.0155948\tvalid_1's f1: 0.996063\n",
      "[300]\ttraining's binary_logloss: 0.0130658\ttraining's f1: 0.997254\tvalid_1's binary_logloss: 0.0155678\tvalid_1's f1: 0.996063\n",
      "[301]\ttraining's binary_logloss: 0.0130289\ttraining's f1: 0.997261\tvalid_1's binary_logloss: 0.0155496\tvalid_1's f1: 0.996063\n",
      "[302]\ttraining's binary_logloss: 0.0129793\ttraining's f1: 0.997273\tvalid_1's binary_logloss: 0.0155026\tvalid_1's f1: 0.996063\n",
      "[303]\ttraining's binary_logloss: 0.0129287\ttraining's f1: 0.997287\tvalid_1's binary_logloss: 0.0154528\tvalid_1's f1: 0.996129\n",
      "[304]\ttraining's binary_logloss: 0.0128913\ttraining's f1: 0.99729\tvalid_1's binary_logloss: 0.0154095\tvalid_1's f1: 0.996129\n",
      "[305]\ttraining's binary_logloss: 0.0128661\ttraining's f1: 0.997298\tvalid_1's binary_logloss: 0.0153814\tvalid_1's f1: 0.996129\n",
      "[306]\ttraining's binary_logloss: 0.0128334\ttraining's f1: 0.997312\tvalid_1's binary_logloss: 0.0153715\tvalid_1's f1: 0.996129\n",
      "[307]\ttraining's binary_logloss: 0.0127927\ttraining's f1: 0.997329\tvalid_1's binary_logloss: 0.0153404\tvalid_1's f1: 0.996129\n",
      "[308]\ttraining's binary_logloss: 0.0127623\ttraining's f1: 0.997333\tvalid_1's binary_logloss: 0.015328\tvalid_1's f1: 0.996129\n",
      "[309]\ttraining's binary_logloss: 0.0127295\ttraining's f1: 0.997337\tvalid_1's binary_logloss: 0.0152801\tvalid_1's f1: 0.996129\n",
      "[310]\ttraining's binary_logloss: 0.0126968\ttraining's f1: 0.997343\tvalid_1's binary_logloss: 0.0152447\tvalid_1's f1: 0.995996\n",
      "[311]\ttraining's binary_logloss: 0.0126542\ttraining's f1: 0.997353\tvalid_1's binary_logloss: 0.0152229\tvalid_1's f1: 0.996063\n",
      "[312]\ttraining's binary_logloss: 0.0125956\ttraining's f1: 0.997374\tvalid_1's binary_logloss: 0.0151563\tvalid_1's f1: 0.996063\n",
      "[313]\ttraining's binary_logloss: 0.0125708\ttraining's f1: 0.997379\tvalid_1's binary_logloss: 0.0151338\tvalid_1's f1: 0.996063\n",
      "[314]\ttraining's binary_logloss: 0.0125302\ttraining's f1: 0.997385\tvalid_1's binary_logloss: 0.0150995\tvalid_1's f1: 0.996063\n",
      "[315]\ttraining's binary_logloss: 0.0124931\ttraining's f1: 0.997394\tvalid_1's binary_logloss: 0.015092\tvalid_1's f1: 0.996063\n",
      "[316]\ttraining's binary_logloss: 0.012474\ttraining's f1: 0.997399\tvalid_1's binary_logloss: 0.0150845\tvalid_1's f1: 0.995996\n",
      "[317]\ttraining's binary_logloss: 0.0124491\ttraining's f1: 0.997404\tvalid_1's binary_logloss: 0.015077\tvalid_1's f1: 0.995996\n",
      "[318]\ttraining's binary_logloss: 0.0124135\ttraining's f1: 0.997414\tvalid_1's binary_logloss: 0.0150554\tvalid_1's f1: 0.995996\n",
      "[319]\ttraining's binary_logloss: 0.0123691\ttraining's f1: 0.997422\tvalid_1's binary_logloss: 0.0150242\tvalid_1's f1: 0.995996\n",
      "[320]\ttraining's binary_logloss: 0.0123284\ttraining's f1: 0.997431\tvalid_1's binary_logloss: 0.0149933\tvalid_1's f1: 0.995996\n",
      "[321]\ttraining's binary_logloss: 0.0122977\ttraining's f1: 0.997433\tvalid_1's binary_logloss: 0.0149616\tvalid_1's f1: 0.995996\n",
      "[322]\ttraining's binary_logloss: 0.0122538\ttraining's f1: 0.997449\tvalid_1's binary_logloss: 0.01494\tvalid_1's f1: 0.995996\n",
      "[323]\ttraining's binary_logloss: 0.0122186\ttraining's f1: 0.997467\tvalid_1's binary_logloss: 0.0148919\tvalid_1's f1: 0.996063\n",
      "[324]\ttraining's binary_logloss: 0.0121851\ttraining's f1: 0.997477\tvalid_1's binary_logloss: 0.0148729\tvalid_1's f1: 0.996063\n",
      "[325]\ttraining's binary_logloss: 0.0121498\ttraining's f1: 0.997489\tvalid_1's binary_logloss: 0.0148337\tvalid_1's f1: 0.996129\n",
      "[326]\ttraining's binary_logloss: 0.0121181\ttraining's f1: 0.997495\tvalid_1's binary_logloss: 0.0148014\tvalid_1's f1: 0.996129\n",
      "[327]\ttraining's binary_logloss: 0.0120886\ttraining's f1: 0.997503\tvalid_1's binary_logloss: 0.0147936\tvalid_1's f1: 0.996063\n",
      "[328]\ttraining's binary_logloss: 0.0120558\ttraining's f1: 0.997517\tvalid_1's binary_logloss: 0.0147636\tvalid_1's f1: 0.996129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[329]\ttraining's binary_logloss: 0.0120341\ttraining's f1: 0.997521\tvalid_1's binary_logloss: 0.0147582\tvalid_1's f1: 0.996129\n",
      "[330]\ttraining's binary_logloss: 0.0120058\ttraining's f1: 0.997522\tvalid_1's binary_logloss: 0.014733\tvalid_1's f1: 0.996129\n",
      "[331]\ttraining's binary_logloss: 0.0119736\ttraining's f1: 0.99753\tvalid_1's binary_logloss: 0.0146853\tvalid_1's f1: 0.996196\n",
      "[332]\ttraining's binary_logloss: 0.0119359\ttraining's f1: 0.997536\tvalid_1's binary_logloss: 0.0146639\tvalid_1's f1: 0.996129\n",
      "[333]\ttraining's binary_logloss: 0.0118953\ttraining's f1: 0.99754\tvalid_1's binary_logloss: 0.0146322\tvalid_1's f1: 0.996196\n",
      "[334]\ttraining's binary_logloss: 0.0118657\ttraining's f1: 0.997547\tvalid_1's binary_logloss: 0.0146044\tvalid_1's f1: 0.996196\n",
      "[335]\ttraining's binary_logloss: 0.011841\ttraining's f1: 0.997554\tvalid_1's binary_logloss: 0.0145833\tvalid_1's f1: 0.996263\n",
      "[336]\ttraining's binary_logloss: 0.0118117\ttraining's f1: 0.997557\tvalid_1's binary_logloss: 0.0145446\tvalid_1's f1: 0.99633\n",
      "[337]\ttraining's binary_logloss: 0.0117463\ttraining's f1: 0.99757\tvalid_1's binary_logloss: 0.0144842\tvalid_1's f1: 0.99633\n",
      "[338]\ttraining's binary_logloss: 0.0117211\ttraining's f1: 0.997576\tvalid_1's binary_logloss: 0.0144776\tvalid_1's f1: 0.99633\n",
      "[339]\ttraining's binary_logloss: 0.0116974\ttraining's f1: 0.997581\tvalid_1's binary_logloss: 0.0144554\tvalid_1's f1: 0.996396\n",
      "[340]\ttraining's binary_logloss: 0.0116708\ttraining's f1: 0.997593\tvalid_1's binary_logloss: 0.0144272\tvalid_1's f1: 0.996396\n",
      "[341]\ttraining's binary_logloss: 0.0116477\ttraining's f1: 0.997598\tvalid_1's binary_logloss: 0.0144168\tvalid_1's f1: 0.996396\n",
      "[342]\ttraining's binary_logloss: 0.0116221\ttraining's f1: 0.997604\tvalid_1's binary_logloss: 0.0144033\tvalid_1's f1: 0.996396\n",
      "[343]\ttraining's binary_logloss: 0.0116004\ttraining's f1: 0.997609\tvalid_1's binary_logloss: 0.0143884\tvalid_1's f1: 0.99633\n",
      "[344]\ttraining's binary_logloss: 0.0115474\ttraining's f1: 0.997623\tvalid_1's binary_logloss: 0.0143578\tvalid_1's f1: 0.996263\n",
      "[345]\ttraining's binary_logloss: 0.0115151\ttraining's f1: 0.99763\tvalid_1's binary_logloss: 0.0143563\tvalid_1's f1: 0.996263\n",
      "[346]\ttraining's binary_logloss: 0.0114947\ttraining's f1: 0.997636\tvalid_1's binary_logloss: 0.0143559\tvalid_1's f1: 0.996263\n",
      "[347]\ttraining's binary_logloss: 0.011477\ttraining's f1: 0.997638\tvalid_1's binary_logloss: 0.0143346\tvalid_1's f1: 0.99633\n",
      "[348]\ttraining's binary_logloss: 0.0114505\ttraining's f1: 0.997643\tvalid_1's binary_logloss: 0.014319\tvalid_1's f1: 0.99633\n",
      "[349]\ttraining's binary_logloss: 0.0114092\ttraining's f1: 0.997648\tvalid_1's binary_logloss: 0.0142585\tvalid_1's f1: 0.99633\n",
      "[350]\ttraining's binary_logloss: 0.0113818\ttraining's f1: 0.997657\tvalid_1's binary_logloss: 0.0142444\tvalid_1's f1: 0.99633\n",
      "[351]\ttraining's binary_logloss: 0.0113284\ttraining's f1: 0.997674\tvalid_1's binary_logloss: 0.0141766\tvalid_1's f1: 0.996396\n",
      "[352]\ttraining's binary_logloss: 0.0112761\ttraining's f1: 0.997684\tvalid_1's binary_logloss: 0.0141302\tvalid_1's f1: 0.996396\n",
      "[353]\ttraining's binary_logloss: 0.0112473\ttraining's f1: 0.997689\tvalid_1's binary_logloss: 0.0140989\tvalid_1's f1: 0.996396\n",
      "[354]\ttraining's binary_logloss: 0.0112205\ttraining's f1: 0.997699\tvalid_1's binary_logloss: 0.0140799\tvalid_1's f1: 0.996463\n",
      "[355]\ttraining's binary_logloss: 0.0111888\ttraining's f1: 0.997707\tvalid_1's binary_logloss: 0.0140673\tvalid_1's f1: 0.996463\n",
      "[356]\ttraining's binary_logloss: 0.011161\ttraining's f1: 0.997713\tvalid_1's binary_logloss: 0.0140361\tvalid_1's f1: 0.996463\n",
      "[357]\ttraining's binary_logloss: 0.0111398\ttraining's f1: 0.997718\tvalid_1's binary_logloss: 0.0140179\tvalid_1's f1: 0.996463\n",
      "[358]\ttraining's binary_logloss: 0.0111112\ttraining's f1: 0.997724\tvalid_1's binary_logloss: 0.0140116\tvalid_1's f1: 0.996396\n",
      "[359]\ttraining's binary_logloss: 0.011074\ttraining's f1: 0.997731\tvalid_1's binary_logloss: 0.0139837\tvalid_1's f1: 0.99653\n",
      "[360]\ttraining's binary_logloss: 0.0110538\ttraining's f1: 0.997738\tvalid_1's binary_logloss: 0.0139922\tvalid_1's f1: 0.99653\n",
      "[361]\ttraining's binary_logloss: 0.0110172\ttraining's f1: 0.997749\tvalid_1's binary_logloss: 0.0139406\tvalid_1's f1: 0.996597\n",
      "[362]\ttraining's binary_logloss: 0.010993\ttraining's f1: 0.997755\tvalid_1's binary_logloss: 0.0139106\tvalid_1's f1: 0.996663\n",
      "[363]\ttraining's binary_logloss: 0.0109672\ttraining's f1: 0.997762\tvalid_1's binary_logloss: 0.0139057\tvalid_1's f1: 0.996663\n",
      "[364]\ttraining's binary_logloss: 0.0109402\ttraining's f1: 0.997765\tvalid_1's binary_logloss: 0.0138761\tvalid_1's f1: 0.996663\n",
      "[365]\ttraining's binary_logloss: 0.0108895\ttraining's f1: 0.997776\tvalid_1's binary_logloss: 0.013831\tvalid_1's f1: 0.996663\n",
      "[366]\ttraining's binary_logloss: 0.0108503\ttraining's f1: 0.99778\tvalid_1's binary_logloss: 0.0137811\tvalid_1's f1: 0.996663\n",
      "[367]\ttraining's binary_logloss: 0.0108367\ttraining's f1: 0.997784\tvalid_1's binary_logloss: 0.0137779\tvalid_1's f1: 0.996663\n",
      "[368]\ttraining's binary_logloss: 0.010817\ttraining's f1: 0.997785\tvalid_1's binary_logloss: 0.0137655\tvalid_1's f1: 0.996663\n",
      "[369]\ttraining's binary_logloss: 0.0107963\ttraining's f1: 0.99779\tvalid_1's binary_logloss: 0.0137509\tvalid_1's f1: 0.996597\n",
      "[370]\ttraining's binary_logloss: 0.0107783\ttraining's f1: 0.997793\tvalid_1's binary_logloss: 0.0137327\tvalid_1's f1: 0.996663\n",
      "[371]\ttraining's binary_logloss: 0.010758\ttraining's f1: 0.997797\tvalid_1's binary_logloss: 0.0137225\tvalid_1's f1: 0.996663\n",
      "[372]\ttraining's binary_logloss: 0.0107308\ttraining's f1: 0.997808\tvalid_1's binary_logloss: 0.0136874\tvalid_1's f1: 0.99673\n",
      "[373]\ttraining's binary_logloss: 0.0107051\ttraining's f1: 0.997813\tvalid_1's binary_logloss: 0.013671\tvalid_1's f1: 0.99673\n",
      "[374]\ttraining's binary_logloss: 0.0106671\ttraining's f1: 0.997823\tvalid_1's binary_logloss: 0.0136423\tvalid_1's f1: 0.99673\n",
      "[375]\ttraining's binary_logloss: 0.0106457\ttraining's f1: 0.997826\tvalid_1's binary_logloss: 0.0136079\tvalid_1's f1: 0.99673\n",
      "[376]\ttraining's binary_logloss: 0.010617\ttraining's f1: 0.997835\tvalid_1's binary_logloss: 0.0135895\tvalid_1's f1: 0.99673\n",
      "[377]\ttraining's binary_logloss: 0.0106048\ttraining's f1: 0.997837\tvalid_1's binary_logloss: 0.0135885\tvalid_1's f1: 0.996797\n",
      "[378]\ttraining's binary_logloss: 0.0105843\ttraining's f1: 0.997843\tvalid_1's binary_logloss: 0.0135697\tvalid_1's f1: 0.996797\n",
      "[379]\ttraining's binary_logloss: 0.0105719\ttraining's f1: 0.997848\tvalid_1's binary_logloss: 0.0135662\tvalid_1's f1: 0.996797\n",
      "[380]\ttraining's binary_logloss: 0.0105291\ttraining's f1: 0.997851\tvalid_1's binary_logloss: 0.0135297\tvalid_1's f1: 0.996797\n",
      "[381]\ttraining's binary_logloss: 0.0105062\ttraining's f1: 0.997857\tvalid_1's binary_logloss: 0.0135102\tvalid_1's f1: 0.996863\n",
      "[382]\ttraining's binary_logloss: 0.0104753\ttraining's f1: 0.997866\tvalid_1's binary_logloss: 0.0134889\tvalid_1's f1: 0.996863\n",
      "[383]\ttraining's binary_logloss: 0.0104527\ttraining's f1: 0.997867\tvalid_1's binary_logloss: 0.0134645\tvalid_1's f1: 0.996863\n",
      "[384]\ttraining's binary_logloss: 0.0104366\ttraining's f1: 0.99787\tvalid_1's binary_logloss: 0.0134713\tvalid_1's f1: 0.996863\n",
      "[385]\ttraining's binary_logloss: 0.0104135\ttraining's f1: 0.997878\tvalid_1's binary_logloss: 0.0134492\tvalid_1's f1: 0.996797\n",
      "[386]\ttraining's binary_logloss: 0.0104017\ttraining's f1: 0.99788\tvalid_1's binary_logloss: 0.0134489\tvalid_1's f1: 0.996863\n",
      "[387]\ttraining's binary_logloss: 0.0103863\ttraining's f1: 0.997886\tvalid_1's binary_logloss: 0.013445\tvalid_1's f1: 0.996863\n",
      "[388]\ttraining's binary_logloss: 0.0103677\ttraining's f1: 0.99789\tvalid_1's binary_logloss: 0.0134348\tvalid_1's f1: 0.996863\n",
      "[389]\ttraining's binary_logloss: 0.0103481\ttraining's f1: 0.997896\tvalid_1's binary_logloss: 0.0134475\tvalid_1's f1: 0.996797\n",
      "[390]\ttraining's binary_logloss: 0.0103342\ttraining's f1: 0.997898\tvalid_1's binary_logloss: 0.0134349\tvalid_1's f1: 0.996797\n",
      "[391]\ttraining's binary_logloss: 0.0102992\ttraining's f1: 0.997905\tvalid_1's binary_logloss: 0.0134018\tvalid_1's f1: 0.996797\n",
      "[392]\ttraining's binary_logloss: 0.0102841\ttraining's f1: 0.997907\tvalid_1's binary_logloss: 0.0133939\tvalid_1's f1: 0.996797\n",
      "[393]\ttraining's binary_logloss: 0.0102579\ttraining's f1: 0.997906\tvalid_1's binary_logloss: 0.0133673\tvalid_1's f1: 0.996797\n",
      "[394]\ttraining's binary_logloss: 0.0102202\ttraining's f1: 0.997918\tvalid_1's binary_logloss: 0.0133248\tvalid_1's f1: 0.996797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[395]\ttraining's binary_logloss: 0.0101992\ttraining's f1: 0.997925\tvalid_1's binary_logloss: 0.0133265\tvalid_1's f1: 0.996797\n",
      "[396]\ttraining's binary_logloss: 0.0101611\ttraining's f1: 0.997933\tvalid_1's binary_logloss: 0.0132968\tvalid_1's f1: 0.996797\n",
      "[397]\ttraining's binary_logloss: 0.010116\ttraining's f1: 0.997946\tvalid_1's binary_logloss: 0.01327\tvalid_1's f1: 0.99673\n",
      "[398]\ttraining's binary_logloss: 0.0100901\ttraining's f1: 0.997953\tvalid_1's binary_logloss: 0.0132445\tvalid_1's f1: 0.99673\n",
      "[399]\ttraining's binary_logloss: 0.01007\ttraining's f1: 0.997957\tvalid_1's binary_logloss: 0.0132147\tvalid_1's f1: 0.99673\n",
      "[400]\ttraining's binary_logloss: 0.0100505\ttraining's f1: 0.997962\tvalid_1's binary_logloss: 0.0132071\tvalid_1's f1: 0.996797\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[400]\ttraining's binary_logloss: 0.0100505\ttraining's f1: 0.997962\tvalid_1's binary_logloss: 0.0132071\tvalid_1's f1: 0.996797\n",
      "Train Time: 1348.74192070961\n",
      "Prediction Time: 13.466694355010986\n",
      "fbeta score_train: 0.8511072630260027\n",
      "recall_score_train: 0.8512990213335211\n",
      "precision_score_train: 0.8503410929038611\n",
      "========================================================\n",
      "Train Time: 1348.74192070961\n",
      "Prediction Time: 13.466694355010986\n",
      "fbeta score: 0.8559888398650403\n",
      "recall_score: 0.8577698309492848\n",
      "precision_score: 0.8489382239382239\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    450385\n",
      "         1.0       0.85      0.86      0.85      6152\n",
      "\n",
      "    accuracy                           1.00    456537\n",
      "   macro avg       0.92      0.93      0.93    456537\n",
      "weighted avg       1.00      1.00      1.00    456537\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(training.drop(\n",
    "    ['cano', 'bacno', 'txkey', 'locdt', 'fraud_ind'], axis=1),\n",
    "                                                        training['fraud_ind'],\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=112)\n",
    "\n",
    "ad_data = training.drop(['cano', 'bacno', 'txkey', 'locdt'], axis=1)\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class before oversampling the data\")\n",
    "print(ad_data['fraud_ind'].value_counts())\n",
    "\n",
    "X_ad = ad_data.drop('fraud_ind', axis=1)\n",
    "y_ad = ad_data['fraud_ind']\n",
    "start = time()\n",
    "# Oversampling the data using SMOTE\n",
    "\n",
    "X_resampled_ad, y_resampled_ad = ADASYN(\n",
    "    sampling_strategy='minority').fit_sample(X_ad, y_ad)\n",
    "end = time()\n",
    "print(\"No. of 0's and 1's in the feature Class After oversampling the data\")\n",
    "print(Counter(y_resampled_ad))\n",
    "results = {}\n",
    "\n",
    "# Initializng the dictionary to store performance metrics\n",
    "results['ad'] = {}\n",
    "results['ad']['resample_time'] = end - start\n",
    "\n",
    "#X_resampled_ad, y_resampled_ad = RandomUnderSampler(sampling_strategy={1:200000,0:200000}).fit_resample(X_resampled_ad,y_resampled_ad)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled_ad,\n",
    "                                                    y_resampled_ad,\n",
    "                                                    test_size=0.005,\n",
    "                                                    random_state=112)\n",
    "\n",
    "# Training the classifier\n",
    "start = time()\n",
    "clf_ad_BF = lig.LGBMClassifier(n_estimators=400,\n",
    "                               reg_alpha=0.3,\n",
    "                               num_leaves=100,\n",
    "                               max_depth=16,\n",
    "                               learning_rate=0.1,\n",
    "                               reg_lambda=0.5,\n",
    "                               subsample=0.7).fit(X_train,\n",
    "                                                  y_train,\n",
    "                                                  eval_set=[(X_train, y_train),\n",
    "                                                            (X_test, y_test)],\n",
    "                                                  eval_metric=cus_f1,\n",
    "                                                  early_stopping_rounds=50)\n",
    "end = time()\n",
    "results['ad']['train_time'] = end - start\n",
    "\n",
    "# Predict on training set\n",
    "start = time()\n",
    "y_pred_score_ad = clf_ad_BF.predict(X_test1)\n",
    "y_score_ad = clf_ad_BF.predict(X_train1)\n",
    "\n",
    "end = time()\n",
    "results['ad']['pred_time'] = end - start\n",
    "\n",
    "results['ad']['fbeta_train'] = fbeta_score(y_train1, y_score_ad, beta=2)\n",
    "results['ad']['recall_train'] = recall_score(y_train1, y_score_ad)\n",
    "results['ad']['precision_train'] = precision_score(y_train1, y_score_ad)\n",
    "\n",
    "results['ad']['fbeta_test'] = fbeta_score(y_test1, y_pred_score_ad, beta=2)\n",
    "results['ad']['recall_test'] = recall_score(y_test1, y_pred_score_ad)\n",
    "results['ad']['precision_test'] = precision_score(y_test1, y_pred_score_ad)\n",
    "\n",
    "print(\"Train Time:\", results['ad']['train_time'])\n",
    "print(\"Prediction Time:\", results['ad']['pred_time'])\n",
    "print(\"fbeta score_train:\", results['ad']['fbeta_train'])\n",
    "print('recall_score_train:', results['ad']['recall_train'])\n",
    "print('precision_score_train:', results['ad']['precision_train'])\n",
    "\n",
    "print('========================================================')\n",
    "print(\"Train Time:\", results['ad']['train_time'])\n",
    "print(\"Prediction Time:\", results['ad']['pred_time'])\n",
    "print(\"fbeta score:\", results['ad']['fbeta_test'])\n",
    "print('recall_score:', results['ad']['recall_test'])\n",
    "print('precision_score:', results['ad']['precision_test'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test1, y_pred_score_ad))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test1, y_pred_score_ad)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T07:38:09.710412Z",
     "start_time": "2019-10-10T07:35:35.916589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99148557, 0.99155597, 0.99149495, 0.99143394, 0.99169678])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kcv = KFold(n_splits=5)\n",
    "cross_val_score(lig_mo, X, Y, cv=kcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T07:38:11.246480Z",
     "start_time": "2019-10-10T07:38:11.243489Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T07:38:12.759914Z",
     "start_time": "2019-10-10T07:38:12.756922Z"
    }
   },
   "outputs": [],
   "source": [
    "def cus_f1(ytru, ypre):\n",
    "    threshold = 0.5\n",
    "    y_pre = [int(item > threshold) for item in ypre]\n",
    "    f1 = f1_score(ytru, y_pre, average='macro')\n",
    "    return 'f1', f1, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T07:51:15.417878Z",
     "start_time": "2019-10-10T07:38:14.274475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.195421\ttraining's f1: 0.609097\tvalid_1's binary_logloss: 0.194956\tvalid_1's f1: 0.609644\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[2]\ttraining's binary_logloss: 0.192306\ttraining's f1: 0.609406\tvalid_1's binary_logloss: 0.192052\tvalid_1's f1: 0.609642\n",
      "[3]\ttraining's binary_logloss: 0.185949\ttraining's f1: 0.609248\tvalid_1's binary_logloss: 0.186072\tvalid_1's f1: 0.609447\n",
      "[4]\ttraining's binary_logloss: 0.182123\ttraining's f1: 0.609713\tvalid_1's binary_logloss: 0.182498\tvalid_1's f1: 0.60974\n",
      "[5]\ttraining's binary_logloss: 0.178601\ttraining's f1: 0.610728\tvalid_1's binary_logloss: 0.179146\tvalid_1's f1: 0.61064\n",
      "[6]\ttraining's binary_logloss: 0.175416\ttraining's f1: 0.611678\tvalid_1's binary_logloss: 0.176072\tvalid_1's f1: 0.611552\n",
      "[7]\ttraining's binary_logloss: 0.172932\ttraining's f1: 0.612375\tvalid_1's binary_logloss: 0.173671\tvalid_1's f1: 0.612042\n",
      "[8]\ttraining's binary_logloss: 0.169686\ttraining's f1: 0.613167\tvalid_1's binary_logloss: 0.170569\tvalid_1's f1: 0.61247\n",
      "[9]\ttraining's binary_logloss: 0.167344\ttraining's f1: 0.614257\tvalid_1's binary_logloss: 0.168345\tvalid_1's f1: 0.613497\n",
      "[10]\ttraining's binary_logloss: 0.165216\ttraining's f1: 0.61468\tvalid_1's binary_logloss: 0.166336\tvalid_1's f1: 0.613816\n",
      "[11]\ttraining's binary_logloss: 0.163074\ttraining's f1: 0.61563\tvalid_1's binary_logloss: 0.164273\tvalid_1's f1: 0.614665\n",
      "[12]\ttraining's binary_logloss: 0.16025\ttraining's f1: 0.616256\tvalid_1's binary_logloss: 0.161605\tvalid_1's f1: 0.615392\n",
      "[13]\ttraining's binary_logloss: 0.158019\ttraining's f1: 0.616835\tvalid_1's binary_logloss: 0.159524\tvalid_1's f1: 0.615792\n",
      "[14]\ttraining's binary_logloss: 0.155943\ttraining's f1: 0.617565\tvalid_1's binary_logloss: 0.157558\tvalid_1's f1: 0.616269\n",
      "[15]\ttraining's binary_logloss: 0.154039\ttraining's f1: 0.618767\tvalid_1's binary_logloss: 0.155819\tvalid_1's f1: 0.617326\n",
      "[16]\ttraining's binary_logloss: 0.151611\ttraining's f1: 0.61973\tvalid_1's binary_logloss: 0.153402\tvalid_1's f1: 0.618121\n",
      "[17]\ttraining's binary_logloss: 0.149411\ttraining's f1: 0.620796\tvalid_1's binary_logloss: 0.151256\tvalid_1's f1: 0.619063\n",
      "[18]\ttraining's binary_logloss: 0.147564\ttraining's f1: 0.621951\tvalid_1's binary_logloss: 0.149482\tvalid_1's f1: 0.62022\n",
      "[19]\ttraining's binary_logloss: 0.14539\ttraining's f1: 0.62308\tvalid_1's binary_logloss: 0.14736\tvalid_1's f1: 0.621291\n",
      "[20]\ttraining's binary_logloss: 0.143295\ttraining's f1: 0.62491\tvalid_1's binary_logloss: 0.145397\tvalid_1's f1: 0.623097\n",
      "[21]\ttraining's binary_logloss: 0.141491\ttraining's f1: 0.626092\tvalid_1's binary_logloss: 0.143594\tvalid_1's f1: 0.624238\n",
      "[22]\ttraining's binary_logloss: 0.139503\ttraining's f1: 0.627442\tvalid_1's binary_logloss: 0.141756\tvalid_1's f1: 0.625334\n",
      "[23]\ttraining's binary_logloss: 0.137945\ttraining's f1: 0.628673\tvalid_1's binary_logloss: 0.140264\tvalid_1's f1: 0.626385\n",
      "[24]\ttraining's binary_logloss: 0.136157\ttraining's f1: 0.630307\tvalid_1's binary_logloss: 0.138562\tvalid_1's f1: 0.627885\n",
      "[25]\ttraining's binary_logloss: 0.134659\ttraining's f1: 0.631956\tvalid_1's binary_logloss: 0.137107\tvalid_1's f1: 0.629412\n",
      "[26]\ttraining's binary_logloss: 0.133357\ttraining's f1: 0.633258\tvalid_1's binary_logloss: 0.135868\tvalid_1's f1: 0.630487\n",
      "[27]\ttraining's binary_logloss: 0.131862\ttraining's f1: 0.634451\tvalid_1's binary_logloss: 0.134416\tvalid_1's f1: 0.631623\n",
      "[28]\ttraining's binary_logloss: 0.130749\ttraining's f1: 0.635401\tvalid_1's binary_logloss: 0.133389\tvalid_1's f1: 0.63248\n",
      "[29]\ttraining's binary_logloss: 0.129225\ttraining's f1: 0.636913\tvalid_1's binary_logloss: 0.13187\tvalid_1's f1: 0.633715\n",
      "[30]\ttraining's binary_logloss: 0.127824\ttraining's f1: 0.638306\tvalid_1's binary_logloss: 0.130513\tvalid_1's f1: 0.635039\n",
      "[31]\ttraining's binary_logloss: 0.1264\ttraining's f1: 0.639541\tvalid_1's binary_logloss: 0.129113\tvalid_1's f1: 0.636259\n",
      "[32]\ttraining's binary_logloss: 0.125396\ttraining's f1: 0.640576\tvalid_1's binary_logloss: 0.128145\tvalid_1's f1: 0.637137\n",
      "[33]\ttraining's binary_logloss: 0.124011\ttraining's f1: 0.641978\tvalid_1's binary_logloss: 0.126883\tvalid_1's f1: 0.638414\n",
      "[34]\ttraining's binary_logloss: 0.122901\ttraining's f1: 0.643028\tvalid_1's binary_logloss: 0.12581\tvalid_1's f1: 0.639332\n",
      "[35]\ttraining's binary_logloss: 0.121852\ttraining's f1: 0.644191\tvalid_1's binary_logloss: 0.124804\tvalid_1's f1: 0.640521\n",
      "[36]\ttraining's binary_logloss: 0.120631\ttraining's f1: 0.645565\tvalid_1's binary_logloss: 0.123631\tvalid_1's f1: 0.641753\n",
      "[37]\ttraining's binary_logloss: 0.119559\ttraining's f1: 0.646689\tvalid_1's binary_logloss: 0.122641\tvalid_1's f1: 0.642613\n",
      "[38]\ttraining's binary_logloss: 0.118535\ttraining's f1: 0.647782\tvalid_1's binary_logloss: 0.12169\tvalid_1's f1: 0.643543\n",
      "[39]\ttraining's binary_logloss: 0.117541\ttraining's f1: 0.649213\tvalid_1's binary_logloss: 0.120753\tvalid_1's f1: 0.644833\n",
      "[40]\ttraining's binary_logloss: 0.116421\ttraining's f1: 0.650588\tvalid_1's binary_logloss: 0.119668\tvalid_1's f1: 0.645939\n",
      "[41]\ttraining's binary_logloss: 0.115542\ttraining's f1: 0.651602\tvalid_1's binary_logloss: 0.118805\tvalid_1's f1: 0.646901\n",
      "[42]\ttraining's binary_logloss: 0.114709\ttraining's f1: 0.652484\tvalid_1's binary_logloss: 0.117994\tvalid_1's f1: 0.647804\n",
      "[43]\ttraining's binary_logloss: 0.113715\ttraining's f1: 0.65378\tvalid_1's binary_logloss: 0.117056\tvalid_1's f1: 0.649038\n",
      "[44]\ttraining's binary_logloss: 0.112855\ttraining's f1: 0.654752\tvalid_1's binary_logloss: 0.116243\tvalid_1's f1: 0.649843\n",
      "[45]\ttraining's binary_logloss: 0.112002\ttraining's f1: 0.655666\tvalid_1's binary_logloss: 0.11548\tvalid_1's f1: 0.650791\n",
      "[46]\ttraining's binary_logloss: 0.110924\ttraining's f1: 0.657156\tvalid_1's binary_logloss: 0.11443\tvalid_1's f1: 0.652189\n",
      "[47]\ttraining's binary_logloss: 0.110314\ttraining's f1: 0.657795\tvalid_1's binary_logloss: 0.113843\tvalid_1's f1: 0.652737\n",
      "[48]\ttraining's binary_logloss: 0.109326\ttraining's f1: 0.658992\tvalid_1's binary_logloss: 0.112905\tvalid_1's f1: 0.653958\n",
      "[49]\ttraining's binary_logloss: 0.108418\ttraining's f1: 0.659812\tvalid_1's binary_logloss: 0.112034\tvalid_1's f1: 0.654822\n",
      "[50]\ttraining's binary_logloss: 0.107675\ttraining's f1: 0.660945\tvalid_1's binary_logloss: 0.111327\tvalid_1's f1: 0.655743\n",
      "[51]\ttraining's binary_logloss: 0.107018\ttraining's f1: 0.661768\tvalid_1's binary_logloss: 0.110695\tvalid_1's f1: 0.656475\n",
      "[52]\ttraining's binary_logloss: 0.106145\ttraining's f1: 0.663001\tvalid_1's binary_logloss: 0.109919\tvalid_1's f1: 0.657601\n",
      "[53]\ttraining's binary_logloss: 0.105336\ttraining's f1: 0.664095\tvalid_1's binary_logloss: 0.109171\tvalid_1's f1: 0.658358\n",
      "[54]\ttraining's binary_logloss: 0.104548\ttraining's f1: 0.665016\tvalid_1's binary_logloss: 0.108446\tvalid_1's f1: 0.659136\n",
      "[55]\ttraining's binary_logloss: 0.104008\ttraining's f1: 0.665641\tvalid_1's binary_logloss: 0.107949\tvalid_1's f1: 0.659898\n",
      "[56]\ttraining's binary_logloss: 0.103223\ttraining's f1: 0.666396\tvalid_1's binary_logloss: 0.107268\tvalid_1's f1: 0.660575\n",
      "[57]\ttraining's binary_logloss: 0.102435\ttraining's f1: 0.667375\tvalid_1's binary_logloss: 0.10655\tvalid_1's f1: 0.661455\n",
      "[58]\ttraining's binary_logloss: 0.101866\ttraining's f1: 0.668076\tvalid_1's binary_logloss: 0.10605\tvalid_1's f1: 0.662116\n",
      "[59]\ttraining's binary_logloss: 0.10115\ttraining's f1: 0.669113\tvalid_1's binary_logloss: 0.105373\tvalid_1's f1: 0.663023\n",
      "[60]\ttraining's binary_logloss: 0.100534\ttraining's f1: 0.669946\tvalid_1's binary_logloss: 0.104815\tvalid_1's f1: 0.663746\n",
      "[61]\ttraining's binary_logloss: 0.0999445\ttraining's f1: 0.670676\tvalid_1's binary_logloss: 0.104307\tvalid_1's f1: 0.664323\n",
      "[62]\ttraining's binary_logloss: 0.0994124\ttraining's f1: 0.671328\tvalid_1's binary_logloss: 0.103835\tvalid_1's f1: 0.664707\n",
      "[63]\ttraining's binary_logloss: 0.0987437\ttraining's f1: 0.672267\tvalid_1's binary_logloss: 0.103196\tvalid_1's f1: 0.665472\n",
      "[64]\ttraining's binary_logloss: 0.0981611\ttraining's f1: 0.672991\tvalid_1's binary_logloss: 0.10265\tvalid_1's f1: 0.666001\n",
      "[65]\ttraining's binary_logloss: 0.0976498\ttraining's f1: 0.673551\tvalid_1's binary_logloss: 0.102161\tvalid_1's f1: 0.666575\n",
      "[66]\ttraining's binary_logloss: 0.0971243\ttraining's f1: 0.674335\tvalid_1's binary_logloss: 0.101698\tvalid_1's f1: 0.667293\n",
      "[67]\ttraining's binary_logloss: 0.0964987\ttraining's f1: 0.675188\tvalid_1's binary_logloss: 0.101108\tvalid_1's f1: 0.667981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68]\ttraining's binary_logloss: 0.0958583\ttraining's f1: 0.676058\tvalid_1's binary_logloss: 0.100488\tvalid_1's f1: 0.668841\n",
      "[69]\ttraining's binary_logloss: 0.0952208\ttraining's f1: 0.677042\tvalid_1's binary_logloss: 0.0998979\tvalid_1's f1: 0.669725\n",
      "[70]\ttraining's binary_logloss: 0.09456\ttraining's f1: 0.67775\tvalid_1's binary_logloss: 0.0992869\tvalid_1's f1: 0.670397\n",
      "[71]\ttraining's binary_logloss: 0.0940302\ttraining's f1: 0.678363\tvalid_1's binary_logloss: 0.0987934\tvalid_1's f1: 0.670978\n",
      "[72]\ttraining's binary_logloss: 0.0935402\ttraining's f1: 0.678922\tvalid_1's binary_logloss: 0.0983365\tvalid_1's f1: 0.671409\n",
      "[73]\ttraining's binary_logloss: 0.0931032\ttraining's f1: 0.679568\tvalid_1's binary_logloss: 0.0979386\tvalid_1's f1: 0.671765\n",
      "[74]\ttraining's binary_logloss: 0.092549\ttraining's f1: 0.680386\tvalid_1's binary_logloss: 0.0974085\tvalid_1's f1: 0.672425\n",
      "[75]\ttraining's binary_logloss: 0.0921108\ttraining's f1: 0.680949\tvalid_1's binary_logloss: 0.0970139\tvalid_1's f1: 0.672837\n",
      "[76]\ttraining's binary_logloss: 0.0915629\ttraining's f1: 0.681834\tvalid_1's binary_logloss: 0.0965207\tvalid_1's f1: 0.673484\n",
      "[77]\ttraining's binary_logloss: 0.0910808\ttraining's f1: 0.682534\tvalid_1's binary_logloss: 0.0960633\tvalid_1's f1: 0.674224\n",
      "[78]\ttraining's binary_logloss: 0.0905215\ttraining's f1: 0.683207\tvalid_1's binary_logloss: 0.0955124\tvalid_1's f1: 0.674865\n",
      "[79]\ttraining's binary_logloss: 0.0900822\ttraining's f1: 0.683769\tvalid_1's binary_logloss: 0.0950825\tvalid_1's f1: 0.675465\n",
      "[80]\ttraining's binary_logloss: 0.0895638\ttraining's f1: 0.684757\tvalid_1's binary_logloss: 0.0946075\tvalid_1's f1: 0.676383\n",
      "[81]\ttraining's binary_logloss: 0.0890734\ttraining's f1: 0.68559\tvalid_1's binary_logloss: 0.0941754\tvalid_1's f1: 0.676838\n",
      "[82]\ttraining's binary_logloss: 0.088335\ttraining's f1: 0.687086\tvalid_1's binary_logloss: 0.0934703\tvalid_1's f1: 0.678117\n",
      "[83]\ttraining's binary_logloss: 0.0876434\ttraining's f1: 0.68811\tvalid_1's binary_logloss: 0.0927716\tvalid_1's f1: 0.679045\n",
      "[84]\ttraining's binary_logloss: 0.0871913\ttraining's f1: 0.688809\tvalid_1's binary_logloss: 0.0923702\tvalid_1's f1: 0.679418\n",
      "[85]\ttraining's binary_logloss: 0.0865515\ttraining's f1: 0.690075\tvalid_1's binary_logloss: 0.091764\tvalid_1's f1: 0.680508\n",
      "[86]\ttraining's binary_logloss: 0.0860954\ttraining's f1: 0.690728\tvalid_1's binary_logloss: 0.0913076\tvalid_1's f1: 0.681304\n",
      "[87]\ttraining's binary_logloss: 0.0856175\ttraining's f1: 0.691628\tvalid_1's binary_logloss: 0.0908661\tvalid_1's f1: 0.682003\n",
      "[88]\ttraining's binary_logloss: 0.0852682\ttraining's f1: 0.692122\tvalid_1's binary_logloss: 0.0905402\tvalid_1's f1: 0.682378\n",
      "[89]\ttraining's binary_logloss: 0.0848389\ttraining's f1: 0.692867\tvalid_1's binary_logloss: 0.0901269\tvalid_1's f1: 0.682929\n",
      "[90]\ttraining's binary_logloss: 0.0845328\ttraining's f1: 0.693248\tvalid_1's binary_logloss: 0.0898407\tvalid_1's f1: 0.68323\n",
      "[91]\ttraining's binary_logloss: 0.0841731\ttraining's f1: 0.693894\tvalid_1's binary_logloss: 0.0895289\tvalid_1's f1: 0.683648\n",
      "[92]\ttraining's binary_logloss: 0.0837396\ttraining's f1: 0.694843\tvalid_1's binary_logloss: 0.0891246\tvalid_1's f1: 0.68448\n",
      "[93]\ttraining's binary_logloss: 0.0831115\ttraining's f1: 0.696071\tvalid_1's binary_logloss: 0.0885437\tvalid_1's f1: 0.685582\n",
      "[94]\ttraining's binary_logloss: 0.0826698\ttraining's f1: 0.696617\tvalid_1's binary_logloss: 0.0881475\tvalid_1's f1: 0.686114\n",
      "[95]\ttraining's binary_logloss: 0.0822271\ttraining's f1: 0.69749\tvalid_1's binary_logloss: 0.0877474\tvalid_1's f1: 0.686886\n",
      "[96]\ttraining's binary_logloss: 0.0817659\ttraining's f1: 0.698197\tvalid_1's binary_logloss: 0.0873095\tvalid_1's f1: 0.687497\n",
      "[97]\ttraining's binary_logloss: 0.0812348\ttraining's f1: 0.699125\tvalid_1's binary_logloss: 0.086816\tvalid_1's f1: 0.68821\n",
      "[98]\ttraining's binary_logloss: 0.0807167\ttraining's f1: 0.699973\tvalid_1's binary_logloss: 0.0863239\tvalid_1's f1: 0.689159\n",
      "[99]\ttraining's binary_logloss: 0.0802953\ttraining's f1: 0.700775\tvalid_1's binary_logloss: 0.0859243\tvalid_1's f1: 0.689731\n",
      "[100]\ttraining's binary_logloss: 0.0799245\ttraining's f1: 0.701374\tvalid_1's binary_logloss: 0.0855788\tvalid_1's f1: 0.690481\n",
      "[101]\ttraining's binary_logloss: 0.0794568\ttraining's f1: 0.702275\tvalid_1's binary_logloss: 0.0851474\tvalid_1's f1: 0.691125\n",
      "[102]\ttraining's binary_logloss: 0.0791742\ttraining's f1: 0.702741\tvalid_1's binary_logloss: 0.0848649\tvalid_1's f1: 0.691653\n",
      "[103]\ttraining's binary_logloss: 0.0787761\ttraining's f1: 0.703467\tvalid_1's binary_logloss: 0.0845275\tvalid_1's f1: 0.69205\n",
      "[104]\ttraining's binary_logloss: 0.0782668\ttraining's f1: 0.704256\tvalid_1's binary_logloss: 0.0840635\tvalid_1's f1: 0.692813\n",
      "[105]\ttraining's binary_logloss: 0.0779219\ttraining's f1: 0.704915\tvalid_1's binary_logloss: 0.0837383\tvalid_1's f1: 0.693452\n",
      "[106]\ttraining's binary_logloss: 0.0775735\ttraining's f1: 0.705548\tvalid_1's binary_logloss: 0.0834515\tvalid_1's f1: 0.693879\n",
      "[107]\ttraining's binary_logloss: 0.0770391\ttraining's f1: 0.706286\tvalid_1's binary_logloss: 0.0829415\tvalid_1's f1: 0.694418\n",
      "[108]\ttraining's binary_logloss: 0.0766721\ttraining's f1: 0.707\tvalid_1's binary_logloss: 0.0826048\tvalid_1's f1: 0.695071\n",
      "[109]\ttraining's binary_logloss: 0.0764392\ttraining's f1: 0.70749\tvalid_1's binary_logloss: 0.0823993\tvalid_1's f1: 0.695413\n",
      "[110]\ttraining's binary_logloss: 0.0760814\ttraining's f1: 0.708143\tvalid_1's binary_logloss: 0.08208\tvalid_1's f1: 0.695923\n",
      "[111]\ttraining's binary_logloss: 0.0756689\ttraining's f1: 0.708689\tvalid_1's binary_logloss: 0.0816924\tvalid_1's f1: 0.696397\n",
      "[112]\ttraining's binary_logloss: 0.0754189\ttraining's f1: 0.709132\tvalid_1's binary_logloss: 0.0814599\tvalid_1's f1: 0.696851\n",
      "[113]\ttraining's binary_logloss: 0.0749913\ttraining's f1: 0.709922\tvalid_1's binary_logloss: 0.081093\tvalid_1's f1: 0.697267\n",
      "[114]\ttraining's binary_logloss: 0.0747091\ttraining's f1: 0.710477\tvalid_1's binary_logloss: 0.0808335\tvalid_1's f1: 0.697575\n",
      "[115]\ttraining's binary_logloss: 0.074225\ttraining's f1: 0.711297\tvalid_1's binary_logloss: 0.0803952\tvalid_1's f1: 0.698352\n",
      "[116]\ttraining's binary_logloss: 0.0737329\ttraining's f1: 0.712388\tvalid_1's binary_logloss: 0.0799352\tvalid_1's f1: 0.69885\n",
      "[117]\ttraining's binary_logloss: 0.0735045\ttraining's f1: 0.712728\tvalid_1's binary_logloss: 0.079719\tvalid_1's f1: 0.699233\n",
      "[118]\ttraining's binary_logloss: 0.0731407\ttraining's f1: 0.713406\tvalid_1's binary_logloss: 0.0793975\tvalid_1's f1: 0.699882\n",
      "[119]\ttraining's binary_logloss: 0.0727452\ttraining's f1: 0.714231\tvalid_1's binary_logloss: 0.079054\tvalid_1's f1: 0.700356\n",
      "[120]\ttraining's binary_logloss: 0.0722395\ttraining's f1: 0.715371\tvalid_1's binary_logloss: 0.0785667\tvalid_1's f1: 0.701284\n",
      "[121]\ttraining's binary_logloss: 0.0718103\ttraining's f1: 0.716143\tvalid_1's binary_logloss: 0.0781655\tvalid_1's f1: 0.701862\n",
      "[122]\ttraining's binary_logloss: 0.0715208\ttraining's f1: 0.716714\tvalid_1's binary_logloss: 0.0778899\tvalid_1's f1: 0.702431\n",
      "[123]\ttraining's binary_logloss: 0.0711969\ttraining's f1: 0.717445\tvalid_1's binary_logloss: 0.0775919\tvalid_1's f1: 0.702932\n",
      "[124]\ttraining's binary_logloss: 0.0709347\ttraining's f1: 0.717872\tvalid_1's binary_logloss: 0.077345\tvalid_1's f1: 0.703285\n",
      "[125]\ttraining's binary_logloss: 0.0706911\ttraining's f1: 0.718443\tvalid_1's binary_logloss: 0.0771306\tvalid_1's f1: 0.703856\n",
      "[126]\ttraining's binary_logloss: 0.0703206\ttraining's f1: 0.719293\tvalid_1's binary_logloss: 0.0767866\tvalid_1's f1: 0.704553\n",
      "[127]\ttraining's binary_logloss: 0.0698574\ttraining's f1: 0.72027\tvalid_1's binary_logloss: 0.0763484\tvalid_1's f1: 0.705571\n",
      "[128]\ttraining's binary_logloss: 0.0696384\ttraining's f1: 0.720789\tvalid_1's binary_logloss: 0.0761422\tvalid_1's f1: 0.705878\n",
      "[129]\ttraining's binary_logloss: 0.0693535\ttraining's f1: 0.721286\tvalid_1's binary_logloss: 0.0758659\tvalid_1's f1: 0.706224\n",
      "[130]\ttraining's binary_logloss: 0.0688539\ttraining's f1: 0.722271\tvalid_1's binary_logloss: 0.0753554\tvalid_1's f1: 0.707\n",
      "[131]\ttraining's binary_logloss: 0.0685373\ttraining's f1: 0.722934\tvalid_1's binary_logloss: 0.0750548\tvalid_1's f1: 0.707552\n",
      "[132]\ttraining's binary_logloss: 0.0682469\ttraining's f1: 0.72362\tvalid_1's binary_logloss: 0.0747916\tvalid_1's f1: 0.708067\n",
      "[133]\ttraining's binary_logloss: 0.0678034\ttraining's f1: 0.724589\tvalid_1's binary_logloss: 0.0743857\tvalid_1's f1: 0.708799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134]\ttraining's binary_logloss: 0.0674047\ttraining's f1: 0.725627\tvalid_1's binary_logloss: 0.0740484\tvalid_1's f1: 0.709499\n",
      "[135]\ttraining's binary_logloss: 0.0671082\ttraining's f1: 0.726405\tvalid_1's binary_logloss: 0.0737783\tvalid_1's f1: 0.710134\n",
      "[136]\ttraining's binary_logloss: 0.0667834\ttraining's f1: 0.72701\tvalid_1's binary_logloss: 0.0735011\tvalid_1's f1: 0.710442\n",
      "[137]\ttraining's binary_logloss: 0.066589\ttraining's f1: 0.727461\tvalid_1's binary_logloss: 0.0733193\tvalid_1's f1: 0.710793\n",
      "[138]\ttraining's binary_logloss: 0.0663651\ttraining's f1: 0.727917\tvalid_1's binary_logloss: 0.0731179\tvalid_1's f1: 0.711244\n",
      "[139]\ttraining's binary_logloss: 0.0661435\ttraining's f1: 0.728475\tvalid_1's binary_logloss: 0.0729099\tvalid_1's f1: 0.711732\n",
      "[140]\ttraining's binary_logloss: 0.0658316\ttraining's f1: 0.729102\tvalid_1's binary_logloss: 0.0726073\tvalid_1's f1: 0.712442\n",
      "[141]\ttraining's binary_logloss: 0.0653931\ttraining's f1: 0.730501\tvalid_1's binary_logloss: 0.0722019\tvalid_1's f1: 0.713214\n",
      "[142]\ttraining's binary_logloss: 0.0650385\ttraining's f1: 0.731283\tvalid_1's binary_logloss: 0.0718792\tvalid_1's f1: 0.713962\n",
      "[143]\ttraining's binary_logloss: 0.0647202\ttraining's f1: 0.731902\tvalid_1's binary_logloss: 0.0716009\tvalid_1's f1: 0.714494\n",
      "[144]\ttraining's binary_logloss: 0.0644856\ttraining's f1: 0.732425\tvalid_1's binary_logloss: 0.0713878\tvalid_1's f1: 0.714837\n",
      "[145]\ttraining's binary_logloss: 0.0641601\ttraining's f1: 0.733305\tvalid_1's binary_logloss: 0.0711062\tvalid_1's f1: 0.715481\n",
      "[146]\ttraining's binary_logloss: 0.0638801\ttraining's f1: 0.733899\tvalid_1's binary_logloss: 0.0708433\tvalid_1's f1: 0.715931\n",
      "[147]\ttraining's binary_logloss: 0.0636054\ttraining's f1: 0.734534\tvalid_1's binary_logloss: 0.0705888\tvalid_1's f1: 0.716506\n",
      "[148]\ttraining's binary_logloss: 0.0633906\ttraining's f1: 0.735037\tvalid_1's binary_logloss: 0.0703969\tvalid_1's f1: 0.716811\n",
      "[149]\ttraining's binary_logloss: 0.0631436\ttraining's f1: 0.735669\tvalid_1's binary_logloss: 0.0701876\tvalid_1's f1: 0.717256\n",
      "[150]\ttraining's binary_logloss: 0.0629038\ttraining's f1: 0.736203\tvalid_1's binary_logloss: 0.0699711\tvalid_1's f1: 0.717741\n",
      "[151]\ttraining's binary_logloss: 0.062715\ttraining's f1: 0.736685\tvalid_1's binary_logloss: 0.0698025\tvalid_1's f1: 0.717968\n",
      "[152]\ttraining's binary_logloss: 0.0624675\ttraining's f1: 0.73745\tvalid_1's binary_logloss: 0.0695665\tvalid_1's f1: 0.718774\n",
      "[153]\ttraining's binary_logloss: 0.0621938\ttraining's f1: 0.737981\tvalid_1's binary_logloss: 0.0693289\tvalid_1's f1: 0.719149\n",
      "[154]\ttraining's binary_logloss: 0.0618687\ttraining's f1: 0.738812\tvalid_1's binary_logloss: 0.0690062\tvalid_1's f1: 0.719842\n",
      "[155]\ttraining's binary_logloss: 0.0614544\ttraining's f1: 0.73991\tvalid_1's binary_logloss: 0.0686388\tvalid_1's f1: 0.720598\n",
      "[156]\ttraining's binary_logloss: 0.0611833\ttraining's f1: 0.740506\tvalid_1's binary_logloss: 0.0684033\tvalid_1's f1: 0.721071\n",
      "[157]\ttraining's binary_logloss: 0.0608125\ttraining's f1: 0.741315\tvalid_1's binary_logloss: 0.068079\tvalid_1's f1: 0.721457\n",
      "[158]\ttraining's binary_logloss: 0.0605018\ttraining's f1: 0.741981\tvalid_1's binary_logloss: 0.0678286\tvalid_1's f1: 0.721896\n",
      "[159]\ttraining's binary_logloss: 0.0602125\ttraining's f1: 0.742734\tvalid_1's binary_logloss: 0.0675568\tvalid_1's f1: 0.722407\n",
      "[160]\ttraining's binary_logloss: 0.0600382\ttraining's f1: 0.743295\tvalid_1's binary_logloss: 0.0674019\tvalid_1's f1: 0.722736\n",
      "[161]\ttraining's binary_logloss: 0.0597486\ttraining's f1: 0.7442\tvalid_1's binary_logloss: 0.0671465\tvalid_1's f1: 0.723552\n",
      "[162]\ttraining's binary_logloss: 0.0595621\ttraining's f1: 0.744458\tvalid_1's binary_logloss: 0.0669707\tvalid_1's f1: 0.723825\n",
      "[163]\ttraining's binary_logloss: 0.0592369\ttraining's f1: 0.745352\tvalid_1's binary_logloss: 0.0666706\tvalid_1's f1: 0.724566\n",
      "[164]\ttraining's binary_logloss: 0.058962\ttraining's f1: 0.746005\tvalid_1's binary_logloss: 0.0664322\tvalid_1's f1: 0.72505\n",
      "[165]\ttraining's binary_logloss: 0.0587767\ttraining's f1: 0.746451\tvalid_1's binary_logloss: 0.0662611\tvalid_1's f1: 0.72537\n",
      "[166]\ttraining's binary_logloss: 0.0585414\ttraining's f1: 0.747233\tvalid_1's binary_logloss: 0.0660389\tvalid_1's f1: 0.725947\n",
      "[167]\ttraining's binary_logloss: 0.0582659\ttraining's f1: 0.747794\tvalid_1's binary_logloss: 0.0657895\tvalid_1's f1: 0.726441\n",
      "[168]\ttraining's binary_logloss: 0.0581015\ttraining's f1: 0.748198\tvalid_1's binary_logloss: 0.0656307\tvalid_1's f1: 0.726722\n",
      "[169]\ttraining's binary_logloss: 0.0579101\ttraining's f1: 0.74869\tvalid_1's binary_logloss: 0.0654604\tvalid_1's f1: 0.727117\n",
      "[170]\ttraining's binary_logloss: 0.0576424\ttraining's f1: 0.749387\tvalid_1's binary_logloss: 0.0652258\tvalid_1's f1: 0.727504\n",
      "[171]\ttraining's binary_logloss: 0.0573441\ttraining's f1: 0.749995\tvalid_1's binary_logloss: 0.0649669\tvalid_1's f1: 0.728015\n",
      "[172]\ttraining's binary_logloss: 0.0572111\ttraining's f1: 0.750308\tvalid_1's binary_logloss: 0.0648393\tvalid_1's f1: 0.728292\n",
      "[173]\ttraining's binary_logloss: 0.0570492\ttraining's f1: 0.750797\tvalid_1's binary_logloss: 0.0647027\tvalid_1's f1: 0.728591\n",
      "[174]\ttraining's binary_logloss: 0.0568194\ttraining's f1: 0.751303\tvalid_1's binary_logloss: 0.0644972\tvalid_1's f1: 0.728772\n",
      "[175]\ttraining's binary_logloss: 0.0565641\ttraining's f1: 0.752029\tvalid_1's binary_logloss: 0.0642482\tvalid_1's f1: 0.729435\n",
      "[176]\ttraining's binary_logloss: 0.0562216\ttraining's f1: 0.753121\tvalid_1's binary_logloss: 0.0639322\tvalid_1's f1: 0.730262\n",
      "[177]\ttraining's binary_logloss: 0.0559805\ttraining's f1: 0.75371\tvalid_1's binary_logloss: 0.0637267\tvalid_1's f1: 0.73075\n",
      "[178]\ttraining's binary_logloss: 0.0557254\ttraining's f1: 0.754382\tvalid_1's binary_logloss: 0.0635037\tvalid_1's f1: 0.731167\n",
      "[179]\ttraining's binary_logloss: 0.0555037\ttraining's f1: 0.7548\tvalid_1's binary_logloss: 0.0633333\tvalid_1's f1: 0.731607\n",
      "[180]\ttraining's binary_logloss: 0.0553102\ttraining's f1: 0.755442\tvalid_1's binary_logloss: 0.06316\tvalid_1's f1: 0.732134\n",
      "[181]\ttraining's binary_logloss: 0.0551563\ttraining's f1: 0.755887\tvalid_1's binary_logloss: 0.0630335\tvalid_1's f1: 0.732364\n",
      "[182]\ttraining's binary_logloss: 0.054918\ttraining's f1: 0.756641\tvalid_1's binary_logloss: 0.0628256\tvalid_1's f1: 0.733041\n",
      "[183]\ttraining's binary_logloss: 0.0545977\ttraining's f1: 0.757738\tvalid_1's binary_logloss: 0.0625133\tvalid_1's f1: 0.734118\n",
      "[184]\ttraining's binary_logloss: 0.0543835\ttraining's f1: 0.758223\tvalid_1's binary_logloss: 0.0623249\tvalid_1's f1: 0.734611\n",
      "[185]\ttraining's binary_logloss: 0.0540673\ttraining's f1: 0.759126\tvalid_1's binary_logloss: 0.0620149\tvalid_1's f1: 0.734997\n",
      "[186]\ttraining's binary_logloss: 0.0539498\ttraining's f1: 0.759453\tvalid_1's binary_logloss: 0.0619119\tvalid_1's f1: 0.735159\n",
      "[187]\ttraining's binary_logloss: 0.0538271\ttraining's f1: 0.759787\tvalid_1's binary_logloss: 0.0618077\tvalid_1's f1: 0.735299\n",
      "[188]\ttraining's binary_logloss: 0.0536279\ttraining's f1: 0.760179\tvalid_1's binary_logloss: 0.0616362\tvalid_1's f1: 0.735591\n",
      "[189]\ttraining's binary_logloss: 0.0534084\ttraining's f1: 0.760755\tvalid_1's binary_logloss: 0.0614276\tvalid_1's f1: 0.736157\n",
      "[190]\ttraining's binary_logloss: 0.0530806\ttraining's f1: 0.761871\tvalid_1's binary_logloss: 0.0611165\tvalid_1's f1: 0.736713\n",
      "[191]\ttraining's binary_logloss: 0.0528723\ttraining's f1: 0.762587\tvalid_1's binary_logloss: 0.0609275\tvalid_1's f1: 0.737251\n",
      "[192]\ttraining's binary_logloss: 0.0526755\ttraining's f1: 0.763115\tvalid_1's binary_logloss: 0.0607407\tvalid_1's f1: 0.737647\n",
      "[193]\ttraining's binary_logloss: 0.0525538\ttraining's f1: 0.763483\tvalid_1's binary_logloss: 0.0606348\tvalid_1's f1: 0.737824\n",
      "[194]\ttraining's binary_logloss: 0.0523357\ttraining's f1: 0.764127\tvalid_1's binary_logloss: 0.0604391\tvalid_1's f1: 0.738333\n",
      "[195]\ttraining's binary_logloss: 0.0521038\ttraining's f1: 0.764816\tvalid_1's binary_logloss: 0.0602405\tvalid_1's f1: 0.738767\n",
      "[196]\ttraining's binary_logloss: 0.0519078\ttraining's f1: 0.765249\tvalid_1's binary_logloss: 0.0600558\tvalid_1's f1: 0.739145\n",
      "[197]\ttraining's binary_logloss: 0.0517288\ttraining's f1: 0.765873\tvalid_1's binary_logloss: 0.059901\tvalid_1's f1: 0.739592\n",
      "[198]\ttraining's binary_logloss: 0.0515209\ttraining's f1: 0.766374\tvalid_1's binary_logloss: 0.0597034\tvalid_1's f1: 0.739851\n",
      "[199]\ttraining's binary_logloss: 0.0514239\ttraining's f1: 0.766614\tvalid_1's binary_logloss: 0.0596159\tvalid_1's f1: 0.740064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's binary_logloss: 0.0512414\ttraining's f1: 0.767161\tvalid_1's binary_logloss: 0.0594422\tvalid_1's f1: 0.740468\n",
      "[201]\ttraining's binary_logloss: 0.05099\ttraining's f1: 0.768019\tvalid_1's binary_logloss: 0.0592144\tvalid_1's f1: 0.741169\n",
      "[202]\ttraining's binary_logloss: 0.0508542\ttraining's f1: 0.768439\tvalid_1's binary_logloss: 0.0590894\tvalid_1's f1: 0.741397\n",
      "[203]\ttraining's binary_logloss: 0.0506098\ttraining's f1: 0.769104\tvalid_1's binary_logloss: 0.0588609\tvalid_1's f1: 0.741841\n",
      "[204]\ttraining's binary_logloss: 0.0504007\ttraining's f1: 0.769705\tvalid_1's binary_logloss: 0.0586819\tvalid_1's f1: 0.742308\n",
      "[205]\ttraining's binary_logloss: 0.0501055\ttraining's f1: 0.770477\tvalid_1's binary_logloss: 0.0583976\tvalid_1's f1: 0.743158\n",
      "[206]\ttraining's binary_logloss: 0.0499214\ttraining's f1: 0.771207\tvalid_1's binary_logloss: 0.0582334\tvalid_1's f1: 0.743704\n",
      "[207]\ttraining's binary_logloss: 0.0497404\ttraining's f1: 0.771681\tvalid_1's binary_logloss: 0.0580726\tvalid_1's f1: 0.744178\n",
      "[208]\ttraining's binary_logloss: 0.049558\ttraining's f1: 0.772231\tvalid_1's binary_logloss: 0.0578904\tvalid_1's f1: 0.744517\n",
      "[209]\ttraining's binary_logloss: 0.0492885\ttraining's f1: 0.773127\tvalid_1's binary_logloss: 0.0576531\tvalid_1's f1: 0.745249\n",
      "[210]\ttraining's binary_logloss: 0.0491171\ttraining's f1: 0.773732\tvalid_1's binary_logloss: 0.057492\tvalid_1's f1: 0.745647\n",
      "[211]\ttraining's binary_logloss: 0.0489366\ttraining's f1: 0.774295\tvalid_1's binary_logloss: 0.0573389\tvalid_1's f1: 0.745902\n",
      "[212]\ttraining's binary_logloss: 0.048777\ttraining's f1: 0.774629\tvalid_1's binary_logloss: 0.0571736\tvalid_1's f1: 0.746203\n",
      "[213]\ttraining's binary_logloss: 0.0486201\ttraining's f1: 0.775165\tvalid_1's binary_logloss: 0.0570258\tvalid_1's f1: 0.746467\n",
      "[214]\ttraining's binary_logloss: 0.0483837\ttraining's f1: 0.77609\tvalid_1's binary_logloss: 0.056797\tvalid_1's f1: 0.747248\n",
      "[215]\ttraining's binary_logloss: 0.0482013\ttraining's f1: 0.776667\tvalid_1's binary_logloss: 0.0566548\tvalid_1's f1: 0.747501\n",
      "[216]\ttraining's binary_logloss: 0.0480426\ttraining's f1: 0.777041\tvalid_1's binary_logloss: 0.0565281\tvalid_1's f1: 0.7479\n",
      "[217]\ttraining's binary_logloss: 0.0479093\ttraining's f1: 0.777481\tvalid_1's binary_logloss: 0.0564222\tvalid_1's f1: 0.748183\n",
      "[218]\ttraining's binary_logloss: 0.0476764\ttraining's f1: 0.778216\tvalid_1's binary_logloss: 0.0561992\tvalid_1's f1: 0.748986\n",
      "[219]\ttraining's binary_logloss: 0.0473575\ttraining's f1: 0.779287\tvalid_1's binary_logloss: 0.0559084\tvalid_1's f1: 0.749746\n",
      "[220]\ttraining's binary_logloss: 0.0470628\ttraining's f1: 0.78036\tvalid_1's binary_logloss: 0.0556661\tvalid_1's f1: 0.750298\n",
      "[221]\ttraining's binary_logloss: 0.0468252\ttraining's f1: 0.780893\tvalid_1's binary_logloss: 0.0554402\tvalid_1's f1: 0.750781\n",
      "[222]\ttraining's binary_logloss: 0.0466152\ttraining's f1: 0.781518\tvalid_1's binary_logloss: 0.055272\tvalid_1's f1: 0.751267\n",
      "[223]\ttraining's binary_logloss: 0.0464388\ttraining's f1: 0.78194\tvalid_1's binary_logloss: 0.0551163\tvalid_1's f1: 0.751927\n",
      "[224]\ttraining's binary_logloss: 0.0462575\ttraining's f1: 0.782624\tvalid_1's binary_logloss: 0.0549776\tvalid_1's f1: 0.752141\n",
      "[225]\ttraining's binary_logloss: 0.0460865\ttraining's f1: 0.78333\tvalid_1's binary_logloss: 0.0548308\tvalid_1's f1: 0.75268\n",
      "[226]\ttraining's binary_logloss: 0.0459728\ttraining's f1: 0.783543\tvalid_1's binary_logloss: 0.0547282\tvalid_1's f1: 0.753051\n",
      "[227]\ttraining's binary_logloss: 0.0458336\ttraining's f1: 0.783922\tvalid_1's binary_logloss: 0.054609\tvalid_1's f1: 0.753134\n",
      "[228]\ttraining's binary_logloss: 0.0456906\ttraining's f1: 0.784375\tvalid_1's binary_logloss: 0.0544881\tvalid_1's f1: 0.753335\n",
      "[229]\ttraining's binary_logloss: 0.0455474\ttraining's f1: 0.784959\tvalid_1's binary_logloss: 0.0543453\tvalid_1's f1: 0.753868\n",
      "[230]\ttraining's binary_logloss: 0.0454133\ttraining's f1: 0.785434\tvalid_1's binary_logloss: 0.0542227\tvalid_1's f1: 0.754139\n",
      "[231]\ttraining's binary_logloss: 0.0452536\ttraining's f1: 0.786103\tvalid_1's binary_logloss: 0.0540865\tvalid_1's f1: 0.754615\n",
      "[232]\ttraining's binary_logloss: 0.045063\ttraining's f1: 0.78673\tvalid_1's binary_logloss: 0.0539177\tvalid_1's f1: 0.755265\n",
      "[233]\ttraining's binary_logloss: 0.0449114\ttraining's f1: 0.787323\tvalid_1's binary_logloss: 0.0537685\tvalid_1's f1: 0.755672\n",
      "[234]\ttraining's binary_logloss: 0.0447666\ttraining's f1: 0.78778\tvalid_1's binary_logloss: 0.0536291\tvalid_1's f1: 0.755868\n",
      "[235]\ttraining's binary_logloss: 0.0445867\ttraining's f1: 0.788459\tvalid_1's binary_logloss: 0.0534777\tvalid_1's f1: 0.756442\n",
      "[236]\ttraining's binary_logloss: 0.0444424\ttraining's f1: 0.788875\tvalid_1's binary_logloss: 0.0533593\tvalid_1's f1: 0.756729\n",
      "[237]\ttraining's binary_logloss: 0.0443417\ttraining's f1: 0.789134\tvalid_1's binary_logloss: 0.0532754\tvalid_1's f1: 0.756904\n",
      "[238]\ttraining's binary_logloss: 0.0441814\ttraining's f1: 0.789653\tvalid_1's binary_logloss: 0.0531235\tvalid_1's f1: 0.75741\n",
      "[239]\ttraining's binary_logloss: 0.0439312\ttraining's f1: 0.790569\tvalid_1's binary_logloss: 0.0528958\tvalid_1's f1: 0.757994\n",
      "[240]\ttraining's binary_logloss: 0.043767\ttraining's f1: 0.790946\tvalid_1's binary_logloss: 0.0527651\tvalid_1's f1: 0.758268\n",
      "[241]\ttraining's binary_logloss: 0.0435975\ttraining's f1: 0.791606\tvalid_1's binary_logloss: 0.0526167\tvalid_1's f1: 0.758637\n",
      "[242]\ttraining's binary_logloss: 0.0434141\ttraining's f1: 0.792159\tvalid_1's binary_logloss: 0.0524527\tvalid_1's f1: 0.758968\n",
      "[243]\ttraining's binary_logloss: 0.0433185\ttraining's f1: 0.792385\tvalid_1's binary_logloss: 0.0523747\tvalid_1's f1: 0.759102\n",
      "[244]\ttraining's binary_logloss: 0.043198\ttraining's f1: 0.79285\tvalid_1's binary_logloss: 0.0522574\tvalid_1's f1: 0.759556\n",
      "[245]\ttraining's binary_logloss: 0.0430555\ttraining's f1: 0.793304\tvalid_1's binary_logloss: 0.0521451\tvalid_1's f1: 0.759855\n",
      "[246]\ttraining's binary_logloss: 0.0429677\ttraining's f1: 0.793583\tvalid_1's binary_logloss: 0.0520621\tvalid_1's f1: 0.760059\n",
      "[247]\ttraining's binary_logloss: 0.0428067\ttraining's f1: 0.794208\tvalid_1's binary_logloss: 0.0519138\tvalid_1's f1: 0.760482\n",
      "[248]\ttraining's binary_logloss: 0.0426929\ttraining's f1: 0.794731\tvalid_1's binary_logloss: 0.0518042\tvalid_1's f1: 0.760608\n",
      "[249]\ttraining's binary_logloss: 0.0425074\ttraining's f1: 0.795335\tvalid_1's binary_logloss: 0.0516193\tvalid_1's f1: 0.761077\n",
      "[250]\ttraining's binary_logloss: 0.0422843\ttraining's f1: 0.79629\tvalid_1's binary_logloss: 0.0514136\tvalid_1's f1: 0.761807\n",
      "[251]\ttraining's binary_logloss: 0.0420773\ttraining's f1: 0.797132\tvalid_1's binary_logloss: 0.05123\tvalid_1's f1: 0.762568\n",
      "[252]\ttraining's binary_logloss: 0.0419375\ttraining's f1: 0.797665\tvalid_1's binary_logloss: 0.0511186\tvalid_1's f1: 0.762955\n",
      "[253]\ttraining's binary_logloss: 0.0417953\ttraining's f1: 0.798145\tvalid_1's binary_logloss: 0.0509877\tvalid_1's f1: 0.763382\n",
      "[254]\ttraining's binary_logloss: 0.041711\ttraining's f1: 0.798493\tvalid_1's binary_logloss: 0.0509037\tvalid_1's f1: 0.763548\n",
      "[255]\ttraining's binary_logloss: 0.0415931\ttraining's f1: 0.798815\tvalid_1's binary_logloss: 0.050798\tvalid_1's f1: 0.764053\n",
      "[256]\ttraining's binary_logloss: 0.0413982\ttraining's f1: 0.799401\tvalid_1's binary_logloss: 0.0506105\tvalid_1's f1: 0.764574\n",
      "[257]\ttraining's binary_logloss: 0.0412037\ttraining's f1: 0.800238\tvalid_1's binary_logloss: 0.0504427\tvalid_1's f1: 0.765031\n",
      "[258]\ttraining's binary_logloss: 0.0410505\ttraining's f1: 0.80074\tvalid_1's binary_logloss: 0.0503035\tvalid_1's f1: 0.765137\n",
      "[259]\ttraining's binary_logloss: 0.0409307\ttraining's f1: 0.801121\tvalid_1's binary_logloss: 0.0501846\tvalid_1's f1: 0.765382\n",
      "[260]\ttraining's binary_logloss: 0.0408139\ttraining's f1: 0.801571\tvalid_1's binary_logloss: 0.0500678\tvalid_1's f1: 0.765817\n",
      "[261]\ttraining's binary_logloss: 0.0405755\ttraining's f1: 0.802489\tvalid_1's binary_logloss: 0.049847\tvalid_1's f1: 0.766741\n",
      "[262]\ttraining's binary_logloss: 0.0403746\ttraining's f1: 0.803218\tvalid_1's binary_logloss: 0.0496538\tvalid_1's f1: 0.767103\n",
      "[263]\ttraining's binary_logloss: 0.0402594\ttraining's f1: 0.803826\tvalid_1's binary_logloss: 0.0495449\tvalid_1's f1: 0.767566\n",
      "[264]\ttraining's binary_logloss: 0.0401169\ttraining's f1: 0.804388\tvalid_1's binary_logloss: 0.049427\tvalid_1's f1: 0.768083\n",
      "[265]\ttraining's binary_logloss: 0.0399356\ttraining's f1: 0.805112\tvalid_1's binary_logloss: 0.049265\tvalid_1's f1: 0.7685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[266]\ttraining's binary_logloss: 0.0397897\ttraining's f1: 0.805517\tvalid_1's binary_logloss: 0.0491333\tvalid_1's f1: 0.768784\n",
      "[267]\ttraining's binary_logloss: 0.0396575\ttraining's f1: 0.806077\tvalid_1's binary_logloss: 0.0490189\tvalid_1's f1: 0.769314\n",
      "[268]\ttraining's binary_logloss: 0.0395315\ttraining's f1: 0.806506\tvalid_1's binary_logloss: 0.0489085\tvalid_1's f1: 0.769728\n",
      "[269]\ttraining's binary_logloss: 0.0394242\ttraining's f1: 0.806829\tvalid_1's binary_logloss: 0.0488173\tvalid_1's f1: 0.769952\n",
      "[270]\ttraining's binary_logloss: 0.0391756\ttraining's f1: 0.807968\tvalid_1's binary_logloss: 0.04858\tvalid_1's f1: 0.771137\n",
      "[271]\ttraining's binary_logloss: 0.0390183\ttraining's f1: 0.808487\tvalid_1's binary_logloss: 0.0484246\tvalid_1's f1: 0.771732\n",
      "[272]\ttraining's binary_logloss: 0.0388906\ttraining's f1: 0.809179\tvalid_1's binary_logloss: 0.048319\tvalid_1's f1: 0.77205\n",
      "[273]\ttraining's binary_logloss: 0.0388229\ttraining's f1: 0.809365\tvalid_1's binary_logloss: 0.0482557\tvalid_1's f1: 0.772156\n",
      "[274]\ttraining's binary_logloss: 0.0387253\ttraining's f1: 0.809823\tvalid_1's binary_logloss: 0.0481672\tvalid_1's f1: 0.772433\n",
      "[275]\ttraining's binary_logloss: 0.0385752\ttraining's f1: 0.810614\tvalid_1's binary_logloss: 0.0480312\tvalid_1's f1: 0.772796\n",
      "[276]\ttraining's binary_logloss: 0.0384667\ttraining's f1: 0.81086\tvalid_1's binary_logloss: 0.0479364\tvalid_1's f1: 0.773248\n",
      "[277]\ttraining's binary_logloss: 0.0382289\ttraining's f1: 0.811743\tvalid_1's binary_logloss: 0.0477027\tvalid_1's f1: 0.77396\n",
      "[278]\ttraining's binary_logloss: 0.0380948\ttraining's f1: 0.812208\tvalid_1's binary_logloss: 0.0475868\tvalid_1's f1: 0.774364\n",
      "[279]\ttraining's binary_logloss: 0.0379407\ttraining's f1: 0.812835\tvalid_1's binary_logloss: 0.04745\tvalid_1's f1: 0.774574\n",
      "[280]\ttraining's binary_logloss: 0.0378085\ttraining's f1: 0.813391\tvalid_1's binary_logloss: 0.0473397\tvalid_1's f1: 0.77482\n",
      "[281]\ttraining's binary_logloss: 0.0377109\ttraining's f1: 0.813743\tvalid_1's binary_logloss: 0.0472549\tvalid_1's f1: 0.775009\n",
      "[282]\ttraining's binary_logloss: 0.0374827\ttraining's f1: 0.814715\tvalid_1's binary_logloss: 0.0470476\tvalid_1's f1: 0.775774\n",
      "[283]\ttraining's binary_logloss: 0.037327\ttraining's f1: 0.815641\tvalid_1's binary_logloss: 0.0469142\tvalid_1's f1: 0.77625\n",
      "[284]\ttraining's binary_logloss: 0.0372593\ttraining's f1: 0.815894\tvalid_1's binary_logloss: 0.0468584\tvalid_1's f1: 0.77647\n",
      "[285]\ttraining's binary_logloss: 0.0371483\ttraining's f1: 0.816251\tvalid_1's binary_logloss: 0.0467591\tvalid_1's f1: 0.776662\n",
      "[286]\ttraining's binary_logloss: 0.0370274\ttraining's f1: 0.816818\tvalid_1's binary_logloss: 0.0466555\tvalid_1's f1: 0.777075\n",
      "[287]\ttraining's binary_logloss: 0.036898\ttraining's f1: 0.817305\tvalid_1's binary_logloss: 0.0465412\tvalid_1's f1: 0.77732\n",
      "[288]\ttraining's binary_logloss: 0.0367881\ttraining's f1: 0.817635\tvalid_1's binary_logloss: 0.0464407\tvalid_1's f1: 0.777793\n",
      "[289]\ttraining's binary_logloss: 0.0366559\ttraining's f1: 0.818169\tvalid_1's binary_logloss: 0.0463225\tvalid_1's f1: 0.778291\n",
      "[290]\ttraining's binary_logloss: 0.0365323\ttraining's f1: 0.818554\tvalid_1's binary_logloss: 0.0462073\tvalid_1's f1: 0.77876\n",
      "[291]\ttraining's binary_logloss: 0.0363831\ttraining's f1: 0.819129\tvalid_1's binary_logloss: 0.0460824\tvalid_1's f1: 0.778994\n",
      "[292]\ttraining's binary_logloss: 0.0362618\ttraining's f1: 0.819577\tvalid_1's binary_logloss: 0.0459856\tvalid_1's f1: 0.779144\n",
      "[293]\ttraining's binary_logloss: 0.0361793\ttraining's f1: 0.819866\tvalid_1's binary_logloss: 0.045914\tvalid_1's f1: 0.779331\n",
      "[294]\ttraining's binary_logloss: 0.0359942\ttraining's f1: 0.820629\tvalid_1's binary_logloss: 0.0457475\tvalid_1's f1: 0.779724\n",
      "[295]\ttraining's binary_logloss: 0.0359327\ttraining's f1: 0.820782\tvalid_1's binary_logloss: 0.0456942\tvalid_1's f1: 0.77992\n",
      "[296]\ttraining's binary_logloss: 0.035806\ttraining's f1: 0.821257\tvalid_1's binary_logloss: 0.0455839\tvalid_1's f1: 0.780163\n",
      "[297]\ttraining's binary_logloss: 0.035717\ttraining's f1: 0.821526\tvalid_1's binary_logloss: 0.0455045\tvalid_1's f1: 0.780458\n",
      "[298]\ttraining's binary_logloss: 0.0355675\ttraining's f1: 0.822064\tvalid_1's binary_logloss: 0.0453766\tvalid_1's f1: 0.780754\n",
      "[299]\ttraining's binary_logloss: 0.0354513\ttraining's f1: 0.822566\tvalid_1's binary_logloss: 0.0452679\tvalid_1's f1: 0.780985\n",
      "[300]\ttraining's binary_logloss: 0.0353018\ttraining's f1: 0.823162\tvalid_1's binary_logloss: 0.0451228\tvalid_1's f1: 0.781631\n",
      "[301]\ttraining's binary_logloss: 0.0352226\ttraining's f1: 0.823449\tvalid_1's binary_logloss: 0.0450601\tvalid_1's f1: 0.781875\n",
      "[302]\ttraining's binary_logloss: 0.0350955\ttraining's f1: 0.824033\tvalid_1's binary_logloss: 0.0449492\tvalid_1's f1: 0.782201\n",
      "[303]\ttraining's binary_logloss: 0.0349818\ttraining's f1: 0.824408\tvalid_1's binary_logloss: 0.0448497\tvalid_1's f1: 0.78247\n",
      "[304]\ttraining's binary_logloss: 0.0348307\ttraining's f1: 0.825112\tvalid_1's binary_logloss: 0.044721\tvalid_1's f1: 0.782982\n",
      "[305]\ttraining's binary_logloss: 0.0346642\ttraining's f1: 0.82578\tvalid_1's binary_logloss: 0.0445513\tvalid_1's f1: 0.78364\n",
      "[306]\ttraining's binary_logloss: 0.0345483\ttraining's f1: 0.826348\tvalid_1's binary_logloss: 0.0444555\tvalid_1's f1: 0.784095\n",
      "[307]\ttraining's binary_logloss: 0.0344905\ttraining's f1: 0.826569\tvalid_1's binary_logloss: 0.044405\tvalid_1's f1: 0.784297\n",
      "[308]\ttraining's binary_logloss: 0.0343774\ttraining's f1: 0.827068\tvalid_1's binary_logloss: 0.0443022\tvalid_1's f1: 0.78464\n",
      "[309]\ttraining's binary_logloss: 0.0342492\ttraining's f1: 0.827513\tvalid_1's binary_logloss: 0.0442146\tvalid_1's f1: 0.784836\n",
      "[310]\ttraining's binary_logloss: 0.0340843\ttraining's f1: 0.828182\tvalid_1's binary_logloss: 0.0440579\tvalid_1's f1: 0.785408\n",
      "[311]\ttraining's binary_logloss: 0.0339588\ttraining's f1: 0.828902\tvalid_1's binary_logloss: 0.0439472\tvalid_1's f1: 0.785746\n",
      "[312]\ttraining's binary_logloss: 0.0338893\ttraining's f1: 0.829078\tvalid_1's binary_logloss: 0.0438842\tvalid_1's f1: 0.785998\n",
      "[313]\ttraining's binary_logloss: 0.0338185\ttraining's f1: 0.829335\tvalid_1's binary_logloss: 0.043821\tvalid_1's f1: 0.786039\n",
      "[314]\ttraining's binary_logloss: 0.0337145\ttraining's f1: 0.829834\tvalid_1's binary_logloss: 0.043727\tvalid_1's f1: 0.786335\n",
      "[315]\ttraining's binary_logloss: 0.0336116\ttraining's f1: 0.830245\tvalid_1's binary_logloss: 0.0436422\tvalid_1's f1: 0.786623\n",
      "[316]\ttraining's binary_logloss: 0.0335297\ttraining's f1: 0.830601\tvalid_1's binary_logloss: 0.0435617\tvalid_1's f1: 0.786981\n",
      "[317]\ttraining's binary_logloss: 0.0333801\ttraining's f1: 0.831323\tvalid_1's binary_logloss: 0.0434211\tvalid_1's f1: 0.787387\n",
      "[318]\ttraining's binary_logloss: 0.0332644\ttraining's f1: 0.831762\tvalid_1's binary_logloss: 0.0433168\tvalid_1's f1: 0.787715\n",
      "[319]\ttraining's binary_logloss: 0.0331564\ttraining's f1: 0.832267\tvalid_1's binary_logloss: 0.0432141\tvalid_1's f1: 0.788109\n",
      "[320]\ttraining's binary_logloss: 0.0330125\ttraining's f1: 0.832914\tvalid_1's binary_logloss: 0.0430931\tvalid_1's f1: 0.788438\n",
      "[321]\ttraining's binary_logloss: 0.0329067\ttraining's f1: 0.833341\tvalid_1's binary_logloss: 0.0430059\tvalid_1's f1: 0.788713\n",
      "[322]\ttraining's binary_logloss: 0.0328388\ttraining's f1: 0.833563\tvalid_1's binary_logloss: 0.0429452\tvalid_1's f1: 0.788879\n",
      "[323]\ttraining's binary_logloss: 0.0326776\ttraining's f1: 0.834139\tvalid_1's binary_logloss: 0.0427823\tvalid_1's f1: 0.789668\n",
      "[324]\ttraining's binary_logloss: 0.0325886\ttraining's f1: 0.834437\tvalid_1's binary_logloss: 0.0427203\tvalid_1's f1: 0.789916\n",
      "[325]\ttraining's binary_logloss: 0.0325172\ttraining's f1: 0.834842\tvalid_1's binary_logloss: 0.0426665\tvalid_1's f1: 0.790072\n",
      "[326]\ttraining's binary_logloss: 0.0324426\ttraining's f1: 0.835191\tvalid_1's binary_logloss: 0.0425974\tvalid_1's f1: 0.790379\n",
      "[327]\ttraining's binary_logloss: 0.032344\ttraining's f1: 0.835482\tvalid_1's binary_logloss: 0.0425092\tvalid_1's f1: 0.790682\n",
      "[328]\ttraining's binary_logloss: 0.0322544\ttraining's f1: 0.835823\tvalid_1's binary_logloss: 0.0424255\tvalid_1's f1: 0.791087\n",
      "[329]\ttraining's binary_logloss: 0.0321604\ttraining's f1: 0.836123\tvalid_1's binary_logloss: 0.0423442\tvalid_1's f1: 0.791244\n",
      "[330]\ttraining's binary_logloss: 0.0320316\ttraining's f1: 0.836675\tvalid_1's binary_logloss: 0.0422289\tvalid_1's f1: 0.791652\n",
      "[331]\ttraining's binary_logloss: 0.031865\ttraining's f1: 0.837413\tvalid_1's binary_logloss: 0.0420715\tvalid_1's f1: 0.792301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332]\ttraining's binary_logloss: 0.0317245\ttraining's f1: 0.838272\tvalid_1's binary_logloss: 0.04195\tvalid_1's f1: 0.792701\n",
      "[333]\ttraining's binary_logloss: 0.0316299\ttraining's f1: 0.838551\tvalid_1's binary_logloss: 0.0418846\tvalid_1's f1: 0.792641\n",
      "[334]\ttraining's binary_logloss: 0.0315373\ttraining's f1: 0.838856\tvalid_1's binary_logloss: 0.0418053\tvalid_1's f1: 0.793146\n",
      "[335]\ttraining's binary_logloss: 0.0314407\ttraining's f1: 0.839424\tvalid_1's binary_logloss: 0.0417258\tvalid_1's f1: 0.793608\n",
      "[336]\ttraining's binary_logloss: 0.0313843\ttraining's f1: 0.839586\tvalid_1's binary_logloss: 0.0416767\tvalid_1's f1: 0.793615\n",
      "[337]\ttraining's binary_logloss: 0.0312982\ttraining's f1: 0.839901\tvalid_1's binary_logloss: 0.0415985\tvalid_1's f1: 0.793851\n",
      "[338]\ttraining's binary_logloss: 0.0312247\ttraining's f1: 0.84031\tvalid_1's binary_logloss: 0.0415287\tvalid_1's f1: 0.794118\n",
      "[339]\ttraining's binary_logloss: 0.0310844\ttraining's f1: 0.841098\tvalid_1's binary_logloss: 0.0414076\tvalid_1's f1: 0.794617\n",
      "[340]\ttraining's binary_logloss: 0.0309923\ttraining's f1: 0.841458\tvalid_1's binary_logloss: 0.0413318\tvalid_1's f1: 0.794991\n",
      "[341]\ttraining's binary_logloss: 0.0308935\ttraining's f1: 0.841785\tvalid_1's binary_logloss: 0.0412592\tvalid_1's f1: 0.795143\n",
      "[342]\ttraining's binary_logloss: 0.0307584\ttraining's f1: 0.84251\tvalid_1's binary_logloss: 0.0411323\tvalid_1's f1: 0.795495\n",
      "[343]\ttraining's binary_logloss: 0.0306248\ttraining's f1: 0.84329\tvalid_1's binary_logloss: 0.0410166\tvalid_1's f1: 0.796087\n",
      "[344]\ttraining's binary_logloss: 0.0305373\ttraining's f1: 0.843672\tvalid_1's binary_logloss: 0.040939\tvalid_1's f1: 0.796436\n",
      "[345]\ttraining's binary_logloss: 0.0304046\ttraining's f1: 0.844168\tvalid_1's binary_logloss: 0.0408156\tvalid_1's f1: 0.796786\n",
      "[346]\ttraining's binary_logloss: 0.0303488\ttraining's f1: 0.844422\tvalid_1's binary_logloss: 0.04077\tvalid_1's f1: 0.797027\n",
      "[347]\ttraining's binary_logloss: 0.0302936\ttraining's f1: 0.84478\tvalid_1's binary_logloss: 0.0407196\tvalid_1's f1: 0.797158\n",
      "[348]\ttraining's binary_logloss: 0.0302047\ttraining's f1: 0.845288\tvalid_1's binary_logloss: 0.040649\tvalid_1's f1: 0.797458\n",
      "[349]\ttraining's binary_logloss: 0.0300639\ttraining's f1: 0.845851\tvalid_1's binary_logloss: 0.0405193\tvalid_1's f1: 0.797942\n",
      "[350]\ttraining's binary_logloss: 0.0299733\ttraining's f1: 0.846327\tvalid_1's binary_logloss: 0.0404397\tvalid_1's f1: 0.798266\n",
      "[351]\ttraining's binary_logloss: 0.0298581\ttraining's f1: 0.846866\tvalid_1's binary_logloss: 0.040341\tvalid_1's f1: 0.798484\n",
      "[352]\ttraining's binary_logloss: 0.0297206\ttraining's f1: 0.847744\tvalid_1's binary_logloss: 0.0402118\tvalid_1's f1: 0.798898\n",
      "[353]\ttraining's binary_logloss: 0.0296631\ttraining's f1: 0.847994\tvalid_1's binary_logloss: 0.0401564\tvalid_1's f1: 0.799027\n",
      "[354]\ttraining's binary_logloss: 0.0295935\ttraining's f1: 0.848395\tvalid_1's binary_logloss: 0.0400887\tvalid_1's f1: 0.799099\n",
      "[355]\ttraining's binary_logloss: 0.0295309\ttraining's f1: 0.848734\tvalid_1's binary_logloss: 0.0400275\tvalid_1's f1: 0.799335\n",
      "[356]\ttraining's binary_logloss: 0.0294396\ttraining's f1: 0.849065\tvalid_1's binary_logloss: 0.0399476\tvalid_1's f1: 0.799486\n",
      "[357]\ttraining's binary_logloss: 0.0293153\ttraining's f1: 0.849702\tvalid_1's binary_logloss: 0.0398277\tvalid_1's f1: 0.79984\n",
      "[358]\ttraining's binary_logloss: 0.0292053\ttraining's f1: 0.850197\tvalid_1's binary_logloss: 0.0397418\tvalid_1's f1: 0.800315\n",
      "[359]\ttraining's binary_logloss: 0.0291112\ttraining's f1: 0.850838\tvalid_1's binary_logloss: 0.0396563\tvalid_1's f1: 0.800905\n",
      "[360]\ttraining's binary_logloss: 0.0290291\ttraining's f1: 0.851101\tvalid_1's binary_logloss: 0.0395824\tvalid_1's f1: 0.801419\n",
      "[361]\ttraining's binary_logloss: 0.0289642\ttraining's f1: 0.851273\tvalid_1's binary_logloss: 0.039526\tvalid_1's f1: 0.801502\n",
      "[362]\ttraining's binary_logloss: 0.0288672\ttraining's f1: 0.851763\tvalid_1's binary_logloss: 0.0394443\tvalid_1's f1: 0.801791\n",
      "[363]\ttraining's binary_logloss: 0.0287934\ttraining's f1: 0.852099\tvalid_1's binary_logloss: 0.0393842\tvalid_1's f1: 0.802026\n",
      "[364]\ttraining's binary_logloss: 0.0287038\ttraining's f1: 0.852583\tvalid_1's binary_logloss: 0.0393014\tvalid_1's f1: 0.802464\n",
      "[365]\ttraining's binary_logloss: 0.0286601\ttraining's f1: 0.85271\tvalid_1's binary_logloss: 0.0392658\tvalid_1's f1: 0.80257\n",
      "[366]\ttraining's binary_logloss: 0.0285863\ttraining's f1: 0.85303\tvalid_1's binary_logloss: 0.0392041\tvalid_1's f1: 0.802843\n",
      "[367]\ttraining's binary_logloss: 0.0284487\ttraining's f1: 0.853902\tvalid_1's binary_logloss: 0.0390923\tvalid_1's f1: 0.803103\n",
      "[368]\ttraining's binary_logloss: 0.0283491\ttraining's f1: 0.854224\tvalid_1's binary_logloss: 0.0390115\tvalid_1's f1: 0.803407\n",
      "[369]\ttraining's binary_logloss: 0.0282905\ttraining's f1: 0.854463\tvalid_1's binary_logloss: 0.0389582\tvalid_1's f1: 0.803775\n",
      "[370]\ttraining's binary_logloss: 0.0282039\ttraining's f1: 0.854878\tvalid_1's binary_logloss: 0.0388957\tvalid_1's f1: 0.804051\n",
      "[371]\ttraining's binary_logloss: 0.0281548\ttraining's f1: 0.855073\tvalid_1's binary_logloss: 0.0388496\tvalid_1's f1: 0.804495\n",
      "[372]\ttraining's binary_logloss: 0.0280544\ttraining's f1: 0.855508\tvalid_1's binary_logloss: 0.0387552\tvalid_1's f1: 0.805126\n",
      "[373]\ttraining's binary_logloss: 0.0279872\ttraining's f1: 0.855851\tvalid_1's binary_logloss: 0.0386997\tvalid_1's f1: 0.805279\n",
      "[374]\ttraining's binary_logloss: 0.0279066\ttraining's f1: 0.856279\tvalid_1's binary_logloss: 0.0386296\tvalid_1's f1: 0.805616\n",
      "[375]\ttraining's binary_logloss: 0.0278319\ttraining's f1: 0.856558\tvalid_1's binary_logloss: 0.0385767\tvalid_1's f1: 0.805827\n",
      "[376]\ttraining's binary_logloss: 0.0277749\ttraining's f1: 0.856801\tvalid_1's binary_logloss: 0.0385264\tvalid_1's f1: 0.80586\n",
      "[377]\ttraining's binary_logloss: 0.0277102\ttraining's f1: 0.857062\tvalid_1's binary_logloss: 0.0384709\tvalid_1's f1: 0.806147\n",
      "[378]\ttraining's binary_logloss: 0.0275806\ttraining's f1: 0.857811\tvalid_1's binary_logloss: 0.0383462\tvalid_1's f1: 0.806564\n",
      "[379]\ttraining's binary_logloss: 0.0274877\ttraining's f1: 0.858178\tvalid_1's binary_logloss: 0.0382642\tvalid_1's f1: 0.806868\n",
      "[380]\ttraining's binary_logloss: 0.0274333\ttraining's f1: 0.858517\tvalid_1's binary_logloss: 0.0382221\tvalid_1's f1: 0.807081\n",
      "[381]\ttraining's binary_logloss: 0.0273571\ttraining's f1: 0.85878\tvalid_1's binary_logloss: 0.0381669\tvalid_1's f1: 0.807392\n",
      "[382]\ttraining's binary_logloss: 0.0272716\ttraining's f1: 0.859111\tvalid_1's binary_logloss: 0.0380975\tvalid_1's f1: 0.807676\n",
      "[383]\ttraining's binary_logloss: 0.0272104\ttraining's f1: 0.859442\tvalid_1's binary_logloss: 0.0380504\tvalid_1's f1: 0.80783\n",
      "[384]\ttraining's binary_logloss: 0.0271297\ttraining's f1: 0.860049\tvalid_1's binary_logloss: 0.0379811\tvalid_1's f1: 0.808124\n",
      "[385]\ttraining's binary_logloss: 0.0270822\ttraining's f1: 0.86022\tvalid_1's binary_logloss: 0.0379359\tvalid_1's f1: 0.808178\n",
      "[386]\ttraining's binary_logloss: 0.0269984\ttraining's f1: 0.860562\tvalid_1's binary_logloss: 0.0378631\tvalid_1's f1: 0.808482\n",
      "[387]\ttraining's binary_logloss: 0.0269197\ttraining's f1: 0.860895\tvalid_1's binary_logloss: 0.0378039\tvalid_1's f1: 0.80875\n",
      "[388]\ttraining's binary_logloss: 0.0268788\ttraining's f1: 0.861163\tvalid_1's binary_logloss: 0.0377702\tvalid_1's f1: 0.808954\n",
      "[389]\ttraining's binary_logloss: 0.0267664\ttraining's f1: 0.861756\tvalid_1's binary_logloss: 0.037667\tvalid_1's f1: 0.809363\n",
      "[390]\ttraining's binary_logloss: 0.0266965\ttraining's f1: 0.862014\tvalid_1's binary_logloss: 0.0376109\tvalid_1's f1: 0.809357\n",
      "[391]\ttraining's binary_logloss: 0.0266121\ttraining's f1: 0.862447\tvalid_1's binary_logloss: 0.037546\tvalid_1's f1: 0.809566\n",
      "[392]\ttraining's binary_logloss: 0.0265457\ttraining's f1: 0.862716\tvalid_1's binary_logloss: 0.0374917\tvalid_1's f1: 0.809787\n",
      "[393]\ttraining's binary_logloss: 0.0264835\ttraining's f1: 0.862986\tvalid_1's binary_logloss: 0.037436\tvalid_1's f1: 0.809861\n",
      "[394]\ttraining's binary_logloss: 0.0264162\ttraining's f1: 0.863188\tvalid_1's binary_logloss: 0.0373735\tvalid_1's f1: 0.810024\n",
      "[395]\ttraining's binary_logloss: 0.0263557\ttraining's f1: 0.86343\tvalid_1's binary_logloss: 0.0373226\tvalid_1's f1: 0.810187\n",
      "[396]\ttraining's binary_logloss: 0.0263106\ttraining's f1: 0.863681\tvalid_1's binary_logloss: 0.0372831\tvalid_1's f1: 0.810443\n",
      "[397]\ttraining's binary_logloss: 0.0261665\ttraining's f1: 0.864379\tvalid_1's binary_logloss: 0.0371529\tvalid_1's f1: 0.810977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[398]\ttraining's binary_logloss: 0.026113\ttraining's f1: 0.864564\tvalid_1's binary_logloss: 0.0371043\tvalid_1's f1: 0.811131\n",
      "[399]\ttraining's binary_logloss: 0.0260416\ttraining's f1: 0.864924\tvalid_1's binary_logloss: 0.0370484\tvalid_1's f1: 0.811404\n",
      "[400]\ttraining's binary_logloss: 0.0259506\ttraining's f1: 0.86548\tvalid_1's binary_logloss: 0.0369662\tvalid_1's f1: 0.811604\n",
      "[401]\ttraining's binary_logloss: 0.0258025\ttraining's f1: 0.866312\tvalid_1's binary_logloss: 0.0368231\tvalid_1's f1: 0.812049\n",
      "[402]\ttraining's binary_logloss: 0.0257363\ttraining's f1: 0.866606\tvalid_1's binary_logloss: 0.0367745\tvalid_1's f1: 0.812065\n",
      "[403]\ttraining's binary_logloss: 0.0256568\ttraining's f1: 0.866803\tvalid_1's binary_logloss: 0.0367094\tvalid_1's f1: 0.81236\n",
      "[404]\ttraining's binary_logloss: 0.0256111\ttraining's f1: 0.867059\tvalid_1's binary_logloss: 0.0366633\tvalid_1's f1: 0.812559\n",
      "[405]\ttraining's binary_logloss: 0.0255188\ttraining's f1: 0.867502\tvalid_1's binary_logloss: 0.0365849\tvalid_1's f1: 0.812897\n",
      "[406]\ttraining's binary_logloss: 0.0254311\ttraining's f1: 0.867838\tvalid_1's binary_logloss: 0.0365138\tvalid_1's f1: 0.813233\n",
      "[407]\ttraining's binary_logloss: 0.0253354\ttraining's f1: 0.868373\tvalid_1's binary_logloss: 0.036431\tvalid_1's f1: 0.813606\n",
      "[408]\ttraining's binary_logloss: 0.0252896\ttraining's f1: 0.868531\tvalid_1's binary_logloss: 0.0363849\tvalid_1's f1: 0.8137\n",
      "[409]\ttraining's binary_logloss: 0.0252286\ttraining's f1: 0.86877\tvalid_1's binary_logloss: 0.036342\tvalid_1's f1: 0.813868\n",
      "[410]\ttraining's binary_logloss: 0.025159\ttraining's f1: 0.869147\tvalid_1's binary_logloss: 0.0362919\tvalid_1's f1: 0.814249\n",
      "[411]\ttraining's binary_logloss: 0.0250154\ttraining's f1: 0.869965\tvalid_1's binary_logloss: 0.0361605\tvalid_1's f1: 0.81478\n",
      "[412]\ttraining's binary_logloss: 0.0249255\ttraining's f1: 0.870396\tvalid_1's binary_logloss: 0.0360819\tvalid_1's f1: 0.81526\n",
      "[413]\ttraining's binary_logloss: 0.024882\ttraining's f1: 0.870686\tvalid_1's binary_logloss: 0.0360431\tvalid_1's f1: 0.81547\n",
      "[414]\ttraining's binary_logloss: 0.0247715\ttraining's f1: 0.871249\tvalid_1's binary_logloss: 0.0359515\tvalid_1's f1: 0.815868\n",
      "[415]\ttraining's binary_logloss: 0.0246977\ttraining's f1: 0.87144\tvalid_1's binary_logloss: 0.0358799\tvalid_1's f1: 0.816289\n",
      "[416]\ttraining's binary_logloss: 0.0246093\ttraining's f1: 0.871773\tvalid_1's binary_logloss: 0.0358144\tvalid_1's f1: 0.816672\n",
      "[417]\ttraining's binary_logloss: 0.0244965\ttraining's f1: 0.872369\tvalid_1's binary_logloss: 0.035709\tvalid_1's f1: 0.817078\n",
      "[418]\ttraining's binary_logloss: 0.0244613\ttraining's f1: 0.87249\tvalid_1's binary_logloss: 0.0356769\tvalid_1's f1: 0.817174\n",
      "[419]\ttraining's binary_logloss: 0.0243095\ttraining's f1: 0.873383\tvalid_1's binary_logloss: 0.0355434\tvalid_1's f1: 0.81752\n",
      "[420]\ttraining's binary_logloss: 0.0242323\ttraining's f1: 0.873902\tvalid_1's binary_logloss: 0.0354738\tvalid_1's f1: 0.817631\n",
      "[421]\ttraining's binary_logloss: 0.0241629\ttraining's f1: 0.874178\tvalid_1's binary_logloss: 0.0354246\tvalid_1's f1: 0.817959\n",
      "[422]\ttraining's binary_logloss: 0.0240747\ttraining's f1: 0.87473\tvalid_1's binary_logloss: 0.0353581\tvalid_1's f1: 0.818347\n",
      "[423]\ttraining's binary_logloss: 0.0239959\ttraining's f1: 0.875048\tvalid_1's binary_logloss: 0.0352781\tvalid_1's f1: 0.818636\n",
      "[424]\ttraining's binary_logloss: 0.0239327\ttraining's f1: 0.875572\tvalid_1's binary_logloss: 0.0352264\tvalid_1's f1: 0.818474\n",
      "[425]\ttraining's binary_logloss: 0.0238799\ttraining's f1: 0.875767\tvalid_1's binary_logloss: 0.0351861\tvalid_1's f1: 0.818491\n",
      "[426]\ttraining's binary_logloss: 0.0238379\ttraining's f1: 0.875994\tvalid_1's binary_logloss: 0.0351572\tvalid_1's f1: 0.818629\n",
      "[427]\ttraining's binary_logloss: 0.0237616\ttraining's f1: 0.876313\tvalid_1's binary_logloss: 0.0350851\tvalid_1's f1: 0.818785\n",
      "[428]\ttraining's binary_logloss: 0.0237235\ttraining's f1: 0.876468\tvalid_1's binary_logloss: 0.0350517\tvalid_1's f1: 0.818997\n",
      "[429]\ttraining's binary_logloss: 0.0236732\ttraining's f1: 0.876644\tvalid_1's binary_logloss: 0.0350049\tvalid_1's f1: 0.819156\n",
      "[430]\ttraining's binary_logloss: 0.0236262\ttraining's f1: 0.876872\tvalid_1's binary_logloss: 0.0349625\tvalid_1's f1: 0.819233\n",
      "[431]\ttraining's binary_logloss: 0.0235407\ttraining's f1: 0.877234\tvalid_1's binary_logloss: 0.0348929\tvalid_1's f1: 0.819547\n",
      "[432]\ttraining's binary_logloss: 0.023438\ttraining's f1: 0.877785\tvalid_1's binary_logloss: 0.0348039\tvalid_1's f1: 0.819959\n",
      "[433]\ttraining's binary_logloss: 0.0233194\ttraining's f1: 0.878493\tvalid_1's binary_logloss: 0.0346994\tvalid_1's f1: 0.82049\n",
      "[434]\ttraining's binary_logloss: 0.023243\ttraining's f1: 0.878827\tvalid_1's binary_logloss: 0.0346415\tvalid_1's f1: 0.820724\n",
      "[435]\ttraining's binary_logloss: 0.0232137\ttraining's f1: 0.8789\tvalid_1's binary_logloss: 0.034616\tvalid_1's f1: 0.820803\n",
      "[436]\ttraining's binary_logloss: 0.0231823\ttraining's f1: 0.879036\tvalid_1's binary_logloss: 0.0345927\tvalid_1's f1: 0.820882\n",
      "[437]\ttraining's binary_logloss: 0.0231465\ttraining's f1: 0.879183\tvalid_1's binary_logloss: 0.0345618\tvalid_1's f1: 0.82094\n",
      "[438]\ttraining's binary_logloss: 0.023084\ttraining's f1: 0.879623\tvalid_1's binary_logloss: 0.0345073\tvalid_1's f1: 0.821016\n",
      "[439]\ttraining's binary_logloss: 0.0230161\ttraining's f1: 0.87998\tvalid_1's binary_logloss: 0.0344533\tvalid_1's f1: 0.821294\n",
      "[440]\ttraining's binary_logloss: 0.0229499\ttraining's f1: 0.880359\tvalid_1's binary_logloss: 0.0344064\tvalid_1's f1: 0.821651\n",
      "[441]\ttraining's binary_logloss: 0.0228858\ttraining's f1: 0.880549\tvalid_1's binary_logloss: 0.0343486\tvalid_1's f1: 0.82193\n",
      "[442]\ttraining's binary_logloss: 0.0228533\ttraining's f1: 0.880718\tvalid_1's binary_logloss: 0.0343197\tvalid_1's f1: 0.822069\n",
      "[443]\ttraining's binary_logloss: 0.0227361\ttraining's f1: 0.881479\tvalid_1's binary_logloss: 0.0342113\tvalid_1's f1: 0.822286\n",
      "[444]\ttraining's binary_logloss: 0.0226761\ttraining's f1: 0.881723\tvalid_1's binary_logloss: 0.0341658\tvalid_1's f1: 0.822241\n",
      "[445]\ttraining's binary_logloss: 0.0226163\ttraining's f1: 0.882041\tvalid_1's binary_logloss: 0.0341224\tvalid_1's f1: 0.822217\n",
      "[446]\ttraining's binary_logloss: 0.0225323\ttraining's f1: 0.882466\tvalid_1's binary_logloss: 0.0340545\tvalid_1's f1: 0.822636\n",
      "[447]\ttraining's binary_logloss: 0.0224994\ttraining's f1: 0.882658\tvalid_1's binary_logloss: 0.0340316\tvalid_1's f1: 0.822919\n",
      "[448]\ttraining's binary_logloss: 0.022432\ttraining's f1: 0.883053\tvalid_1's binary_logloss: 0.0339744\tvalid_1's f1: 0.823119\n",
      "[449]\ttraining's binary_logloss: 0.0223906\ttraining's f1: 0.88333\tvalid_1's binary_logloss: 0.0339468\tvalid_1's f1: 0.82332\n",
      "[450]\ttraining's binary_logloss: 0.0222805\ttraining's f1: 0.88378\tvalid_1's binary_logloss: 0.0338405\tvalid_1's f1: 0.823641\n",
      "[451]\ttraining's binary_logloss: 0.0222274\ttraining's f1: 0.884059\tvalid_1's binary_logloss: 0.0337964\tvalid_1's f1: 0.823882\n",
      "[452]\ttraining's binary_logloss: 0.0221985\ttraining's f1: 0.884166\tvalid_1's binary_logloss: 0.0337766\tvalid_1's f1: 0.823923\n",
      "[453]\ttraining's binary_logloss: 0.0221294\ttraining's f1: 0.884499\tvalid_1's binary_logloss: 0.033726\tvalid_1's f1: 0.824125\n",
      "[454]\ttraining's binary_logloss: 0.0220693\ttraining's f1: 0.884736\tvalid_1's binary_logloss: 0.033684\tvalid_1's f1: 0.824246\n",
      "[455]\ttraining's binary_logloss: 0.0219973\ttraining's f1: 0.885124\tvalid_1's binary_logloss: 0.0336123\tvalid_1's f1: 0.824549\n",
      "[456]\ttraining's binary_logloss: 0.0219541\ttraining's f1: 0.885329\tvalid_1's binary_logloss: 0.0335731\tvalid_1's f1: 0.824832\n",
      "[457]\ttraining's binary_logloss: 0.0218888\ttraining's f1: 0.885588\tvalid_1's binary_logloss: 0.0335147\tvalid_1's f1: 0.824852\n",
      "[458]\ttraining's binary_logloss: 0.0218194\ttraining's f1: 0.885869\tvalid_1's binary_logloss: 0.0334524\tvalid_1's f1: 0.825197\n",
      "[459]\ttraining's binary_logloss: 0.0217808\ttraining's f1: 0.886075\tvalid_1's binary_logloss: 0.0334214\tvalid_1's f1: 0.82532\n",
      "[460]\ttraining's binary_logloss: 0.0217079\ttraining's f1: 0.886422\tvalid_1's binary_logloss: 0.0333677\tvalid_1's f1: 0.825339\n",
      "[461]\ttraining's binary_logloss: 0.021651\ttraining's f1: 0.886715\tvalid_1's binary_logloss: 0.0333283\tvalid_1's f1: 0.825502\n",
      "[462]\ttraining's binary_logloss: 0.0215781\ttraining's f1: 0.887064\tvalid_1's binary_logloss: 0.0332686\tvalid_1's f1: 0.825849\n",
      "[463]\ttraining's binary_logloss: 0.0215256\ttraining's f1: 0.887467\tvalid_1's binary_logloss: 0.0332256\tvalid_1's f1: 0.826114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[464]\ttraining's binary_logloss: 0.0214812\ttraining's f1: 0.887718\tvalid_1's binary_logloss: 0.0331843\tvalid_1's f1: 0.826278\n",
      "[465]\ttraining's binary_logloss: 0.0214095\ttraining's f1: 0.888134\tvalid_1's binary_logloss: 0.0331248\tvalid_1's f1: 0.826605\n",
      "[466]\ttraining's binary_logloss: 0.0213633\ttraining's f1: 0.88832\tvalid_1's binary_logloss: 0.0330828\tvalid_1's f1: 0.826708\n",
      "[467]\ttraining's binary_logloss: 0.0213376\ttraining's f1: 0.888462\tvalid_1's binary_logloss: 0.0330627\tvalid_1's f1: 0.826749\n",
      "[468]\ttraining's binary_logloss: 0.02131\ttraining's f1: 0.888528\tvalid_1's binary_logloss: 0.0330401\tvalid_1's f1: 0.82679\n",
      "[469]\ttraining's binary_logloss: 0.0212386\ttraining's f1: 0.888879\tvalid_1's binary_logloss: 0.0329767\tvalid_1's f1: 0.826974\n",
      "[470]\ttraining's binary_logloss: 0.0211972\ttraining's f1: 0.889055\tvalid_1's binary_logloss: 0.0329446\tvalid_1's f1: 0.826913\n",
      "[471]\ttraining's binary_logloss: 0.0211714\ttraining's f1: 0.889242\tvalid_1's binary_logloss: 0.0329264\tvalid_1's f1: 0.826892\n",
      "[472]\ttraining's binary_logloss: 0.0210745\ttraining's f1: 0.889871\tvalid_1's binary_logloss: 0.0328387\tvalid_1's f1: 0.827633\n",
      "[473]\ttraining's binary_logloss: 0.0209778\ttraining's f1: 0.89049\tvalid_1's binary_logloss: 0.0327609\tvalid_1's f1: 0.82815\n",
      "[474]\ttraining's binary_logloss: 0.0209199\ttraining's f1: 0.890922\tvalid_1's binary_logloss: 0.0327127\tvalid_1's f1: 0.82842\n",
      "[475]\ttraining's binary_logloss: 0.0207989\ttraining's f1: 0.891522\tvalid_1's binary_logloss: 0.0326007\tvalid_1's f1: 0.828814\n",
      "[476]\ttraining's binary_logloss: 0.020725\ttraining's f1: 0.891968\tvalid_1's binary_logloss: 0.0325373\tvalid_1's f1: 0.829106\n",
      "[477]\ttraining's binary_logloss: 0.0206758\ttraining's f1: 0.892213\tvalid_1's binary_logloss: 0.0324941\tvalid_1's f1: 0.829252\n",
      "[478]\ttraining's binary_logloss: 0.0206512\ttraining's f1: 0.892269\tvalid_1's binary_logloss: 0.0324745\tvalid_1's f1: 0.829294\n",
      "[479]\ttraining's binary_logloss: 0.0206078\ttraining's f1: 0.892526\tvalid_1's binary_logloss: 0.0324384\tvalid_1's f1: 0.82946\n",
      "[480]\ttraining's binary_logloss: 0.0205403\ttraining's f1: 0.893008\tvalid_1's binary_logloss: 0.0323885\tvalid_1's f1: 0.829461\n",
      "[481]\ttraining's binary_logloss: 0.0204801\ttraining's f1: 0.893232\tvalid_1's binary_logloss: 0.0323352\tvalid_1's f1: 0.829712\n",
      "[482]\ttraining's binary_logloss: 0.0204302\ttraining's f1: 0.893356\tvalid_1's binary_logloss: 0.0322928\tvalid_1's f1: 0.829672\n",
      "[483]\ttraining's binary_logloss: 0.0203661\ttraining's f1: 0.893625\tvalid_1's binary_logloss: 0.0322428\tvalid_1's f1: 0.8298\n",
      "[484]\ttraining's binary_logloss: 0.0202919\ttraining's f1: 0.894098\tvalid_1's binary_logloss: 0.0321875\tvalid_1's f1: 0.830137\n",
      "[485]\ttraining's binary_logloss: 0.0202364\ttraining's f1: 0.894391\tvalid_1's binary_logloss: 0.0321462\tvalid_1's f1: 0.830409\n",
      "[486]\ttraining's binary_logloss: 0.0201969\ttraining's f1: 0.89473\tvalid_1's binary_logloss: 0.0321205\tvalid_1's f1: 0.830474\n",
      "[487]\ttraining's binary_logloss: 0.0201263\ttraining's f1: 0.894922\tvalid_1's binary_logloss: 0.0320633\tvalid_1's f1: 0.830642\n",
      "[488]\ttraining's binary_logloss: 0.0200249\ttraining's f1: 0.8955\tvalid_1's binary_logloss: 0.0319639\tvalid_1's f1: 0.830833\n",
      "[489]\ttraining's binary_logloss: 0.0199466\ttraining's f1: 0.895875\tvalid_1's binary_logloss: 0.0318959\tvalid_1's f1: 0.831107\n",
      "[490]\ttraining's binary_logloss: 0.0198458\ttraining's f1: 0.896478\tvalid_1's binary_logloss: 0.0318037\tvalid_1's f1: 0.831489\n",
      "[491]\ttraining's binary_logloss: 0.0198166\ttraining's f1: 0.896695\tvalid_1's binary_logloss: 0.0317794\tvalid_1's f1: 0.831617\n",
      "[492]\ttraining's binary_logloss: 0.0197653\ttraining's f1: 0.896912\tvalid_1's binary_logloss: 0.0317375\tvalid_1's f1: 0.831533\n",
      "[493]\ttraining's binary_logloss: 0.0197415\ttraining's f1: 0.897106\tvalid_1's binary_logloss: 0.0317126\tvalid_1's f1: 0.831744\n",
      "[494]\ttraining's binary_logloss: 0.0196873\ttraining's f1: 0.897507\tvalid_1's binary_logloss: 0.0316644\tvalid_1's f1: 0.831873\n",
      "[495]\ttraining's binary_logloss: 0.0196393\ttraining's f1: 0.897679\tvalid_1's binary_logloss: 0.0316184\tvalid_1's f1: 0.832002\n",
      "[496]\ttraining's binary_logloss: 0.0195936\ttraining's f1: 0.897874\tvalid_1's binary_logloss: 0.0315846\tvalid_1's f1: 0.832173\n",
      "[497]\ttraining's binary_logloss: 0.0195362\ttraining's f1: 0.898264\tvalid_1's binary_logloss: 0.0315342\tvalid_1's f1: 0.832577\n",
      "[498]\ttraining's binary_logloss: 0.0194954\ttraining's f1: 0.898391\tvalid_1's binary_logloss: 0.0314966\tvalid_1's f1: 0.832726\n",
      "[499]\ttraining's binary_logloss: 0.0194525\ttraining's f1: 0.898632\tvalid_1's binary_logloss: 0.0314565\tvalid_1's f1: 0.832876\n",
      "[500]\ttraining's binary_logloss: 0.0194105\ttraining's f1: 0.898944\tvalid_1's binary_logloss: 0.0314213\tvalid_1's f1: 0.833069\n",
      "[501]\ttraining's binary_logloss: 0.0193681\ttraining's f1: 0.899047\tvalid_1's binary_logloss: 0.0313893\tvalid_1's f1: 0.833154\n",
      "[502]\ttraining's binary_logloss: 0.0193306\ttraining's f1: 0.899394\tvalid_1's binary_logloss: 0.0313597\tvalid_1's f1: 0.833368\n",
      "[503]\ttraining's binary_logloss: 0.0192904\ttraining's f1: 0.899579\tvalid_1's binary_logloss: 0.031329\tvalid_1's f1: 0.833712\n",
      "[504]\ttraining's binary_logloss: 0.0192186\ttraining's f1: 0.899915\tvalid_1's binary_logloss: 0.0312567\tvalid_1's f1: 0.833927\n",
      "[505]\ttraining's binary_logloss: 0.0191607\ttraining's f1: 0.90017\tvalid_1's binary_logloss: 0.0312128\tvalid_1's f1: 0.833993\n",
      "[506]\ttraining's binary_logloss: 0.0191074\ttraining's f1: 0.900658\tvalid_1's binary_logloss: 0.03118\tvalid_1's f1: 0.834207\n",
      "[507]\ttraining's binary_logloss: 0.019072\ttraining's f1: 0.900809\tvalid_1's binary_logloss: 0.0311483\tvalid_1's f1: 0.834443\n",
      "[508]\ttraining's binary_logloss: 0.0190158\ttraining's f1: 0.901065\tvalid_1's binary_logloss: 0.0311008\tvalid_1's f1: 0.834765\n",
      "[509]\ttraining's binary_logloss: 0.018982\ttraining's f1: 0.901147\tvalid_1's binary_logloss: 0.0310666\tvalid_1's f1: 0.834764\n",
      "[510]\ttraining's binary_logloss: 0.0188918\ttraining's f1: 0.901754\tvalid_1's binary_logloss: 0.0309864\tvalid_1's f1: 0.835024\n",
      "[511]\ttraining's binary_logloss: 0.018836\ttraining's f1: 0.902175\tvalid_1's binary_logloss: 0.0309419\tvalid_1's f1: 0.835434\n",
      "[512]\ttraining's binary_logloss: 0.0187842\ttraining's f1: 0.902374\tvalid_1's binary_logloss: 0.0309001\tvalid_1's f1: 0.835542\n",
      "[513]\ttraining's binary_logloss: 0.0187359\ttraining's f1: 0.902644\tvalid_1's binary_logloss: 0.0308524\tvalid_1's f1: 0.835737\n",
      "[514]\ttraining's binary_logloss: 0.0186425\ttraining's f1: 0.903315\tvalid_1's binary_logloss: 0.030762\tvalid_1's f1: 0.836108\n",
      "[515]\ttraining's binary_logloss: 0.0186221\ttraining's f1: 0.903421\tvalid_1's binary_logloss: 0.0307484\tvalid_1's f1: 0.836088\n",
      "[516]\ttraining's binary_logloss: 0.0185557\ttraining's f1: 0.903727\tvalid_1's binary_logloss: 0.0306867\tvalid_1's f1: 0.836587\n",
      "[517]\ttraining's binary_logloss: 0.0185114\ttraining's f1: 0.904011\tvalid_1's binary_logloss: 0.0306538\tvalid_1's f1: 0.836484\n",
      "[518]\ttraining's binary_logloss: 0.0184216\ttraining's f1: 0.904425\tvalid_1's binary_logloss: 0.0305693\tvalid_1's f1: 0.836727\n",
      "[519]\ttraining's binary_logloss: 0.0183887\ttraining's f1: 0.904543\tvalid_1's binary_logloss: 0.0305448\tvalid_1's f1: 0.836814\n",
      "[520]\ttraining's binary_logloss: 0.0183331\ttraining's f1: 0.904899\tvalid_1's binary_logloss: 0.0304948\tvalid_1's f1: 0.836991\n",
      "[521]\ttraining's binary_logloss: 0.0182831\ttraining's f1: 0.905089\tvalid_1's binary_logloss: 0.0304501\tvalid_1's f1: 0.837296\n",
      "[522]\ttraining's binary_logloss: 0.0182308\ttraining's f1: 0.905362\tvalid_1's binary_logloss: 0.0304071\tvalid_1's f1: 0.837669\n",
      "[523]\ttraining's binary_logloss: 0.018189\ttraining's f1: 0.90554\tvalid_1's binary_logloss: 0.0303754\tvalid_1's f1: 0.837911\n",
      "[524]\ttraining's binary_logloss: 0.0181038\ttraining's f1: 0.906101\tvalid_1's binary_logloss: 0.0302965\tvalid_1's f1: 0.838239\n",
      "[525]\ttraining's binary_logloss: 0.0180516\ttraining's f1: 0.906471\tvalid_1's binary_logloss: 0.0302584\tvalid_1's f1: 0.838263\n",
      "[526]\ttraining's binary_logloss: 0.0179876\ttraining's f1: 0.90677\tvalid_1's binary_logloss: 0.0302061\tvalid_1's f1: 0.838251\n",
      "[527]\ttraining's binary_logloss: 0.0179606\ttraining's f1: 0.906818\tvalid_1's binary_logloss: 0.0301815\tvalid_1's f1: 0.838251\n",
      "[528]\ttraining's binary_logloss: 0.0179075\ttraining's f1: 0.907141\tvalid_1's binary_logloss: 0.0301365\tvalid_1's f1: 0.838361\n",
      "[529]\ttraining's binary_logloss: 0.0178608\ttraining's f1: 0.907441\tvalid_1's binary_logloss: 0.0300916\tvalid_1's f1: 0.838321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[530]\ttraining's binary_logloss: 0.0178363\ttraining's f1: 0.907526\tvalid_1's binary_logloss: 0.0300748\tvalid_1's f1: 0.838303\n",
      "[531]\ttraining's binary_logloss: 0.0178116\ttraining's f1: 0.90767\tvalid_1's binary_logloss: 0.0300526\tvalid_1's f1: 0.838395\n",
      "[532]\ttraining's binary_logloss: 0.0177689\ttraining's f1: 0.907886\tvalid_1's binary_logloss: 0.030018\tvalid_1's f1: 0.838639\n",
      "[533]\ttraining's binary_logloss: 0.017723\ttraining's f1: 0.908187\tvalid_1's binary_logloss: 0.0299864\tvalid_1's f1: 0.838949\n",
      "[534]\ttraining's binary_logloss: 0.0176759\ttraining's f1: 0.908537\tvalid_1's binary_logloss: 0.0299522\tvalid_1's f1: 0.839066\n",
      "[535]\ttraining's binary_logloss: 0.017622\ttraining's f1: 0.908936\tvalid_1's binary_logloss: 0.0299108\tvalid_1's f1: 0.839288\n",
      "[536]\ttraining's binary_logloss: 0.0175738\ttraining's f1: 0.909166\tvalid_1's binary_logloss: 0.0298662\tvalid_1's f1: 0.839575\n",
      "[537]\ttraining's binary_logloss: 0.0175309\ttraining's f1: 0.909335\tvalid_1's binary_logloss: 0.0298329\tvalid_1's f1: 0.839579\n",
      "[538]\ttraining's binary_logloss: 0.0174512\ttraining's f1: 0.909869\tvalid_1's binary_logloss: 0.0297611\tvalid_1's f1: 0.839893\n",
      "[539]\ttraining's binary_logloss: 0.0174271\ttraining's f1: 0.909978\tvalid_1's binary_logloss: 0.0297419\tvalid_1's f1: 0.83994\n",
      "[540]\ttraining's binary_logloss: 0.0174033\ttraining's f1: 0.910039\tvalid_1's binary_logloss: 0.0297308\tvalid_1's f1: 0.839918\n",
      "[541]\ttraining's binary_logloss: 0.0173422\ttraining's f1: 0.910502\tvalid_1's binary_logloss: 0.0296802\tvalid_1's f1: 0.84003\n",
      "[542]\ttraining's binary_logloss: 0.017302\ttraining's f1: 0.910672\tvalid_1's binary_logloss: 0.0296466\tvalid_1's f1: 0.840452\n",
      "[543]\ttraining's binary_logloss: 0.0172343\ttraining's f1: 0.911319\tvalid_1's binary_logloss: 0.0295817\tvalid_1's f1: 0.840544\n",
      "[544]\ttraining's binary_logloss: 0.0171613\ttraining's f1: 0.911846\tvalid_1's binary_logloss: 0.0295137\tvalid_1's f1: 0.840797\n",
      "[545]\ttraining's binary_logloss: 0.017126\ttraining's f1: 0.91203\tvalid_1's binary_logloss: 0.0294845\tvalid_1's f1: 0.84082\n",
      "[546]\ttraining's binary_logloss: 0.0170721\ttraining's f1: 0.912472\tvalid_1's binary_logloss: 0.029442\tvalid_1's f1: 0.841047\n",
      "[547]\ttraining's binary_logloss: 0.0170259\ttraining's f1: 0.912903\tvalid_1's binary_logloss: 0.0294045\tvalid_1's f1: 0.841232\n",
      "[548]\ttraining's binary_logloss: 0.0169625\ttraining's f1: 0.91326\tvalid_1's binary_logloss: 0.0293515\tvalid_1's f1: 0.841532\n",
      "[549]\ttraining's binary_logloss: 0.0169276\ttraining's f1: 0.913483\tvalid_1's binary_logloss: 0.0293239\tvalid_1's f1: 0.841733\n",
      "[550]\ttraining's binary_logloss: 0.0168657\ttraining's f1: 0.913854\tvalid_1's binary_logloss: 0.0292715\tvalid_1's f1: 0.842159\n",
      "[551]\ttraining's binary_logloss: 0.0168234\ttraining's f1: 0.914114\tvalid_1's binary_logloss: 0.0292354\tvalid_1's f1: 0.842431\n",
      "[552]\ttraining's binary_logloss: 0.0167884\ttraining's f1: 0.914436\tvalid_1's binary_logloss: 0.0292179\tvalid_1's f1: 0.842564\n",
      "[553]\ttraining's binary_logloss: 0.0167514\ttraining's f1: 0.914659\tvalid_1's binary_logloss: 0.0291811\tvalid_1's f1: 0.842725\n",
      "[554]\ttraining's binary_logloss: 0.0167161\ttraining's f1: 0.914647\tvalid_1's binary_logloss: 0.0291537\tvalid_1's f1: 0.842839\n",
      "[555]\ttraining's binary_logloss: 0.0166503\ttraining's f1: 0.915094\tvalid_1's binary_logloss: 0.0291061\tvalid_1's f1: 0.843228\n",
      "[556]\ttraining's binary_logloss: 0.0165776\ttraining's f1: 0.915605\tvalid_1's binary_logloss: 0.0290443\tvalid_1's f1: 0.843559\n",
      "[557]\ttraining's binary_logloss: 0.0165412\ttraining's f1: 0.91578\tvalid_1's binary_logloss: 0.0290146\tvalid_1's f1: 0.843858\n",
      "[558]\ttraining's binary_logloss: 0.0165078\ttraining's f1: 0.915942\tvalid_1's binary_logloss: 0.0289853\tvalid_1's f1: 0.84395\n",
      "[559]\ttraining's binary_logloss: 0.0164794\ttraining's f1: 0.91603\tvalid_1's binary_logloss: 0.0289616\tvalid_1's f1: 0.84411\n",
      "[560]\ttraining's binary_logloss: 0.0164534\ttraining's f1: 0.916167\tvalid_1's binary_logloss: 0.028946\tvalid_1's f1: 0.844198\n",
      "[561]\ttraining's binary_logloss: 0.0164158\ttraining's f1: 0.916393\tvalid_1's binary_logloss: 0.028916\tvalid_1's f1: 0.84425\n",
      "[562]\ttraining's binary_logloss: 0.0163901\ttraining's f1: 0.916618\tvalid_1's binary_logloss: 0.0288948\tvalid_1's f1: 0.844391\n",
      "[563]\ttraining's binary_logloss: 0.0163564\ttraining's f1: 0.916743\tvalid_1's binary_logloss: 0.0288704\tvalid_1's f1: 0.844466\n",
      "[564]\ttraining's binary_logloss: 0.0163122\ttraining's f1: 0.916944\tvalid_1's binary_logloss: 0.0288345\tvalid_1's f1: 0.844558\n",
      "[565]\ttraining's binary_logloss: 0.0162867\ttraining's f1: 0.917045\tvalid_1's binary_logloss: 0.0288153\tvalid_1's f1: 0.844696\n",
      "[566]\ttraining's binary_logloss: 0.0162173\ttraining's f1: 0.91761\tvalid_1's binary_logloss: 0.0287484\tvalid_1's f1: 0.845001\n",
      "[567]\ttraining's binary_logloss: 0.0161575\ttraining's f1: 0.918039\tvalid_1's binary_logloss: 0.0286997\tvalid_1's f1: 0.845153\n",
      "[568]\ttraining's binary_logloss: 0.0160966\ttraining's f1: 0.918569\tvalid_1's binary_logloss: 0.0286516\tvalid_1's f1: 0.845354\n",
      "[569]\ttraining's binary_logloss: 0.0160785\ttraining's f1: 0.918645\tvalid_1's binary_logloss: 0.028636\tvalid_1's f1: 0.845424\n",
      "[570]\ttraining's binary_logloss: 0.0160293\ttraining's f1: 0.918987\tvalid_1's binary_logloss: 0.0285962\tvalid_1's f1: 0.845678\n",
      "[571]\ttraining's binary_logloss: 0.0159763\ttraining's f1: 0.919355\tvalid_1's binary_logloss: 0.0285514\tvalid_1's f1: 0.846161\n",
      "[572]\ttraining's binary_logloss: 0.0159245\ttraining's f1: 0.919596\tvalid_1's binary_logloss: 0.028506\tvalid_1's f1: 0.84635\n",
      "[573]\ttraining's binary_logloss: 0.0158943\ttraining's f1: 0.919736\tvalid_1's binary_logloss: 0.0284812\tvalid_1's f1: 0.846397\n",
      "[574]\ttraining's binary_logloss: 0.015861\ttraining's f1: 0.919952\tvalid_1's binary_logloss: 0.0284569\tvalid_1's f1: 0.846517\n",
      "[575]\ttraining's binary_logloss: 0.0158262\ttraining's f1: 0.920118\tvalid_1's binary_logloss: 0.0284284\tvalid_1's f1: 0.846636\n",
      "[576]\ttraining's binary_logloss: 0.0157497\ttraining's f1: 0.920806\tvalid_1's binary_logloss: 0.0283567\tvalid_1's f1: 0.847059\n",
      "[577]\ttraining's binary_logloss: 0.0157005\ttraining's f1: 0.921139\tvalid_1's binary_logloss: 0.0283141\tvalid_1's f1: 0.847017\n",
      "[578]\ttraining's binary_logloss: 0.0156795\ttraining's f1: 0.921267\tvalid_1's binary_logloss: 0.0282986\tvalid_1's f1: 0.847087\n",
      "[579]\ttraining's binary_logloss: 0.0156413\ttraining's f1: 0.921395\tvalid_1's binary_logloss: 0.0282722\tvalid_1's f1: 0.847246\n",
      "[580]\ttraining's binary_logloss: 0.0156073\ttraining's f1: 0.921536\tvalid_1's binary_logloss: 0.0282528\tvalid_1's f1: 0.847503\n",
      "[581]\ttraining's binary_logloss: 0.0155745\ttraining's f1: 0.92169\tvalid_1's binary_logloss: 0.0282281\tvalid_1's f1: 0.84762\n",
      "[582]\ttraining's binary_logloss: 0.0155592\ttraining's f1: 0.921728\tvalid_1's binary_logloss: 0.028221\tvalid_1's f1: 0.847577\n",
      "[583]\ttraining's binary_logloss: 0.0155055\ttraining's f1: 0.921985\tvalid_1's binary_logloss: 0.0281697\tvalid_1's f1: 0.848159\n",
      "[584]\ttraining's binary_logloss: 0.0154831\ttraining's f1: 0.922152\tvalid_1's binary_logloss: 0.028152\tvalid_1's f1: 0.848163\n",
      "[585]\ttraining's binary_logloss: 0.0154473\ttraining's f1: 0.922358\tvalid_1's binary_logloss: 0.0281255\tvalid_1's f1: 0.848507\n",
      "[586]\ttraining's binary_logloss: 0.0154228\ttraining's f1: 0.922409\tvalid_1's binary_logloss: 0.0281059\tvalid_1's f1: 0.848672\n",
      "[587]\ttraining's binary_logloss: 0.0153857\ttraining's f1: 0.922499\tvalid_1's binary_logloss: 0.0280784\tvalid_1's f1: 0.848609\n",
      "[588]\ttraining's binary_logloss: 0.015359\ttraining's f1: 0.922589\tvalid_1's binary_logloss: 0.028062\tvalid_1's f1: 0.848637\n",
      "[589]\ttraining's binary_logloss: 0.0153083\ttraining's f1: 0.92277\tvalid_1's binary_logloss: 0.0280262\tvalid_1's f1: 0.848896\n",
      "[590]\ttraining's binary_logloss: 0.01529\ttraining's f1: 0.922796\tvalid_1's binary_logloss: 0.028008\tvalid_1's f1: 0.848928\n",
      "[591]\ttraining's binary_logloss: 0.015266\ttraining's f1: 0.922899\tvalid_1's binary_logloss: 0.0279877\tvalid_1's f1: 0.848893\n",
      "[592]\ttraining's binary_logloss: 0.0152243\ttraining's f1: 0.923209\tvalid_1's binary_logloss: 0.0279535\tvalid_1's f1: 0.849082\n",
      "[593]\ttraining's binary_logloss: 0.0151878\ttraining's f1: 0.923415\tvalid_1's binary_logloss: 0.027925\tvalid_1's f1: 0.849208\n",
      "[594]\ttraining's binary_logloss: 0.0151702\ttraining's f1: 0.923415\tvalid_1's binary_logloss: 0.027911\tvalid_1's f1: 0.849204\n",
      "[595]\ttraining's binary_logloss: 0.0151132\ttraining's f1: 0.92392\tvalid_1's binary_logloss: 0.0278529\tvalid_1's f1: 0.849587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[596]\ttraining's binary_logloss: 0.015072\ttraining's f1: 0.924037\tvalid_1's binary_logloss: 0.0278212\tvalid_1's f1: 0.849804\n",
      "[597]\ttraining's binary_logloss: 0.015048\ttraining's f1: 0.924115\tvalid_1's binary_logloss: 0.027804\tvalid_1's f1: 0.849809\n",
      "[598]\ttraining's binary_logloss: 0.0150082\ttraining's f1: 0.924426\tvalid_1's binary_logloss: 0.0277704\tvalid_1's f1: 0.84996\n",
      "[599]\ttraining's binary_logloss: 0.014977\ttraining's f1: 0.924582\tvalid_1's binary_logloss: 0.0277477\tvalid_1's f1: 0.850197\n",
      "[600]\ttraining's binary_logloss: 0.014946\ttraining's f1: 0.924959\tvalid_1's binary_logloss: 0.0277265\tvalid_1's f1: 0.850321\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[600]\ttraining's binary_logloss: 0.014946\ttraining's f1: 0.924959\tvalid_1's binary_logloss: 0.0277265\tvalid_1's f1: 0.850321\n"
     ]
    }
   ],
   "source": [
    "lig_model = lig_mo.fit(X,Y\n",
    "                    ,eval_set=[(X,Y),(tx,ty)]\n",
    "                      ,eval_metric=cus_f1,early_stopping_rounds=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T08:03:18.063609Z",
     "start_time": "2019-10-10T08:03:11.561782Z"
    }
   },
   "outputs": [],
   "source": [
    "yh = lig_model.predict(tx)\n",
    "ypre = lig_model.predict(tx,raw_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T08:03:19.581909Z",
     "start_time": "2019-10-10T08:03:19.577920Z"
    }
   },
   "outputs": [],
   "source": [
    "ypre = (ypre > -1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T08:03:21.266773Z",
     "start_time": "2019-10-10T08:03:21.097861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7056188656873724"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(ty,yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "yh = lig_model.predict(kaggle_,raw_score=True)\n",
    "ypre = lig_model.predict(kaggle_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only size-1 arrays can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1324-8a5ae4044d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m  \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mypre\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1324-8a5ae4044d05>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pre\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m  \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mypre\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "threshold =  0.3\n",
    "y_pre = [int(item>threshold) for  item in ypre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "yh = (yh > -1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypre = pd.DataFrame(ypre,index=kaggle_.index)\n",
    "yh = pd.DataFrame(yh,index=kaggle_.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypre = pd.concat([ypre,kaggle_['txkey']],axis=1)\n",
    "yh = pd.concat([yh,kaggle_['txkey']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = kaggle_ans.merge(ypre)\n",
    "bbb = kaggle_ans.merge(yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5930408472012102"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(aaa['fraud_ind'],aaa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6004213483146068"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(aaa['fraud_ind'],bbb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:17.166470Z",
     "start_time": "2019-10-11T08:12:13.101410Z"
    }
   },
   "outputs": [],
   "source": [
    "ypre = clf_over_sampled_lig.predict(testing.drop(['cano','bacno','txkey','locdt'],axis=1)) \n",
    "yh = clf_over_sampled_lig.predict(testing.drop(['cano','bacno','txkey','locdt'],axis=1),raw_score=True) \n",
    "yh = (yh > 3.5) * 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:20.854168Z",
     "start_time": "2019-10-11T08:12:20.615274Z"
    }
   },
   "outputs": [],
   "source": [
    "ypre = pd.DataFrame(ypre,index=testing.index) \n",
    "ypre = pd.concat([ypre,testing['txkey']],axis=1) \n",
    "b = sub.merge(ypre) \n",
    "yh = pd.DataFrame(yh,index=testing.index) \n",
    "yh = pd.concat([yh,testing['txkey']],axis=1) \n",
    "c = sub.merge(yh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:24.385883Z",
     "start_time": "2019-10-11T08:12:24.374912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51209.0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:27.850992Z",
     "start_time": "2019-10-11T08:12:27.843013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5837"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:31.444119Z",
     "start_time": "2019-10-11T08:12:31.308458Z"
    }
   },
   "outputs": [],
   "source": [
    "c = sub.merge(yh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_ans['fraud_ind'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:34.979466Z",
     "start_time": "2019-10-11T08:12:34.971486Z"
    }
   },
   "outputs": [],
   "source": [
    "c['fraud_ind'] = c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:38.417906Z",
     "start_time": "2019-10-11T08:12:38.405939Z"
    }
   },
   "outputs": [],
   "source": [
    "c.drop(0,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:41.860728Z",
     "start_time": "2019-10-11T08:12:41.852749Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txkey</th>\n",
       "      <th>fraud_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>592489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>592452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>590212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>590209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>592488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421660</td>\n",
       "      <td>1187507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421661</td>\n",
       "      <td>1182598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421662</td>\n",
       "      <td>898724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421663</td>\n",
       "      <td>971467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>421664</td>\n",
       "      <td>101230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          txkey  fraud_ind\n",
       "0        592489          0\n",
       "1        592452          0\n",
       "2        590212          0\n",
       "3        590209          0\n",
       "4        592488          0\n",
       "...         ...        ...\n",
       "421660  1187507          0\n",
       "421661  1182598          0\n",
       "421662   898724          0\n",
       "421663   971467          0\n",
       "421664   101230          0\n",
       "\n",
       "[421665 rows x 2 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T08:12:46.270967Z",
     "start_time": "2019-10-11T08:12:45.324494Z"
    }
   },
   "outputs": [],
   "source": [
    "c.to_csv('test13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txkey</th>\n",
       "      <th>fraud_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>592489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>590212</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>592488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>592460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>590160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>592453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>585745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>592451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>592456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1176112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>900425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1611461</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>215591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1751664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>185563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>608423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1041457</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>899509</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>605308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>602666</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>268390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1390047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1616943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>602665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1831585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1186182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1402780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1045947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421635</th>\n",
       "      <td>1034535</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421636</th>\n",
       "      <td>1323068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421637</th>\n",
       "      <td>1037920</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421638</th>\n",
       "      <td>1537063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421639</th>\n",
       "      <td>47480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421640</th>\n",
       "      <td>1608577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421641</th>\n",
       "      <td>1037924</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421642</th>\n",
       "      <td>1462822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421643</th>\n",
       "      <td>1932478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421644</th>\n",
       "      <td>1935813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421645</th>\n",
       "      <td>1951795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421646</th>\n",
       "      <td>1036006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421647</th>\n",
       "      <td>1938590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421648</th>\n",
       "      <td>1953793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421649</th>\n",
       "      <td>1331090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421650</th>\n",
       "      <td>1944814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421651</th>\n",
       "      <td>1946378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421652</th>\n",
       "      <td>270871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421653</th>\n",
       "      <td>358272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421654</th>\n",
       "      <td>329145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421655</th>\n",
       "      <td>385657</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421656</th>\n",
       "      <td>214574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421657</th>\n",
       "      <td>1043700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421658</th>\n",
       "      <td>966092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421659</th>\n",
       "      <td>963833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421660</th>\n",
       "      <td>1187507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421661</th>\n",
       "      <td>1182598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421662</th>\n",
       "      <td>898724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421663</th>\n",
       "      <td>971467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421664</th>\n",
       "      <td>101230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421665 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          txkey  fraud_ind\n",
       "0        592489          0\n",
       "1        592452          0\n",
       "2        590212          0\n",
       "3        590209          0\n",
       "4        592488          0\n",
       "...         ...        ...\n",
       "421660  1187507          0\n",
       "421661  1182598          0\n",
       "421662   898724          0\n",
       "421663   971467          0\n",
       "421664   101230          0\n",
       "\n",
       "[421665 rows x 2 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kaggle_ans = kaggle_ans.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36695.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['fraud_ind'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5585533869115958"
      ]
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(aaa['fraud_ind'],aaa[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[530045,   4070],\n",
       "       [   974,   6487]], dtype=int64)"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ty,ypre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [406182, 167847]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1124-66e65d96b598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mty\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mypre\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1850\u001b[0m     \"\"\"\n\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 205\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [406182, 167847]"
     ]
    }
   ],
   "source": [
    "print(classification_report(ty,ypre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T08:01:53.737087Z",
     "start_time": "2019-10-10T08:01:53.729117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>comsum_max</td>\n",
       "      <td>4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>conam</td>\n",
       "      <td>4461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_ave</td>\n",
       "      <td>4292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>loctm</td>\n",
       "      <td>4014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_total</td>\n",
       "      <td>3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_feq30</td>\n",
       "      <td>2564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>day_trad_num</td>\n",
       "      <td>2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>day_comsum_total</td>\n",
       "      <td>2498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_feq3060</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_feq60</td>\n",
       "      <td>2070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mcc</td>\n",
       "      <td>2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mchno</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_feq3090</td>\n",
       "      <td>1944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acc_trad_ave</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acqic</td>\n",
       "      <td>1768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_feq6090</td>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_min</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>city_com_num</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ecfg_scity</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_feq60120</td>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scity</td>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>week</td>\n",
       "      <td>1144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ecfg_stocn</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>csmcu</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ovrlt_stocn</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stscd</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>country_com_num</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>stocn</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comsum_feq90120</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>etymd</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>trad_hour</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morning</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>afternoon</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>contp</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hcefg</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_taiwan</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flg_3dsmk_N</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flbmk_N</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iterm</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flbmk_Y</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>insfg_N</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ovrlt_N</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>insfg_Y</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>flg_3dsmk_Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>midnight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ecfg_N</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>acc_trad_total</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ecfg_Y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ovrlt_scity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ovrlt_Y</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "comsum_max        4570\n",
       "conam             4461\n",
       "comsum_ave        4292\n",
       "loctm             4014\n",
       "comsum_total      3102\n",
       "comsum_feq30      2564\n",
       "day_trad_num      2544\n",
       "day_comsum_total  2498\n",
       "comsum_feq3060    2323\n",
       "comsum_feq60      2070\n",
       "mcc               2037\n",
       "mchno             1970\n",
       "comsum_feq3090    1944\n",
       "acc_trad_ave      1893\n",
       "acqic             1768\n",
       "comsum_feq6090    1720\n",
       "comsum_min        1647\n",
       "city_com_num      1646\n",
       "ecfg_scity        1627\n",
       "comsum_feq60120   1518\n",
       "scity             1446\n",
       "week              1144\n",
       "ecfg_stocn         942\n",
       "csmcu              846\n",
       "ovrlt_stocn        777\n",
       "stscd              735\n",
       "country_com_num    687\n",
       "stocn              676\n",
       "comsum_feq90120    504\n",
       "etymd              412\n",
       "trad_hour          296\n",
       "morning            195\n",
       "afternoon          142\n",
       "contp              133\n",
       "hcefg               50\n",
       "is_taiwan           44\n",
       "flg_3dsmk_N         39\n",
       "flbmk_N             32\n",
       "iterm               28\n",
       "flbmk_Y             22\n",
       "insfg_N             18\n",
       "ovrlt_N             12\n",
       "insfg_Y              5\n",
       "flg_3dsmk_Y          4\n",
       "night                1\n",
       "midnight             1\n",
       "ecfg_N               1\n",
       "acc_trad_total       0\n",
       "ecfg_Y               0\n",
       "ovrlt_scity          0\n",
       "ovrlt_Y              0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp = lig_model.feature_importances_\n",
    "imp_col = X.columns.tolist()\n",
    "importance = pd.DataFrame(imp,index=imp_col)\n",
    "importance.sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min & Max comsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = data_all.groupby(['bacno'])['conam'].min().reset_index().rename(columns={'conam':'comsum_min'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "grp = data_all.groupby(['bacno'])['conam'].max().reset_index().rename(columns={'conam':'comsum_max'})\n",
    "data_all = data_all.merge(grp,how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total & Average of num per custom trade times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = (data_all.groupby(['bacno'])['txkey'].count() / data_all['locdt'].max()).reset_index().rename(columns={'txkey':'acc_trad_ave'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "grp = data_all.groupby(['bacno'])['txkey'].count().reset_index().rename(columns={'txkey':'acc_trad_total'})\n",
    "data_all = data_all.merge(grp,how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total & Average payment per custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = data_all.groupby(['bacno'])['conam'].sum().reset_index().rename(columns={'conam':'comsum_total'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "grp = data_all.groupby(['bacno'])['conam'].mean().reset_index().rename(columns={'conam':'comsum_ave'})\n",
    "data_all = data_all.merge(grp,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1943452, 29)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# every 30days trade frequency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "day30 = data_all[data_all['locdt'] <= 30]\n",
    "grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq30'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "data_all['comsum_feq30'].fillna(0,inplace=True)\n",
    "\n",
    "day30 = data_all[(data_all['locdt'] <= 60) & (data_all['locdt'] >30 ) ]\n",
    "grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq3060'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "data_all['comsum_feq3060'].fillna(0,inplace=True)\n",
    "\n",
    "day30 = data_all[(data_all['locdt'] <= 90) & (data_all['locdt'] >60 ) ]\n",
    "grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq6090'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "data_all['comsum_feq6090'].fillna(0,inplace=True)\n",
    "\n",
    "day30 = data_all[(data_all['locdt'] <= 120) & (data_all['locdt'] >90 ) ]\n",
    "grp = (day30.groupby(['bacno'])['txkey'].count() / 30).reset_index().rename(columns={'txkey':'comsum_feq90120'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "data_all['comsum_feq90120'].fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# every 60days trade frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "day60 = data_all[data_all['locdt'] <= 60]\n",
    "grp = (day60.groupby(['bacno'])['txkey'].count() / 60).reset_index().rename(columns={'txkey':'comsum_feq60'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "data_all['comsum_feq60'].fillna(0,inplace=True)\n",
    "\n",
    "day60 = data_all[(data_all['locdt'] <= 90) & (data_all['locdt'] >30 ) ]\n",
    "grp = (day60.groupby(['bacno'])['txkey'].count() / 60).reset_index().rename(columns={'txkey':'comsum_feq3090'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "data_all['comsum_feq3090'].fillna(0,inplace=True)\n",
    "\n",
    "day60 = data_all[(data_all['locdt'] <= 120) & (data_all['locdt'] >60 ) ]\n",
    "grp = (day60.groupby(['bacno'])['txkey'].count() / 60).reset_index().rename(columns={'txkey':'comsum_feq60120'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "data_all['comsum_feq60120'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 每日交易次數、金額"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = data_all.groupby(['locdt'])['bacno'].count().reset_index().rename(columns={'bacno':'day_trad_num'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "grp = data_all.groupby(['locdt'])['conam'].sum().reset_index().rename(columns={'conam':'day_comsum_total'})\n",
    "data_all = data_all.merge(grp,how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 網路交易和國家&城市 cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['ecfg_stocn'] = data_all['ecfg'] + data_all['stocn'].astype('str')\n",
    "data_all['ecfg_scity'] = data_all['ecfg'] + data_all['scity'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超額註記和國家&城市 cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['ovrlt_stocn'] = data_all['ovrlt'] + data_all['stocn'].astype('str')\n",
    "data_all['ovrlt_scity'] = data_all['ovrlt'] + data_all['stocn'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日期轉換成星期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['week'] = data_all['locdt']\n",
    "data_all['week'] = data_all['week'] % 7 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 天轉換成小時"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['trad_hour'] = data_all['loctm'] // 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小時轉換成上午中午下午 ( code on desktop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['morning'] = ((data_all['trad_hour'] < 12) & (data_all['trad_hour'] >=6)).replace([True,False],[1,0])\n",
    "data_all['afternoon'] = ((data_all['trad_hour'] < 18) & (data_all['trad_hour'] >=12)).replace([True,False],[1,0])\n",
    "data_all['night'] = ((data_all['trad_hour'] < 24) & (data_all['trad_hour'] >=18)).replace([True,False],[1,0])\n",
    "data_all['midnight'] = ((data_all['trad_hour'] < 6) & (data_all['trad_hour'] >=0)).replace([True,False],[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 國家是否台灣 ( code on desktop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all['is_taiwan'] = (data_all['stocn'] == 102).replace([True,False],[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 消費次數(依照每個國家、城市消費次數)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = data_all.groupby(['stocn'])['txkey'].count().reset_index().rename(columns={'txkey':'country_com_num'})\n",
    "data_all = data_all.merge(grp,how='outer')\n",
    "\n",
    "grp = data_all.groupby(['scity'])['txkey'].count().reset_index().rename(columns={'txkey':'city_com_num'})\n",
    "data_all = data_all.merge(grp,how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 填補na 將flbmk 為na  直接視為無盜刷 ( 統計發現flbmk為na值 盜刷機率並無上升)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_predict = data_all[data_all['flbmk'].isna() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop na data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = data_all[data_all['fraud_ind'].isna() == False]\n",
    "testing = data_all[data_all['fraud_ind'].isna() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1521787, 51) test (421665, 51)\n"
     ]
    }
   ],
   "source": [
    "print('train',training.shape , 'test', testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o_train (1521787, 23) o_test (421665, 22)\n"
     ]
    }
   ],
   "source": [
    "print('o_train',train.shape,'o_test',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training.dropna(axis=0)\n",
    "testing = testing.drop('fraud_ind',axis=1)\n",
    "testing = testing.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1509206, 51) test (417950, 50)\n"
     ]
    }
   ],
   "source": [
    "print('train',training.shape , 'test', testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_list = []\n",
    "int_list = []\n",
    "float_list = []\n",
    "for col in data_all.columns.tolist() :\n",
    "    if data_all[col].dtype == 'object' :\n",
    "        object_list.append(col)\n",
    "    if data_all[col].dtype == 'int64'  :\n",
    "        int_list.append(col)\n",
    "    if data_all[col].dtype == 'float64' :\n",
    "        float_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nd_ont_list :\n",
    "    data_all =pd.concat([data_all] + [pd.get_dummies(data_all[col],prefix=col)] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "421665"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ypre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.DataFrame(ypre,index=testing['txkey'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = ans.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = ans.set_index(testing.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "421660    0\n",
       "421661    0\n",
       "421662    0\n",
       "421663    0\n",
       "421664    0\n",
       "Name: fraud_ind, Length: 421665, dtype: int64"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T11:31:09.419381Z",
     "start_time": "2019-10-09T11:31:09.365527Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./data/submission_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['fraud_ind'] = ypre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421665, 2)"
      ]
     },
     "execution_count": 783,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = sub.merge(ans,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans[0].fillna(0.0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['fraud_ind'] = ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans.drop(0,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans['fraud_ind'] = ans['fraud_ind'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24525.0"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['fraud_ind'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('test04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2|8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12581"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['flbmk'].isna()==True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015896987520864797"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200/12581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1521787"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20355"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['fraud_ind'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013375722095142093"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20355/1521787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T21:37:37.398828Z",
     "start_time": "2019-10-10T21:37:01.521018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of 0's and 1's in the feature Class before oversampling the data\n",
      "0.0    1501432\n",
      "1.0      20355\n",
      "Name: fraud_ind, dtype: int64\n",
      "No. of 0's and 1's in the feature Class after oversampling the data\n",
      "0.0    1501432\n",
      "1.0    1000000\n",
      "Name: fraud_ind, dtype: int64\n",
      "Training set has 1500859 samples.\n",
      "Testing set has 1000573 samples.\n",
      "Train Time: 28.721435546875\n",
      "Prediction Time: 1.8661365509033203\n",
      "fbeta score: 0.7963054123377465\n",
      "recall_score: 0.9991872561768531\n",
      "precision_score: 0.43941668453785115\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99    450385\n",
      "         1.0       0.44      1.00      0.61      6152\n",
      "\n",
      "    accuracy                           0.98    456537\n",
      "   macro avg       0.72      0.99      0.80    456537\n",
      "weighted avg       0.99      0.98      0.99    456537\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD9CAYAAABOd5eOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAYhklEQVR4nO3deZhU1ZnH8e9LLwqKuEYNkIAjdoImo4KEjNGgGMElYp6g4sxEHkQ7Ku4mLskz0WjmeYJxxDFxCRFGXGKLotITF8QFTYxsbihqSSsKLSgqS1QShO53/rinmbKtqq5uurvoc38fn/tQ973n3jql7a8P556qMndHRES6tm6l7oCIiGw5hbmISAQU5iIiEVCYi4hEQGEuIhIBhbmISATKS92BrqSqqqoMWAi8m8lkjs2q/xYYl8lktg/7FwKnAZuAD4BTM5nMO+FYA/ByOHVZJpM5rtlzNL/WGcAEoAH4BKjOZDKvdtyrlHZQBdydtb8X8AtgDnAzsC3Jz8ZZwPysdgcBc4GTgHuB/YGbgB1I/vv/Z7PrimymMG+d84DXSP7nAqCqqmowsGOzdi8AgzOZzPqqqqozgatJ/gcF+Hsmk9k/18XzXOuPmUzm5nD8OOBaYOSWvhDpUBmSIAYoA94F7gf+APwSeBg4muTnYlhWu4nArKzrrAdOAZYAXwaeC8fXdmjvpUtqMczN7GvAKKA34MAKoNbdX+vgvm1Vqqqq+gDHkIyOLgy1MuA3wL8CP2hqm8lknsw6dS7w70VcP9+1/pbVbDuS/wbSdQwH3gTeIflv1zQQ6EXy/1KTc4AZJKPzJm9kPV4BrAJ2Q2EuORScMzezS4AawEj+OrggPL7LzC7t+O5tVa4DLgYas2pnA7WZTGZlgfPGk4zEmmxbVVW1sKqqam5VVdXxxVyrqqpqQlVV1ZskI7lz2/wKpBTGAHeFx+eT/MJeDlwDXBbqvUl+gd9c4DpDgEqSXwwiX2CF3s5vZm8A+7r7xmb1SmCxuw/Ic141UA3w+0uOHVR9/KD263EJPPniuzz10gquGHsQ8157n6kPv86V4w7i/Bue4fbLhlNe1o0Dqu/hhcknfO68mc8s5c7Hl3DHZcOprCgD4P0169l9px4sX/UJYyc+wa0XH8Y2lWUtXgvgf599m7+8vJKJ1d/ujJfdoSq/c1Wpu9DhKioqeGd5Pft/8xusWrWKayddx5+ffpr777+P0aNPYPzpp3HUiBHcVXM3kyZdy/x587hlylQeevBB7rtvxubr7LHHHjz2+BOceuo45s+bV8JX1PE+29RgW3yRuVcU/7fXoVds+fNtJVoK89eBEe7+TrP6V4FH3b2qxWdozb/YrdR/TX+RmX99m/KybmzY2MAnf99IZXk3KivK2CaE9IqPPqXvbtsz+zffB+Cvi9/jqtuf446fDWeXHbbNed1L/zCXYft/mW0ryvj51Pl5r9WksdE56KwZPHfz6A58tZ0jDWH+/e8fxxlnncUxRyW3OD74aDW77bLz5uMfrl7DrjvvRGZJHWZJpuy6666sX7+es844g9ramfTs2ZPHHn+CqydOZMaMe0vyOjqTwrztWpozPx943MyWkPzVEOArwN4k0wKpcNGJ+3PRicn9rKaR+e8v/O7n2hxQfc/m8H31ndX84n8WcMtPhn0uyNd9+hndK8uorChj9ccbeH7JB5x29NfZu3cvnrn+Bzmv9fZ7H9Nvj54AzHlpBV/dvWeHvlZpPyeNGcPdNTWb91euWMGh3/0uTz/1FIcdfjh1S5YAUDVg781tmkbmtbUzqaio4J4ZM7jjjttTEeTtJqUfHlgwzN39ETPbh2S+rjfJfHk9sMDdGzqhf13S1TUvsn7DRs674S8A7Lnzdtx8waG8uWIdl9+6ADPD3Tn9mIHs3btXwWvd8dgbPLv4PcrLu7FDj0omnj60M16CbKHu3bsz/IgjOOvMMzbXzjjjx1x77STKy8v5x4Z/cGbWsVxOOOFEDjnkUHbZeRdOOWUsAKeNP5WXXnqpQ/ve5aU0zAtOs7SLCKZZpP2lYZpFWq9dplme+UXxmXPwlamZZhER6VpSOjLX2/lFRCKgkbmIxCWlI3OFuYjEJZ1ZrjAXkcg0pjPNFeYiEhmFuYhI15fOLFeYi0hkdANURCQC6cxyhbmIREYjcxGRCCjMRUQikM4sV5iLSGRSOjLXZ7OIiBRgZmVm9oKZ/Sns9zezeWa2xMzuDt+8hpltE/brwvF+Wde4LNQzZjYiqz4y1Oqyv4oz33MUojAXkbi4F78V5zwg+wvsJwKTwtdmriH5nl/Cn2vcfW9gUmiHmQ0k+S7YfYGRwI3hF0QZcANwFDAQODm0LfQceSnMRSQujV781gIz6wMcA9wS9g04HGj66qdpQNMXs48K+4Tjw0P7UUCNu29w96VAHckX/gwB6tz9LXf/DKgBRrXwHHkpzEUkLl78ZmbVZrYwa6tudrXrgIuBxrC/C7DW3TeF/XqSb2Ej/LkcIBxfF9pvrjc7J1+90HPkpRugIhKZ4m+AuvtkYHKuY2Z2LLDK3Z8zs2FN5QJPmO9YvnquwXSh9gUpzEUkLu23mOVg4DgzOxrYFtiBZKS+o5mVh5FzH2BFaF8P9AXqzawc6AWszqo3yT4nV/3DAs+Rl6ZZRCQu7XQD1N0vc/c+7t6P5AbmE+7+b8CTwOjQbCwwMzyuDfuE40948iXLtcCYsNqlPzAAmA8sAAaElSuV4Tlqwzn5niMvhbmIxKX9V7M0dwlwoZnVkcxvTwn1KcAuoX4hcGnSHV8MTAdeBR4BJrh7Qxh1nw3MIlktMz20LfQceZl39AL7uVekcwW/FFT5natK3QXZCn22qSHXfHHrzLyg+MwZNWnLn28roTlzEYlLSt8BqjAXkbikM8sV5iISmZSOzHUDVEQkAhqZi0hcinibfowU5iISF02ziIhIV6WRuYjEJaUjc4W5iMQlnVmuMBeRyGhkLiISAYW5iEgE0pnlCnMRiYxG5iIiEUhnlivMRSQyGpmLiHR9rfmOhmg+zByFuYhEpjUDc4W5iMhWqsO/PW0rpTAXkaikM8oV5iISGY3MRUQikNKPM1eYi0hcGlOa5gpzEYlKOqNcYS4ikWnUnLmISNeX0ixXmItIXLSaRUQkAumMcoW5iESmQatZRES6Pk2ziIhEIKVZTrdSd0BEpD014kVvhZjZtmY238xeMrPFZvbLUL/TzDJm9oqZTTWzilA3M7vezOrMbJGZHZh1rbFmtiRsY7Pqg8zs5XDO9WZmob6zmc0O7Web2U4tvW6FuYhExb34rQUbgMPd/Z+B/YGRZjYUuBP4GvANoDtwWmh/FDAgbNXATZAEM3A58C1gCHB5VjjfFNo2nTcy1C8FHnf3AcDjYb8ghbmIRKWx0YveCvHEJ2G3Imzu7g+FYw7MB/qENqOA28KhucCOZrYnMAKY7e6r3X0NMJvkF8OewA7u/my41m3A8VnXmhYeT8uq56UwF5GoeCv+aYmZlZnZi8AqkkCel3WsAvgR8Ego9QaWZ51eH2qF6vU56gC7u/tKgPDnl1rqq8JcRKLS6MVvZlZtZguztursa7l7g7vvTzL6HmJm+2UdvhF42t3/HPZzfXGRt6HeJlrNIiJRac3SRHefDEwuot1aM5tDMqf9ipldDuwG/DirWT3QN2u/D7Ai1Ic1q88J9T452gO8b2Z7uvvKMB2zqqU+amQuIlFprxugZrabme0YHncHjgBeN7PTSObBT3b3xqxTaoFTwqqWocC6MEUyCzjSzHYKNz6PBGaFYx+b2dCwiuUUYGbWtZpWvYzNquelkbmIRKUd3zS0JzDNzMpIBr7T3f1PZrYJeAd4NqwkvM/drwQeAo4G6oD1wLjQn9VmdhWwIFz3SndfHR6fCdxKsirm4bAB/BqYbmbjgWXACS11VmEuIlFpaKcwd/dFwAE56jlzM6xImZDn2FRgao76QmC/HPWPgOGt6a/CXESiktZ3gCrMRSQq+mwWEZEIpPRDExXmIhKXYt4MFCOFuYhEJaWzLApzEYmLvpxCRCQCmmYREYmApllERCKgpYkiIhFIaZYrzEUkLu31dv6uRmEuIlHRNIuISARSmuUKcxGJS2NK01xhLiJRSWeUK8xFJDKaMxcRiYDezi8iEoGUDswV5iISF302i4hIBDQyFxGJgJYmiohEQGEuIhKBlGa5wlxE4qJ15iIiEUjpMnOFuYjERSNzEZEIpDPKFeYiEhm9nV9EJAKaZhERiUBKs1xhLiJxSetns3QrdQdERNpToxe/FWJmfc3sSTN7zcwWm9l5zY7/xMzczHYN+2Zm15tZnZktMrMDs9qONbMlYRubVR9kZi+Hc643Mwv1nc1sdmg/28x2aul1K8xFJCruXvTWgk3ARe7+dWAoMMHMBkIS9MD3gGVZ7Y8CBoStGrgptN0ZuBz4FjAEuDwrnG8KbZvOGxnqlwKPu/sA4PGwX5DCXESi0uhe9FaIu6909+fD44+B14De4fAk4GI+vxJyFHCbJ+YCO5rZnsAIYLa7r3b3NcBsYGQ4toO7P+vJb5bbgOOzrjUtPJ6WVc9LYS4iUWnNNIuZVZvZwqytOtc1zawfcAAwz8yOA95195eaNesNLM/arw+1QvX6HHWA3d19JSS/VIAvtfS6dQNURKLSmqWJ7j4ZmFyojZltD8wAzieZevk5cGSuprmeog31NtHIXESi4l781hIzqyAJ8jvd/T7gn4D+wEtm9jbQB3jezPYgGVn3zTq9D7CihXqfHHWA98M0DOHPVS31VWEuIlFprxugYWXJFOA1d782XPtld/+Su/dz934kgXygu78H1AKnhFUtQ4F1YYpkFnCkme0UbnweCcwKxz42s6HhuU4BZoanrwWaVr2MzarnpWkWEYlKQ/u9a+hg4EfAy2b2Yqj9zN0fytP+IeBooA5YD4wDcPfVZnYVsCC0u9LdV4fHZwK3At2Bh8MG8GtgupmNJ1kxc0JLnVWYi0hU2ivL3f0v5J7Xzm7TL+uxAxPytJsKTM1RXwjsl6P+ETC8Nf1VmItIVPTZLCIiEUhnlCvMRSQy+kLnDmLf/mVHP4V0QeXdCk5FirRZSrNcI3MRiUujvpxCRKTra0zprLnCXESiomkWEZEIaGmiiEgEUprlCnMRiYvmzEVEIqDVLCIiEdA0i4hIBHQDVEQkAo2l7kCJKMxFJCoamYuIREA3QEVEIpDSLFeYi0hcXOvMRUS6vpROmSvMRSQuugEqIhIBzZmLiERAXxsnIhIBTbOIiERA0ywiIhHQyFxEJALpjHKFuYhERiNzEZEINKR00lxhLiJRSWeUK8xFJDJpnWbpVuoOiIi0J/fit5aY2VQzW2VmrzSrn2NmGTNbbGZXZ9UvM7O6cGxEVn1kqNWZ2aVZ9f5mNs/MlpjZ3WZWGerbhP26cLxfS31VmItIVBrdi96KcCswMrtgZocBo4Bvuvu+wDWhPhAYA+wbzrnRzMrMrAy4ATgKGAicHNoCTAQmufsAYA0wPtTHA2vcfW9gUmhXkMJcRKLSnmHu7k8Dq5uVzwR+7e4bQptVoT4KqHH3De6+FKgDhoStzt3fcvfPgBpglJkZcDhwbzh/GnB81rWmhcf3AsND+7wU5iISldZMs5hZtZktzNqqi3iKfYBDwvTHU2Z2UKj3BpZntasPtXz1XYC17r6pWf1z1wrH14X2eekGqIhEpTUftOXuk4HJrXyKcmAnYChwEDDdzPYCco2cndyDZi/QnhaO5e2UiEg0OmExSz1wnyfLZuabWSOwa6j3zWrXB1gRHueqfwjsaGblYfSd3b7pWvVmVg704ovTPZ+jaRYRiYq34p82eoBkrhsz2weoJAnmWmBMWInSHxgAzAcWAAPCypVKkpukteGXwZPA6HDdscDM8Lg27BOOP+EtrLnUyFxEotKeI3MzuwsYBuxqZvXA5cBUYGpYrvgZMDYE7WIzmw68CmwCJrh7Q7jO2cAsoAyY6u6Lw1NcAtSY2a+AF4ApoT4FuN3M6khG5GNa7GtHL7A3s3Su4JeCyrsVvDEvKbWxoXGLfzAmHLFf0Zlzw2OvRPODqJG5iEQlre8AVZiLSFTSGeUKcxGJjEbmIiIRSOkn4CrMRSQujSlNc4W5iERlC9aPd2kKcxGJSkoH5gpzEYmLboCKiEQgpVmuMBeRuGjOXEQkAg0pnTRXmItIVDTNIiISAd0AFRGJQGOpO1AiCnMRiYpG5iIiEUhplivMRSQurflC55gozEUkKgpzEZEIpDTLFeYiEhfdABURiUBKs1xhLiJxaUhpmivMRSQqmmYREYlASrNcYS4icWnUR+CKiHR9GpmLiERAc+YiIhHQl1OIiEQgnVGuMBeRyKR1mqVbqTsgItKe3IvfWmJmF5jZYjN7xczuMrNtzay/mc0zsyVmdreZVYa224T9unC8X9Z1Lgv1jJmNyKqPDLU6M7t0S163wlxEouLuRW+FmFlv4FxgsLvvB5QBY4CJwCR3HwCsAcaHU8YDa9x9b2BSaIeZDQzn7QuMBG40szIzKwNuAI4CBgInh7ZtojAXkag0evFbEcqB7mZWDvQAVgKHA/eG49OA48PjUWGfcHy4mVmo17j7BndfCtQBQ8JW5+5vuftnQE1o2yYKcxGJSqN70ZuZVZvZwqytuuk67v4ucA2wjCTE1wHPAWvdfVNoVg/0Do97A8vDuZtC+12y683OyVdvE90AFZGotOYGqLtPBibnOmZmO5GMlPsDa4F7SKZEvnCZplPyHMtXzzWYbvPdW4W5iESlHZeZHwEsdfcPAMzsPuBfgB3NrDyMvvsAK0L7eqAvUB+mZXoBq7PqTbLPyVdvNU2ziEhUvBX/tGAZMNTMeoS57+HAq8CTwOjQZiwwMzyuDfuE40948teEWmBMWO3SHxgAzAcWAAPC6phKkpuktW193RqZi0hU2muZubvPM7N7geeBTcALJFMyDwI1ZvarUJsSTpkC3G5mdSQj8jHhOovNbDrJL4JNwAR3bwAws7OBWSQrZaa6++K29tc6eoG9maVzBb8UVN4t1zSipN3GhsYt/sE4sN9uRWfO829/EM0PokbmIhKVtL4DVGEuIlFJZ5QrzEUkMhqZi4hEIKWfgKswF5G4aGQuIhKBRoW5iEjXl9IsV5iLSFw0MhcRiUBKs1xhLiJxKeIzV6KkMBeRqGhkLiISgYaULjRXmItIVDTNIiISAU2ziIhEQEsTRUQikNIsV5iLSFw0MhcRiYDCXEQkAinNcoW5iMRFH4ErIhKBlGa5wlxE4qI3DYmIREBv5xcRiYCmWUREIqBpFhGRCKR0lkVhLiJx0dJEEZEIpDTLFeYiEpeGlKa5wlxEopLWaZZupe5AWixdupRFixbxwgsvsGDBglJ3RzpYr169qJk+nZcXv8qiVxYzdOhQfjh6NC8uepkNGzcxaNCgL5zTt29f1qz7GxdceBEA++yzDwufe37z9tGatZx77nmd/VK6HPfit5hoZN6JDjvsMD766KNSd0M6waTrruPRWbMYc+KJVFRU0KNHD9auXcuJo3/IjTfdnPOca669lkceeXjz/htvvMHgQQcC0K1bN95ZXs8DD9zfKf3vytI6MleYi7Sznj178p1DDuXUceMA2LhxI+vWrWPdunV5zzlu1CiWvrWUTz/9NOfxw4cP560332TZsmUd0ueYNJa6AyXS5mkWMxvXnh2Jnbvz6KOPsnDhQk4//fRSd0c60F577cWHH3zAlKlTWbDwOX4/+Q/06NEjb/sePXrw059ezFVX/jJvm5NOGsPdNTUd0d3oNDZ60VtMrK1/JTGzZe7+lTzHqoHqsDvZ3Se3sX8x+bKZHevuDwCzgXOAp0vcJ+kYg4G5wMHAPOC/gb8B/xGOzwF+AiwEmDNnzqPDhg27BZgOXAF8AlyTdb1KYAWwL/B+h/deuqSC0yxmtijfIWD3fOeF8FaAf94Kkl9wk4H7gSEozGNVH7Z5Yf9e4NJ8jXv27PltYB/gamBHkpmCfwC/C02OAp5HQS4FtDRnvjswAljTrG7AXzukR3Hajv+f0toOOBK4snTdkQ72HrAcqAIywHDg1XyNBw8enHH3wWH3CpKR+e+ympwM3NUhPZVotBTmfwK2d/cXmx8wszkd0qM47Q7c//rrrw8A5gN/BB4pbZekg50D3EkyRfIWMA74AfBbYDfgQeBFksFSIT2A7wE/7rCeShTaPGcurWdm1bp/IM3p50Lag8JcRCQCegeoiEgEFOYiIhFQmHcSMxtpZhkzqzOzvMvUJD3MbKqZrTKzV0rdF+n6FOadwMzKgBtI1gsPBE42s4Gl7ZVsBW4FRpa6ExIHhXnnGALUuftb7v4ZUAOMKnGfpMTc/Wlgdan7IXFQmHeO3iRvImlSH2oiIu1CYd45LEdNa0JFpN0ozDtHPdA3a78PyWe1iIi0C4V551gADDCz/mZWCYwBakvcJxGJiMK8E7j7JuBsYBbwGjDd3ReXtldSamZ2F/AsUGVm9WY2vtR9kq5Lb+cXEYmARuYiIhFQmIuIREBhLiISAYW5iEgEFOYiIhFQmIuIREBhLiISgf8DgGL4/LMzr0UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(training.drop(['cano','bacno','txkey','locdt','fraud_ind'], axis=1), \n",
    "                                                    training['fraud_ind'], \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "\n",
    "resample_data = training.drop(['cano','bacno','txkey','locdt'], axis=1)\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['oversampled']={}\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class before oversampling the data\")\n",
    "print(resample_data['fraud_ind'].value_counts())\n",
    "\n",
    "\n",
    "data_majority = resample_data[resample_data['fraud_ind'] == 0]\n",
    "data_minority = resample_data[resample_data['fraud_ind'] == 1]\n",
    "\n",
    "data_minority_oversampled  = resample(data_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=1000000, \n",
    "                                 random_state=112) \n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_oversampled = pd.concat([data_majority, data_minority_oversampled])\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class after oversampling the data\")\n",
    " \n",
    "print(data_oversampled['fraud_ind'].value_counts())\n",
    "\n",
    "y = data_oversampled['fraud_ind']\n",
    "X = data_oversampled.drop('fraud_ind', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.4, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "start = time()\n",
    "#Training the Classifier\n",
    "clf_over_sampled_lig = lig.LGBMClassifier(n_estimators=300,reg_alpha=0.3,num_leaves=100,learning_rate=0.1,reg_lambda=0.5,subsample=0.7).fit(X_train, y_train)\n",
    "end = time()\n",
    "results['oversampled']['train_time'] = end - start\n",
    "\n",
    "# Predict on training set\n",
    "start = time()\n",
    "y_pred_score = clf_over_sampled_lig.predict(X_test1)\n",
    "end = time()\n",
    "results['oversampled']['pred_time'] = end - start\n",
    "\n",
    "results['oversampled']['fbeta'] = fbeta_score(y_test1,y_pred_score,beta=2)\n",
    "results['oversampled']['recall']= recall_score(y_test1,y_pred_score)\n",
    "results['oversampled']['precision'] = precision_score(y_test1,y_pred_score)\n",
    "\n",
    "\n",
    "print (\"Train Time:\", results['oversampled']['train_time'])\n",
    "print (\"Prediction Time:\", results['oversampled']['pred_time'])\n",
    "print (\"fbeta score:\", results['oversampled']['fbeta'])\n",
    "print('recall_score:', results['oversampled']['recall'])\n",
    "print('precision_score:', results['oversampled']['precision'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test1, y_pred_score))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test1,y_pred_score)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T21:38:27.650576Z",
     "start_time": "2019-10-10T21:37:41.283665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of 0's and 1's in the feature Class before oversampling the data\n",
      "0.0    1501432\n",
      "1.0      20355\n",
      "Name: fraud_ind, dtype: int64\n",
      "No. of 0's and 1's in the feature Class after oversampling the data\n",
      "0.0    1501432\n",
      "1.0    1000000\n",
      "Name: fraud_ind, dtype: int64\n",
      "Training set has 2001145 samples.\n",
      "Testing set has 500287 samples.\n",
      "Train Time: 39.03973054885864\n",
      "Prediction Time: 1.9922878742218018\n",
      "fbeta score: 0.8043751308352521\n",
      "recall_score: 0.9993498049414824\n",
      "precision_score: 0.45179306290417404\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99    450385\n",
      "         1.0       0.45      1.00      0.62      6152\n",
      "\n",
      "    accuracy                           0.98    456537\n",
      "   macro avg       0.73      0.99      0.81    456537\n",
      "weighted avg       0.99      0.98      0.99    456537\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(training.drop(['cano','bacno','txkey','locdt','fraud_ind'], axis=1), \n",
    "                                                    training['fraud_ind'], \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "\n",
    "resample_data = training.drop(['cano','bacno','txkey','locdt'], axis=1)\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['oversampled']={}\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class before oversampling the data\")\n",
    "print(resample_data['fraud_ind'].value_counts())\n",
    "\n",
    "\n",
    "data_majority = resample_data[resample_data['fraud_ind'] == 0]\n",
    "data_minority = resample_data[resample_data['fraud_ind'] == 1]\n",
    "\n",
    "data_minority_oversampled  = resample(data_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=1000000, \n",
    "                                 random_state=112) \n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_oversampled = pd.concat([data_majority, data_minority_oversampled])\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class after oversampling the data\")\n",
    " \n",
    "print(data_oversampled['fraud_ind'].value_counts())\n",
    "\n",
    "y = data_oversampled['fraud_ind']\n",
    "X = data_oversampled.drop('fraud_ind', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "start = time()\n",
    "#Training the Classifier\n",
    "clf_over_sampled_lig = lig.LGBMClassifier(n_estimators=300,reg_alpha=0.3,num_leaves=100,learning_rate=0.1,reg_lambda=0.5,subsample=0.7).fit(X_train, y_train)\n",
    "end = time()\n",
    "results['oversampled']['train_time'] = end - start\n",
    "\n",
    "# Predict on training set\n",
    "start = time()\n",
    "y_pred_score = clf_over_sampled_lig.predict(X_test1)\n",
    "end = time()\n",
    "results['oversampled']['pred_time'] = end - start\n",
    "\n",
    "results['oversampled']['fbeta'] = fbeta_score(y_test1,y_pred_score,beta=2)\n",
    "results['oversampled']['recall']= recall_score(y_test1,y_pred_score)\n",
    "results['oversampled']['precision'] = precision_score(y_test1,y_pred_score)\n",
    "\n",
    "\n",
    "print (\"Train Time:\", results['oversampled']['train_time'])\n",
    "print (\"Prediction Time:\", results['oversampled']['pred_time'])\n",
    "print (\"fbeta score:\", results['oversampled']['fbeta'])\n",
    "print('recall_score:', results['oversampled']['recall'])\n",
    "print('precision_score:', results['oversampled']['precision'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test1, y_pred_score))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test1,y_pred_score)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T23:30:16.409531Z",
     "start_time": "2019-10-10T23:29:27.185450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of 0's and 1's in the feature Class before oversampling the data\n",
      "0.0    1501432\n",
      "1.0      20355\n",
      "Name: fraud_ind, dtype: int64\n",
      "No. of 0's and 1's in the feature Class after oversampling the data\n",
      "0.0    1501432\n",
      "1.0     700000\n",
      "Name: fraud_ind, dtype: int64\n",
      "Training set has 1981288 samples.\n",
      "Testing set has 220144 samples.\n",
      "Train Time: 41.471346378326416\n",
      "Prediction Time: 2.0518805980682373\n",
      "fbeta score: 0.8346956569124299\n",
      "recall_score: 0.9959362808842653\n",
      "precision_score: 0.5066148503390111\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99    450385\n",
      "         1.0       0.51      1.00      0.67      6152\n",
      "\n",
      "    accuracy                           0.99    456537\n",
      "   macro avg       0.75      0.99      0.83    456537\n",
      "weighted avg       0.99      0.99      0.99    456537\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(training.drop(['cano','bacno','txkey','locdt','fraud_ind'], axis=1), \n",
    "                                                    training['fraud_ind'], \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "\n",
    "resample_data = training.drop(['cano','bacno','txkey','locdt'], axis=1)\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['oversampled']={}\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class before oversampling the data\")\n",
    "print(resample_data['fraud_ind'].value_counts())\n",
    "\n",
    "\n",
    "data_majority = resample_data[resample_data['fraud_ind'] == 0]\n",
    "data_minority = resample_data[resample_data['fraud_ind'] == 1]\n",
    "\n",
    "data_minority_oversampled  = resample(data_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=700000, \n",
    "                                 random_state=112) \n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_oversampled = pd.concat([data_majority, data_minority_oversampled])\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class after oversampling the data\")\n",
    " \n",
    "print(data_oversampled['fraud_ind'].value_counts())\n",
    "\n",
    "y = data_oversampled['fraud_ind']\n",
    "X = data_oversampled.drop('fraud_ind', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.1, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "start = time()\n",
    "#Training the Classifier\n",
    "clf_over_sampled_lig = lig.LGBMClassifier(n_estimators=300,reg_alpha=0.3,num_leaves=100,learning_rate=0.1,reg_lambda=0.5,subsample=0.7).fit(X_train, y_train)\n",
    "end = time()\n",
    "results['oversampled']['train_time'] = end - start\n",
    "\n",
    "# Predict on training set\n",
    "start = time()\n",
    "y_pred_score = clf_over_sampled_lig.predict(X_test1)\n",
    "end = time()\n",
    "results['oversampled']['pred_time'] = end - start\n",
    "\n",
    "results['oversampled']['fbeta'] = fbeta_score(y_test1,y_pred_score,beta=2)\n",
    "results['oversampled']['recall']= recall_score(y_test1,y_pred_score)\n",
    "results['oversampled']['precision'] = precision_score(y_test1,y_pred_score)\n",
    "\n",
    "\n",
    "print (\"Train Time:\", results['oversampled']['train_time'])\n",
    "print (\"Prediction Time:\", results['oversampled']['pred_time'])\n",
    "print (\"fbeta score:\", results['oversampled']['fbeta'])\n",
    "print('recall_score:', results['oversampled']['recall'])\n",
    "print('precision_score:', results['oversampled']['precision'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test1, y_pred_score))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test1,y_pred_score)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T21:39:26.819007Z",
     "start_time": "2019-10-10T21:38:31.535252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of 0's and 1's in the feature Class before oversampling the data\n",
      "0.0    1501432\n",
      "1.0      20355\n",
      "Name: fraud_ind, dtype: int64\n",
      "No. of 0's and 1's in the feature Class after oversampling the data\n",
      "0.0    1501432\n",
      "1.0    1000000\n",
      "Name: fraud_ind, dtype: int64\n",
      "Training set has 2476417 samples.\n",
      "Testing set has 25015 samples.\n",
      "Train Time: 48.08730125427246\n",
      "Prediction Time: 1.877608299255371\n",
      "fbeta score: 0.8093795283888817\n",
      "recall_score: 0.9986996098829649\n",
      "precision_score: 0.4603281636322769\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99    450385\n",
      "         1.0       0.46      1.00      0.63      6152\n",
      "\n",
      "    accuracy                           0.98    456537\n",
      "   macro avg       0.73      0.99      0.81    456537\n",
      "weighted avg       0.99      0.98      0.99    456537\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(training.drop(['cano','bacno','txkey','locdt','fraud_ind'], axis=1), \n",
    "                                                    training['fraud_ind'], \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "\n",
    "resample_data = training.drop(['cano','bacno','txkey','locdt'], axis=1)\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['oversampled']={}\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class before oversampling the data\")\n",
    "print(resample_data['fraud_ind'].value_counts())\n",
    "\n",
    "\n",
    "data_majority = resample_data[resample_data['fraud_ind'] == 0]\n",
    "data_minority = resample_data[resample_data['fraud_ind'] == 1]\n",
    "\n",
    "data_minority_oversampled  = resample(data_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=1000000, \n",
    "                                 random_state=112) \n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_oversampled = pd.concat([data_majority, data_minority_oversampled])\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class after oversampling the data\")\n",
    " \n",
    "print(data_oversampled['fraud_ind'].value_counts())\n",
    "\n",
    "y = data_oversampled['fraud_ind']\n",
    "X = data_oversampled.drop('fraud_ind', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.01, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "start = time()\n",
    "#Training the Classifier\n",
    "clf_over_sampled_lig = lig.LGBMClassifier(n_estimators=300,reg_alpha=0.3,num_leaves=100,learning_rate=0.1,reg_lambda=0.5,subsample=0.7).fit(X_train, y_train)\n",
    "end = time()\n",
    "results['oversampled']['train_time'] = end - start\n",
    "\n",
    "# Predict on training set\n",
    "start = time()\n",
    "y_pred_score = clf_over_sampled_lig.predict(X_test1)\n",
    "end = time()\n",
    "results['oversampled']['pred_time'] = end - start\n",
    "\n",
    "results['oversampled']['fbeta'] = fbeta_score(y_test1,y_pred_score,beta=2)\n",
    "results['oversampled']['recall']= recall_score(y_test1,y_pred_score)\n",
    "results['oversampled']['precision'] = precision_score(y_test1,y_pred_score)\n",
    "\n",
    "\n",
    "print (\"Train Time:\", results['oversampled']['train_time'])\n",
    "print (\"Prediction Time:\", results['oversampled']['pred_time'])\n",
    "print (\"fbeta score:\", results['oversampled']['fbeta'])\n",
    "print('recall_score:', results['oversampled']['recall'])\n",
    "print('precision_score:', results['oversampled']['precision'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test1, y_pred_score))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test1,y_pred_score)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T23:00:49.882148Z",
     "start_time": "2019-10-10T22:57:13.881335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of 0's and 1's in the feature Class before oversampling the data\n",
      "0.0    1501432\n",
      "1.0      20355\n",
      "Name: fraud_ind, dtype: int64\n",
      "No. of 0's and 1's in the feature Class after oversampling the data\n",
      "0.0    1501432\n",
      "1.0    1000000\n",
      "Name: fraud_ind, dtype: int64\n",
      "Training set has 2376360 samples.\n",
      "Testing set has 125072 samples.\n",
      "Train Time: 210.37633347511292\n",
      "Prediction Time: 0.10372519493103027\n",
      "fbeta score: 0.3447415503328749\n",
      "recall_score: 0.9208387516254877\n",
      "precision_score: 0.09842759099991312\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.88      0.94    450385\n",
      "         1.0       0.10      0.92      0.18      6152\n",
      "\n",
      "    accuracy                           0.89    456537\n",
      "   macro avg       0.55      0.90      0.56    456537\n",
      "weighted avg       0.99      0.89      0.93    456537\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(training.drop(['cano','bacno','txkey','locdt','fraud_ind'], axis=1), \n",
    "                                                    training['fraud_ind'], \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "\n",
    "resample_data = training.drop(['cano','bacno','txkey','locdt'], axis=1)\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['oversampled']={}\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class before oversampling the data\")\n",
    "print(resample_data['fraud_ind'].value_counts())\n",
    "\n",
    "\n",
    "data_majority = resample_data[resample_data['fraud_ind'] == 0]\n",
    "data_minority = resample_data[resample_data['fraud_ind'] == 1]\n",
    "\n",
    "data_minority_oversampled  = resample(data_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=1000000, \n",
    "                                 random_state=112) \n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_oversampled = pd.concat([data_majority, data_minority_oversampled])\n",
    "\n",
    "print(\"No. of 0's and 1's in the feature Class after oversampling the data\")\n",
    " \n",
    "print(data_oversampled['fraud_ind'].value_counts())\n",
    "\n",
    "y = data_oversampled['fraud_ind']\n",
    "X = data_oversampled.drop('fraud_ind', axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.05, \n",
    "                                                    random_state = 112)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))\n",
    "\n",
    "start = time()\n",
    "#Training the Classifier\n",
    "clf_over_sampled_lig = LogisticRegression(C=0.3,penalty=\"l2\",solver='newton-cg').fit(X_train, y_train)\n",
    "end = time()\n",
    "results['oversampled']['train_time'] = end - start\n",
    "\n",
    "# Predict on training set\n",
    "start = time()\n",
    "y_pred_score = clf_over_sampled_lig.predict(X_test1)\n",
    "end = time()\n",
    "results['oversampled']['pred_time'] = end - start\n",
    "\n",
    "results['oversampled']['fbeta'] = fbeta_score(y_test1,y_pred_score,beta=2)\n",
    "results['oversampled']['recall']= recall_score(y_test1,y_pred_score)\n",
    "results['oversampled']['precision'] = precision_score(y_test1,y_pred_score)\n",
    "\n",
    "\n",
    "print (\"Train Time:\", results['oversampled']['train_time'])\n",
    "print (\"Prediction Time:\", results['oversampled']['pred_time'])\n",
    "print (\"fbeta score:\", results['oversampled']['fbeta'])\n",
    "print('recall_score:', results['oversampled']['recall'])\n",
    "print('precision_score:', results['oversampled']['precision'])\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification report:\\n')\n",
    "print(classification_report(y_test1, y_pred_score))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test1,y_pred_score)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap=plt.cm.copper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "324.986px",
    "width": "580px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "627.273px",
    "left": "21.9886px",
    "top": "156.281px",
    "width": "284.233px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 646.903818,
   "position": {
    "height": "40px",
    "left": "1475.45px",
    "right": "20px",
    "top": "120px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
